{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2ytTie3bXSm",
        "outputId": "9cc73570-5539-45a5-c252-c91553a02347"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Eh6zXjqDJlx"
      },
      "outputs": [],
      "source": [
        "!unzip \"/content/drive/MyDrive/mdl_HAN.zip\"\n",
        "#!unzip \"/content/imdl_HAN_replace.zip\"\n",
        "# !unzip \"imdl_HAN_bert.zip\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLEmBuD41zn8",
        "outputId": "b67edb9a-ae62-4e57-faf7-a50e73a0f40a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentence_transformers\n",
            "  Downloading sentence_transformers-3.0.0-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.7/224.7 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.41.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.4)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.3.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.11.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.23.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.4.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, sentence_transformers\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 sentence_transformers-3.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install sentence_transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVJ-wAC40IQ0",
        "outputId": "337ce15d-561d-412f-ed0b-69628bbdd43c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting allennlp\n",
            "  Downloading allennlp-2.10.1-py3-none-any.whl (730 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m730.2/730.2 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch<1.13.0,>=1.10.0 (from allennlp)\n",
            "  Downloading torch-1.12.1-cp310-cp310-manylinux1_x86_64.whl (776.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.3/776.3 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision<0.14.0,>=0.8.1 (from allennlp)\n",
            "  Downloading torchvision-0.13.1-cp310-cp310-manylinux1_x86_64.whl (19.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cached-path<1.2.0,>=1.1.3 (from allennlp)\n",
            "  Downloading cached_path-1.1.6-py3-none-any.whl (26 kB)\n",
            "Collecting fairscale==0.4.6 (from allennlp)\n",
            "  Downloading fairscale-0.4.6.tar.gz (248 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m248.2/248.2 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: nltk>=3.6.5 in /usr/local/lib/python3.10/dist-packages (from allennlp) (3.8.1)\n",
            "Collecting spacy<3.4,>=2.1.0 (from allennlp)\n",
            "  Downloading spacy-3.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m89.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21.4 in /usr/local/lib/python3.10/dist-packages (from allennlp) (1.25.2)\n",
            "Collecting tensorboardX>=1.2 (from allennlp)\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.28 in /usr/local/lib/python3.10/dist-packages (from allennlp) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62 in /usr/local/lib/python3.10/dist-packages (from allennlp) (4.66.4)\n",
            "Requirement already satisfied: h5py>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from allennlp) (3.9.0)\n",
            "Requirement already satisfied: scikit-learn>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from allennlp) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.7.3 in /usr/local/lib/python3.10/dist-packages (from allennlp) (1.11.4)\n",
            "Requirement already satisfied: pytest>=6.2.5 in /usr/local/lib/python3.10/dist-packages (from allennlp) (7.4.4)\n",
            "Collecting transformers<4.21,>=4.1 (from allennlp)\n",
            "  Downloading transformers-4.20.1-py3-none-any.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m107.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sentencepiece>=0.1.96 in /usr/local/lib/python3.10/dist-packages (from allennlp) (0.1.99)\n",
            "Collecting filelock<3.8,>=3.3 (from allennlp)\n",
            "  Downloading filelock-3.7.1-py3-none-any.whl (10 kB)\n",
            "Collecting lmdb>=1.2.1 (from allennlp)\n",
            "  Downloading lmdb-1.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (299 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.2/299.2 kB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: more-itertools>=8.12.0 in /usr/local/lib/python3.10/dist-packages (from allennlp) (10.1.0)\n",
            "Collecting termcolor==1.1.0 (from allennlp)\n",
            "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting wandb<0.13.0,>=0.10.0 (from allennlp)\n",
            "  Downloading wandb-0.12.21-py2.py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m85.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.0.16 in /usr/local/lib/python3.10/dist-packages (from allennlp) (0.23.1)\n",
            "Collecting dill>=0.3.4 (from allennlp)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting base58>=2.1.1 (from allennlp)\n",
            "  Downloading base58-2.1.1-py3-none-any.whl (5.6 kB)\n",
            "Collecting sacremoses (from allennlp)\n",
            "  Downloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typer>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from allennlp) (0.9.4)\n",
            "Requirement already satisfied: protobuf<4.0.0,>=3.12.0 in /usr/local/lib/python3.10/dist-packages (from allennlp) (3.20.3)\n",
            "Requirement already satisfied: traitlets>5.1.1 in /usr/local/lib/python3.10/dist-packages (from allennlp) (5.7.1)\n",
            "Collecting jsonnet>=0.10.0 (from allennlp)\n",
            "  Downloading jsonnet-0.20.0.tar.gz (594 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.2/594.2 kB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting rich<13.0,>=12.1 (from cached-path<1.2.0,>=1.1.3->allennlp)\n",
            "  Downloading rich-12.6.0-py3-none-any.whl (237 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m237.5/237.5 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting boto3<2.0,>=1.0 (from cached-path<1.2.0,>=1.1.3->allennlp)\n",
            "  Downloading boto3-1.34.114-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-cloud-storage<3.0,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from cached-path<1.2.0,>=1.1.3->allennlp) (2.8.0)\n",
            "Collecting huggingface-hub>=0.0.16 (from allennlp)\n",
            "  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.5/163.5 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.0.16->allennlp) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.0.16->allennlp) (4.11.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.0.16->allennlp) (24.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.6.5->allennlp) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.6.5->allennlp) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.6.5->allennlp) (2024.5.15)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest>=6.2.5->allennlp) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest>=6.2.5->allennlp) (1.5.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest>=6.2.5->allennlp) (1.2.1)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest>=6.2.5->allennlp) (2.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->allennlp) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->allennlp) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->allennlp) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->allennlp) (2024.2.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.1->allennlp) (3.5.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (3.0.9)\n",
            "Collecting thinc<8.1.0,>=8.0.14 (from spacy<3.4,>=2.1.0->allennlp)\n",
            "  Downloading thinc-8.0.17-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (659 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m659.5/659.5 kB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (0.7.11)\n",
            "Collecting wasabi<1.1.0,>=0.9.1 (from spacy<3.4,>=2.1.0->allennlp)\n",
            "  Downloading wasabi-0.10.1-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (2.0.10)\n",
            "Collecting typer>=0.4.1 (from allennlp)\n",
            "  Downloading typer-0.4.2-py3-none-any.whl (27 kB)\n",
            "Collecting pathy>=0.3.5 (from spacy<3.4,>=2.1.0->allennlp)\n",
            "  Downloading pathy-0.11.0-py3-none-any.whl (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.3/47.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (6.4.0)\n",
            "Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 (from spacy<3.4,>=2.1.0->allennlp)\n",
            "  Downloading pydantic-1.8.2-py3-none-any.whl (126 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (67.7.2)\n",
            "Collecting typing-extensions>=3.7.4.3 (from huggingface-hub>=0.0.16->allennlp)\n",
            "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (3.4.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision<0.14.0,>=0.8.1->allennlp) (9.4.0)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1 (from transformers<4.21,>=4.1->allennlp)\n",
            "  Downloading tokenizers-0.12.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m100.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting GitPython>=1.0.0 (from wandb<0.13.0,>=0.10.0->allennlp)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.10/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp) (2.3)\n",
            "Collecting shortuuid>=0.5.0 (from wandb<0.13.0,>=0.10.0->allennlp)\n",
            "  Downloading shortuuid-1.0.13-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb<0.13.0,>=0.10.0->allennlp)\n",
            "  Downloading sentry_sdk-2.3.1-py2.py3-none-any.whl (289 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.0/289.0 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp) (1.16.0)\n",
            "Collecting docker-pycreds>=0.4.0 (from wandb<0.13.0,>=0.10.0->allennlp)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting pathtools (from wandb<0.13.0,>=0.10.0->allennlp)\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting setproctitle (from wandb<0.13.0,>=0.10.0->allennlp)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Collecting botocore<1.35.0,>=1.34.114 (from boto3<2.0,>=1.0->cached-path<1.2.0,>=1.1.3->allennlp)\n",
            "  Downloading botocore-1.34.114-py3-none-any.whl (12.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m105.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3<2.0,>=1.0->cached-path<1.2.0,>=1.1.3->allennlp)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3<2.0,>=1.0->cached-path<1.2.0,>=1.1.3->allennlp)\n",
            "  Downloading s3transfer-0.10.1-py3-none-any.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.2/82.2 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1 (from GitPython>=1.0.0->wandb<0.13.0,>=0.10.0->allennlp)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-auth<3.0dev,>=1.25.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (2.27.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (2.11.1)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (2.3.3)\n",
            "Requirement already satisfied: google-resumable-media>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (2.7.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.4,>=2.1.0->allennlp) (1.2.0)\n",
            "Collecting pathlib-abc==0.1.1 (from pathy>=0.3.5->spacy<3.4,>=2.1.0->allennlp)\n",
            "  Downloading pathlib_abc-0.1.1-py3-none-any.whl (23 kB)\n",
            "Collecting commonmark<0.10.0,>=0.9.0 (from rich<13.0,>=12.1->cached-path<1.2.0,>=1.1.3->allennlp)\n",
            "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from rich<13.0,>=12.1->cached-path<1.2.0,>=1.1.3->allennlp) (2.16.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.4,>=2.1.0->allennlp) (2.1.5)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.114->boto3<2.0,>=1.0->cached-path<1.2.0,>=1.1.3->allennlp) (2.8.2)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb<0.13.0,>=0.10.0->allennlp)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (1.63.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (4.9)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media>=2.3.2->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (1.5.0)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.4,>=2.1.0->allennlp) (1.1.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (0.6.0)\n",
            "Building wheels for collected packages: fairscale, termcolor, jsonnet, pathtools\n",
            "  Building wheel for fairscale (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairscale: filename=fairscale-0.4.6-py3-none-any.whl size=307222 sha256=75f2ca7eeea51226d2aed22edec09f786c95ce82a120cb00632d0e8efb21bfa5\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/58/3d/e114952ab4a8f31eb9dae230658450afff986b211a5b1f2256\n",
            "  Building wheel for termcolor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4832 sha256=52c27ecb065ded6fbe1c6a792a8a18b25da1cc7fb9f8f16bfd19d6ab62db01fc\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/49/46/1b13a65d8da11238af9616b00fdde6d45b0f95d9291bac8452\n",
            "  Building wheel for jsonnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jsonnet: filename=jsonnet-0.20.0-cp310-cp310-linux_x86_64.whl size=6406869 sha256=4a3d8fb1c051116f283599507182e7841c5cf1eaec8561c79ce0aa2eefaa730c\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/0d/6b/5467dd1db9332ba4bd5cf4153e2870c5f89bb4db473d989cc2\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=83782a95c6d2a16dc97281dd4c08bc364cfcf50945cd93414bfb83e124485934\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n",
            "Successfully built fairscale termcolor jsonnet pathtools\n",
            "Installing collected packages: wasabi, tokenizers, termcolor, pathtools, lmdb, jsonnet, commonmark, typing-extensions, typer, tensorboardX, smmap, shortuuid, setproctitle, sentry-sdk, sacremoses, rich, pathlib-abc, jmespath, filelock, docker-pycreds, dill, base58, torch, pydantic, pathy, huggingface-hub, gitdb, botocore, transformers, torchvision, thinc, s3transfer, GitPython, fairscale, wandb, spacy, boto3, cached-path, allennlp\n",
            "  Attempting uninstall: wasabi\n",
            "    Found existing installation: wasabi 1.1.2\n",
            "    Uninstalling wasabi-1.1.2:\n",
            "      Successfully uninstalled wasabi-1.1.2\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.19.1\n",
            "    Uninstalling tokenizers-0.19.1:\n",
            "      Successfully uninstalled tokenizers-0.19.1\n",
            "  Attempting uninstall: termcolor\n",
            "    Found existing installation: termcolor 2.4.0\n",
            "    Uninstalling termcolor-2.4.0:\n",
            "      Successfully uninstalled termcolor-2.4.0\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.11.0\n",
            "    Uninstalling typing_extensions-4.11.0:\n",
            "      Successfully uninstalled typing_extensions-4.11.0\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.9.4\n",
            "    Uninstalling typer-0.9.4:\n",
            "      Successfully uninstalled typer-0.9.4\n",
            "  Attempting uninstall: rich\n",
            "    Found existing installation: rich 13.7.1\n",
            "    Uninstalling rich-13.7.1:\n",
            "      Successfully uninstalled rich-13.7.1\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.14.0\n",
            "    Uninstalling filelock-3.14.0:\n",
            "      Successfully uninstalled filelock-3.14.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.3.0+cu121\n",
            "    Uninstalling torch-2.3.0+cu121:\n",
            "      Successfully uninstalled torch-2.3.0+cu121\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.7.1\n",
            "    Uninstalling pydantic-2.7.1:\n",
            "      Successfully uninstalled pydantic-2.7.1\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.23.1\n",
            "    Uninstalling huggingface-hub-0.23.1:\n",
            "      Successfully uninstalled huggingface-hub-0.23.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.41.1\n",
            "    Uninstalling transformers-4.41.1:\n",
            "      Successfully uninstalled transformers-4.41.1\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.18.0+cu121\n",
            "    Uninstalling torchvision-0.18.0+cu121:\n",
            "      Successfully uninstalled torchvision-0.18.0+cu121\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 8.2.3\n",
            "    Uninstalling thinc-8.2.3:\n",
            "      Successfully uninstalled thinc-8.2.3\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.7.4\n",
            "    Uninstalling spacy-3.7.4:\n",
            "      Successfully uninstalled spacy-3.7.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sqlalchemy 2.0.30 requires typing-extensions>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "en-core-web-sm 3.7.1 requires spacy<3.8.0,>=3.7.2, but you have spacy 3.3.3 which is incompatible.\n",
            "inflect 7.0.0 requires pydantic>=1.9.1, but you have pydantic 1.8.2 which is incompatible.\n",
            "pydantic-core 2.18.2 requires typing-extensions!=4.7.0,>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "sentence-transformers 3.0.0 requires huggingface-hub>=0.15.1, but you have huggingface-hub 0.10.1 which is incompatible.\n",
            "sentence-transformers 3.0.0 requires transformers<5.0.0,>=4.34.0, but you have transformers 4.20.1 which is incompatible.\n",
            "torchaudio 2.3.0+cu121 requires torch==2.3.0, but you have torch 1.12.1 which is incompatible.\n",
            "torchtext 0.18.0 requires torch>=2.3.0, but you have torch 1.12.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed GitPython-3.1.43 allennlp-2.10.1 base58-2.1.1 boto3-1.34.114 botocore-1.34.114 cached-path-1.1.6 commonmark-0.9.1 dill-0.3.8 docker-pycreds-0.4.0 fairscale-0.4.6 filelock-3.7.1 gitdb-4.0.11 huggingface-hub-0.10.1 jmespath-1.0.1 jsonnet-0.20.0 lmdb-1.4.1 pathlib-abc-0.1.1 pathtools-0.1.2 pathy-0.11.0 pydantic-1.8.2 rich-12.6.0 s3transfer-0.10.1 sacremoses-0.1.1 sentry-sdk-2.3.1 setproctitle-1.3.3 shortuuid-1.0.13 smmap-5.0.1 spacy-3.3.3 tensorboardX-2.6.2.2 termcolor-1.1.0 thinc-8.0.17 tokenizers-0.12.1 torch-1.12.1 torchvision-0.13.1 transformers-4.20.1 typer-0.4.2 typing-extensions-4.5.0 wandb-0.12.21 wasabi-0.10.1\n"
          ]
        }
      ],
      "source": [
        "!pip install allennlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iom7zG2J2mDT",
        "outputId": "8be3b61a-5f51-42dc-c83a-e637fdb8a39c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting overrides==3.1.0\n",
            "  Downloading overrides-3.1.0.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: overrides\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-3.1.0-py3-none-any.whl size=10171 sha256=a9ba8c78679ad9122a2899f5cbc6845c43390b4973928bc395c16dbd4348cdf9\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/23/63/4d5849844f8f9d32be09e1b9b278e80de2d8314fbf1e28068b\n",
            "Successfully built overrides\n",
            "Installing collected packages: overrides\n",
            "Successfully installed overrides-3.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install overrides==3.1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4YieSNQ3gfb",
        "outputId": "9a5b8d24-49f5-4a4a-830b-3863cbfaefa7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.3.3)\n",
            "Collecting spacy\n",
            "  Downloading spacy-3.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Collecting thinc<8.3.0,>=8.2.2 (from spacy)\n",
            "  Downloading thinc-8.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (922 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m922.3/922.3 kB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.25.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.1.1)\n",
            "Installing collected packages: thinc, spacy\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 8.0.17\n",
            "    Uninstalling thinc-8.0.17:\n",
            "      Successfully uninstalled thinc-8.0.17\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.3.3\n",
            "    Uninstalling spacy-3.3.3:\n",
            "      Successfully uninstalled spacy-3.3.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "allennlp 2.10.1 requires spacy<3.4,>=2.1.0, but you have spacy 3.7.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed spacy-3.7.4 thinc-8.2.3\n"
          ]
        }
      ],
      "source": [
        "!pip install spacy --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DmPMxIkj3XB",
        "outputId": "b74923af-4aa3-4c77-d0b8-72cb36995c65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.20.1)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.41.1-py3-none-any.whl (9.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.7.1)\n",
            "Collecting huggingface-hub<1.0,>=0.23.0 (from transformers)\n",
            "  Downloading huggingface_hub-0.23.2-py3-none-any.whl (401 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.7/401.7 kB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers<0.20,>=0.19 (from transformers)\n",
            "  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m88.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Installing collected packages: huggingface-hub, tokenizers, transformers\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.10.1\n",
            "    Uninstalling huggingface-hub-0.10.1:\n",
            "      Successfully uninstalled huggingface-hub-0.10.1\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.12.1\n",
            "    Uninstalling tokenizers-0.12.1:\n",
            "      Successfully uninstalled tokenizers-0.12.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.20.1\n",
            "    Uninstalling transformers-4.20.1:\n",
            "      Successfully uninstalled transformers-4.20.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "allennlp 2.10.1 requires spacy<3.4,>=2.1.0, but you have spacy 3.7.4 which is incompatible.\n",
            "allennlp 2.10.1 requires transformers<4.21,>=4.1, but you have transformers 4.41.1 which is incompatible.\n",
            "cached-path 1.1.6 requires huggingface-hub<0.11.0,>=0.8.1, but you have huggingface-hub 0.23.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed huggingface-hub-0.23.2 tokenizers-0.19.1 transformers-4.41.1\n"
          ]
        }
      ],
      "source": [
        "pip install --upgrade transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TF6qU-VMr80r",
        "outputId": "c93c4342-2751-4f8d-f360-6326a75c047e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (1.12.1)\n",
            "Collecting torch\n",
            "  Downloading torch-2.3.0-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.7.1)\n",
            "Collecting typing-extensions>=4.8.0 (from torch)\n",
            "  Downloading typing_extensions-4.12.0-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.40)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: typing-extensions, torch\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.12.1\n",
            "    Uninstalling torch-1.12.1:\n",
            "      Successfully uninstalled torch-1.12.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "allennlp 2.10.1 requires spacy<3.4,>=2.1.0, but you have spacy 3.7.4 which is incompatible.\n",
            "allennlp 2.10.1 requires torch<1.13.0,>=1.10.0, but you have torch 2.3.0 which is incompatible.\n",
            "allennlp 2.10.1 requires transformers<4.21,>=4.1, but you have transformers 4.41.1 which is incompatible.\n",
            "inflect 7.0.0 requires pydantic>=1.9.1, but you have pydantic 1.8.2 which is incompatible.\n",
            "torchvision 0.13.1 requires torch==1.12.1, but you have torch 2.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-2.3.0 typing-extensions-4.12.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torch --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUVsboLhN6Kg",
        "outputId": "0fdb3805-c6f0-47e1-84ed-69a99f7b53fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting vaderSentiment\n",
            "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/126.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from vaderSentiment) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (2024.2.2)\n",
            "Installing collected packages: vaderSentiment\n",
            "Successfully installed vaderSentiment-3.3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install vaderSentiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9145228381e84439ba69400afddf7f08",
            "732c39e18f00415cbfd6fa9ec7ba5e6c",
            "1d4852f01adb47d89c80dde7cbef242a",
            "c1650893cc094d67b300b2b6c96c0622",
            "b9f3655a0a2a408a84a15ee67f0f5703",
            "fc55967e05934297ba74488c1704ab6b",
            "b82f01b4885f4cac8eab2c7cce2df1ca",
            "aac59ab24c2f4f1b8a0daab4c81bb6ae",
            "018f8f95c2404f39a644a88e68fe2b4a",
            "6c20276d83554a73865bd7a2155ddf12",
            "b2ac30d5abc145e893c1c1f54033e4e7",
            "b99b97319aca426d9ac73e35732d0815",
            "6540cb0576bd430b9f193997be093800",
            "cbb403780c714069a34484114a36f49c",
            "877ff06916c447f3ad3ecaadc88d6efc",
            "10c0db1ab1e3446eb8e31ea0e3000584",
            "81822ecffe884dd8952c618f801dafdc",
            "ba02f1693d5b46e992d538194cb5794c",
            "f25e8bc4cd4148b39f185369f3514272",
            "1f92e1ced55f4029a759ba24eef086aa",
            "fe2d9fe6c4bc4cf4a3269fb6afa18d92",
            "3eb9bce2caa2434ba1f3522f96ab6132",
            "c38e040510d941afadd9b987194af2a6",
            "d998fd45599a4b01a4cbf3b541930e5f",
            "830613a567f3450c9d15078c31bb25b0",
            "d0b7fcf3a9a8481683e4f4e014599575",
            "03d24806d6c340c6816fc38b27d722fc",
            "4c5fa59228fd42a696deff6790e2e41b",
            "26056809ae1a4b51b1b7127758b03276",
            "26b9219106494f338379f71b02ead85b",
            "3ca1fde70c7f4b4782e516022c94cf0f",
            "cf865b83fdf04f81a8830e249afae2b9",
            "bddfbb10472a4707a3632def13a33ea5",
            "c06e4753558a4a249ea78759da57009d",
            "c2e1b32293ec4c94887e8053e358ff28",
            "3a3e4f98b82a42f6b579d6e5810b5bde",
            "4933c17d1fff4ebf976ac42c51ac40cd",
            "85741bf0fadf43b2a77a91ebb9bb1031",
            "b0eda42ccbd8410390ec297966a2207e",
            "2470d5f999484947b8302fc62577c08d",
            "2be3dffe33a14c43907096c8bde47902",
            "c807cab2a75e4883b58eda40c2a86e54",
            "1d03fac667a44bc19937c7821807917d",
            "ab4c899022c640d485f3b54e4580c296",
            "5b20119ec26b4ea28272e9418da45985",
            "537f30537edb4ce58418099110d45b04",
            "06525c39ddc4482ea4fd6197fa61cc46",
            "185faced2fc344cfbf5560ac260a04c9",
            "ba1b85c0c6b54b5a930030b6e19fe9d0",
            "3a6c2596ab8146bdb1153dcaf6db722f",
            "bfdf9294b5384a25905bdc1b7953265d",
            "afb6ca4d87554aaf844749c50537ccca",
            "0bd0af5aae6a483989081059e6b8e708",
            "0959676f5e8f498aa7d31d61505cfffc",
            "643286f983154a52b45a28f7381660a6"
          ]
        },
        "id": "6rCFJIKW0HNx",
        "outputId": "8ba31830-a478-454b-e9a4-66c972cfb196"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /usr/local/lib/python3.10/dist-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
            "  warn(f\"Failed to load image Python extension: {e}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA AVAILABILITY: True\n",
            "================= model settings ========================\n",
            "trainset file path:  train.csv\n",
            "heldout file path:  dev.csv\n",
            "evaluation set path:  test.csv\n",
            "post data dir:  mdl_HAN\n",
            "model file prefix:  training_test\n",
            "gpu device:  0\n",
            "num_epochs:  10\n",
            "max_post_size_option:  200\n",
            "============================================================\n",
            "================================ check current GPU usage =============================\n",
            "Wed May 29 17:41:48 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P8               9W /  70W |      3MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n",
            "\n",
            "======================================================================================\n",
            "training HAN on development dataset [train.csv] and [dev.csv] with gpu [0]\n",
            "post data directory is set to [mdl_HAN]\n",
            "model training in batches [size: 128]\n",
            "2024-05-29 17:41:48 :: start to train ExplainableDepressionDetection model with training set [train.csv] and dev set [dev.csv] with gpu [0] ... \n",
            "2024-05-29 17:41:48 :: the model will be evaluated with test set [test.csv]\n",
            "2024-05-29 17:41:48 :: training batch size: [128]\n",
            "2024-05-29 17:41:48 :: DepressionDataReader ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/__init__.py:747: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:431.)\n",
            "  _C._set_default_tensor_type(t)\n",
            "building vocab: 100%|##########| 3366/3366 [00:00<00:00, 835188.55it/s]\n",
            "loading instances: 2524it [00:00, 162465.64it/s]\n",
            "loading instances: 842it [00:00, 102258.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 17:41:49 :: DepressionDataReader ...\n",
            "2024-05-29 17:41:49 :: loading development dataset and indexing vocabulary  ... \n",
            "train.csv\n",
            "dev.csv\n",
            "train.csv\n",
            "dev.csv\n",
            "2024-05-29 17:41:49 :: done. datasets loaded and vocab indexed completely.\n",
            "2024-05-29 17:41:49 :: initialising ExplainableDepressionDetection model ... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 17:41:49 :: set fully-connected layer to leaky_relu+linear+linear with dropout (0.2, 0.3, 0.0)\n",
            "HELLO CURRENT CUDA DEVICE  cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9145228381e84439ba69400afddf7f08"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b99b97319aca426d9ac73e35732d0815"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c38e040510d941afadd9b987194af2a6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c06e4753558a4a249ea78759da57009d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5b20119ec26b4ea28272e9418da45985"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 17:41:57 :: maximum post sequence size is [200]\n",
            "2024-05-29 17:41:57 :: re-set attention1 with the new post sequence size\n",
            "2024-05-29 17:41:57 :: Total number of parameters in the model: 180351986\n",
            "2024-05-29 17:41:57 :: model architecture: \n",
            "DepressionClassifier(\n",
            "  (post_encoder): PytorchSeq2SeqWrapper(\n",
            "    (_module): LSTM(768, 1536, num_layers=2, batch_first=True)\n",
            "  )\n",
            "  (metaphor_encoder): PytorchSeq2SeqWrapper(\n",
            "    (_module): LSTM(768, 1536, num_layers=2, batch_first=True)\n",
            "  )\n",
            "  (classifier_feedforward): FeedForward(\n",
            "    (_activations): ModuleList(\n",
            "      (0): LeakyReLU(negative_slope=0.01)\n",
            "      (1-2): 2 x LinearActivation()\n",
            "    )\n",
            "    (_linear_layers): ModuleList(\n",
            "      (0-1): 2 x Linear(in_features=778, out_features=778, bias=True)\n",
            "      (2): Linear(in_features=778, out_features=2, bias=True)\n",
            "    )\n",
            "    (_dropout): ModuleList(\n",
            "      (0): Dropout(p=0.2, inplace=False)\n",
            "      (1-2): 2 x Dropout(p=0.3, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (loss_function): CrossEntropyLoss()\n",
            "  (embedding_model): BertModel(\n",
            "    (embeddings): BertEmbeddings(\n",
            "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "      (position_embeddings): Embedding(512, 768)\n",
            "      (token_type_embeddings): Embedding(2, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): BertEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0-11): 12 x BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSdpaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (pooler): BertPooler(\n",
            "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (activation): Tanh()\n",
            "    )\n",
            "  )\n",
            "  (HAN_1_tweet): HAN_block(\n",
            "    (att): ScaledDotProductAttention()\n",
            "    (linear_observer): Linear(in_features=768, out_features=768, bias=True)\n",
            "    (linear_matrix): Linear(in_features=768, out_features=768, bias=True)\n",
            "    (linear_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "    (activation): ReLU()\n",
            "    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "    (dropout): Dropout(p=0.2, inplace=False)\n",
            "  )\n",
            "  (HAN_2_tweet): HAN_block(\n",
            "    (att): ScaledDotProductAttention()\n",
            "    (linear_observer): Linear(in_features=768, out_features=768, bias=True)\n",
            "    (linear_matrix): Linear(in_features=768, out_features=768, bias=True)\n",
            "    (linear_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "    (activation): ReLU()\n",
            "    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "    (dropout): Dropout(p=0.2, inplace=False)\n",
            "  )\n",
            ")\n",
            "2024-05-29 17:41:57 :: done. ExplainableDepressionDetection model is initialised completely.\n",
            "2024-05-29 17:41:57 :: initialising optimiser and dataset iteractor ... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:allennlp.training.gradient_descent_trainer:You provided a validation dataset but patience was set to None, meaning that early stopping is disabled\n",
            "/usr/local/lib/python3.10/dist-packages/torch/cuda/memory.py:330: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
            "  warnings.warn(\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 17:41:57 :: done.\n",
            "2024-05-29 17:41:57 :: training starting now ... \n",
            "Hello, initialised!!\n",
            "2024-05-29 17:41:57 :: encode posts per user in batch ...\n",
            "2024-05-29 17:41:57 :: First two user ids in current batch: [20036788] and [126170676]\n",
            "load post data from dir:  mdl_HAN\n",
            "post_dataset_abs_path:  /content/mdl_HAN\n",
            "done.\n",
            "load post data from dir:  mdl_HAN\n",
            "post_dataset_abs_path:  /content/mdl_HAN\n",
            "done.\n",
            "called:  (1284, 768)\n",
            "called:  (840, 768)\n",
            "called:  (655, 768)\n",
            "called:  (376, 768)\n",
            "called:  (320, 768)\n",
            "called:  (385, 768)\n",
            "called:  (358, 768)\n",
            "2024-05-29 17:43:26 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 17:43:27 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 17:43:27 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 17:43:27 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 17:43:27 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 17:43:27 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.5757575631141663, 'recall': 0.30645161867141724, 'f1': 0.4000000059604645}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.5758, recall: 0.3065, f1: 0.4000, accuracy: 0.5547, batch_loss: 0.6900, loss: 0.6900 ||:   5%|5         | 1/20 [01:31<29:03, 91.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 17:43:29 :: encode posts per user in batch ...\n",
            "2024-05-29 17:43:29 :: First two user ids in current batch: [2741334519] and [67810480]\n",
            "called:  (232, 768)\n",
            "called:  (441, 768)\n",
            "called:  (249, 768)\n",
            "called:  (456, 768)\n",
            "called:  (208, 768)\n",
            "called:  (266, 768)\n",
            "called:  (569, 768)\n",
            "called:  (420, 768)\n",
            "called:  (325, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.5126, recall: 0.5041, f1: 0.5083, accuracy: 0.5391, batch_loss: 0.7063, loss: 0.6982 ||:  10%|#         | 2/20 [02:53<25:42, 85.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 17:44:50 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 17:44:50 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 17:44:50 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 17:44:50 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 17:44:50 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 17:44:50 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.5126050710678101, 'recall': 0.5041322112083435, 'f1': 0.5083333849906921}\n",
            "\n",
            "2024-05-29 17:44:50 :: encode posts per user in batch ...\n",
            "2024-05-29 17:44:50 :: First two user ids in current batch: [2159092987] and [16205293]\n",
            "called:  (804, 768)\n",
            "called:  (1096, 768)\n",
            "called:  (437, 768)\n",
            "called:  (267, 768)\n",
            "called:  (812, 768)\n",
            "called:  (229, 768)\n",
            "called:  (2317, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.5370, recall: 0.4652, f1: 0.4986, accuracy: 0.5443, batch_loss: 0.7121, loss: 0.7028 ||:  15%|#5        | 3/20 [04:55<28:57, 102.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 17:46:52 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 17:46:52 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 17:46:52 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 17:46:52 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 17:46:52 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 17:46:52 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.5370370149612427, 'recall': 0.46524062752723694, 'f1': 0.4985673129558563}\n",
            "\n",
            "2024-05-29 17:46:52 :: encode posts per user in batch ...\n",
            "2024-05-29 17:46:52 :: First two user ids in current batch: [446668784] and [3128084143]\n",
            "called:  (936, 768)\n",
            "called:  (616, 768)\n",
            "called:  (1012, 768)\n",
            "called:  (326, 768)\n",
            "called:  (1059, 768)\n",
            "called:  (299, 768)\n",
            "called:  (413, 768)\n",
            "called:  (328, 768)\n",
            "called:  (556, 768)\n",
            "called:  (551, 768)\n",
            "called:  (1025, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.5769, recall: 0.4781, f1: 0.5229, accuracy: 0.5723, batch_loss: 0.6471, loss: 0.6889 ||:  20%|##        | 4/20 [07:13<31:03, 116.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 17:49:10 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 17:49:10 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 17:49:10 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 17:49:10 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 17:49:10 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 17:49:10 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.5769230723381042, 'recall': 0.4780876636505127, 'f1': 0.5228757858276367}\n",
            "\n",
            "2024-05-29 17:49:11 :: encode posts per user in batch ...\n",
            "2024-05-29 17:49:11 :: First two user ids in current batch: [286426637] and [541321924]\n",
            "called:  (407, 768)\n",
            "called:  (263, 768)\n",
            "called:  (323, 768)\n",
            "called:  (259, 768)\n",
            "called:  (356, 768)\n",
            "called:  (1909, 768)\n",
            "called:  (618, 768)\n",
            "called:  (644, 768)\n",
            "called:  (850, 768)\n",
            "called:  (255, 768)\n",
            "called:  (1230, 768)\n",
            "called:  (539, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.5815, recall: 0.4968, f1: 0.5358, accuracy: 0.5750, batch_loss: 0.6645, loss: 0.6840 ||:  25%|##5       | 5/20 [09:21<30:08, 120.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 17:51:18 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 17:51:18 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 17:51:18 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 17:51:18 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 17:51:18 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 17:51:18 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.5814814567565918, 'recall': 0.4968354403972626, 'f1': 0.5358361005783081}\n",
            "\n",
            "2024-05-29 17:51:18 :: encode posts per user in batch ...\n",
            "2024-05-29 17:51:18 :: First two user ids in current batch: [348443844] and [2749624949]\n",
            "called:  (223, 768)\n",
            "called:  (388, 768)\n",
            "called:  (279, 768)\n",
            "called:  (527, 768)\n",
            "called:  (282, 768)\n",
            "called:  (950, 768)\n",
            "called:  (444, 768)\n",
            "called:  (535, 768)\n",
            "called:  (1567, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.5831, recall: 0.5195, f1: 0.5495, accuracy: 0.5729, batch_loss: 0.6382, loss: 0.6764 ||:  30%|###       | 6/20 [10:58<26:17, 112.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 17:52:56 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 17:52:56 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 17:52:56 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 17:52:56 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 17:52:56 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 17:52:56 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.5830903649330139, 'recall': 0.5194805264472961, 'f1': 0.5494505763053894}\n",
            "\n",
            "2024-05-29 17:52:56 :: encode posts per user in batch ...\n",
            "2024-05-29 17:52:56 :: First two user ids in current batch: [62072718] and [216063873]\n",
            "called:  (942, 768)\n",
            "called:  (1181, 768)\n",
            "called:  (826, 768)\n",
            "called:  (1772, 768)\n",
            "called:  (290, 768)\n",
            "called:  (1463, 768)\n",
            "called:  (236, 768)\n",
            "called:  (959, 768)\n",
            "called:  (222, 768)\n",
            "called:  (854, 768)\n",
            "called:  (288, 768)\n",
            "called:  (453, 768)\n",
            "called:  (288, 768)\n",
            "called:  (529, 768)\n",
            "called:  (2068, 768)\n",
            "called:  (468, 768)\n",
            "called:  (673, 768)\n",
            "called:  (465, 768)\n",
            "called:  (800, 768)\n",
            "called:  (420, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.5813, recall: 0.5268, f1: 0.5527, accuracy: 0.5737, batch_loss: 0.6863, loss: 0.6778 ||:  35%|###5      | 7/20 [15:10<34:17, 158.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 17:57:08 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 17:57:08 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 17:57:08 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 17:57:08 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 17:57:08 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 17:57:08 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.5812807679176331, 'recall': 0.5267857313156128, 'f1': 0.5526931881904602}\n",
            "\n",
            "2024-05-29 17:57:08 :: encode posts per user in batch ...\n",
            "2024-05-29 17:57:08 :: First two user ids in current batch: [471208685] and [1561702988]\n",
            "called:  (937, 768)\n",
            "called:  (397, 768)\n",
            "called:  (458, 768)\n",
            "called:  (235, 768)\n",
            "called:  (241, 768)\n",
            "called:  (600, 768)\n",
            "called:  (2298, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.5996, recall: 0.5310, f1: 0.5632, accuracy: 0.5850, batch_loss: 0.6352, loss: 0.6725 ||:  40%|####      | 8/20 [16:43<27:29, 137.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 17:58:41 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 17:58:41 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 17:58:41 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 17:58:41 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 17:58:41 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 17:58:41 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.5995623469352722, 'recall': 0.5310077667236328, 'f1': 0.5632065534591675}\n",
            "\n",
            "2024-05-29 17:58:41 :: encode posts per user in batch ...\n",
            "2024-05-29 17:58:41 :: First two user ids in current batch: [2556774854] and [790111668588060672]\n",
            "called:  (524, 768)\n",
            "called:  (517, 768)\n",
            "called:  (458, 768)\n",
            "called:  (861, 768)\n",
            "called:  (439, 768)\n",
            "called:  (371, 768)\n",
            "called:  (784, 768)\n",
            "called:  (337, 768)\n",
            "called:  (430, 768)\n",
            "called:  (651, 768)\n",
            "called:  (1362, 768)\n",
            "called:  (231, 768)\n",
            "called:  (627, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.6190, recall: 0.5461, f1: 0.5802, accuracy: 0.5981, batch_loss: 0.5906, loss: 0.6634 ||:  45%|####5     | 9/20 [19:01<25:14, 137.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 18:00:59 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 18:00:59 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:00:59 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 18:00:59 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:00:59 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:00:59 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.6189554929733276, 'recall': 0.5460751056671143, 'f1': 0.5802357196807861}\n",
            "\n",
            "2024-05-29 18:00:59 :: encode posts per user in batch ...\n",
            "2024-05-29 18:00:59 :: First two user ids in current batch: [2847009577] and [3395626274]\n",
            "called:  (410, 768)\n",
            "called:  (383, 768)\n",
            "called:  (634, 768)\n",
            "called:  (389, 768)\n",
            "called:  (336, 768)\n",
            "called:  (692, 768)\n",
            "called:  (830, 768)\n",
            "called:  (254, 768)\n",
            "called:  (294, 768)\n",
            "called:  (263, 768)\n",
            "called:  (412, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.6418, recall: 0.5710, f1: 0.6043, accuracy: 0.6133, batch_loss: 0.5506, loss: 0.6521 ||:  50%|#####     | 10/20 [20:36<20:42, 124.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 18:02:33 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 18:02:33 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:02:33 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 18:02:33 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:02:33 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:02:33 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.6417657136917114, 'recall': 0.5709969997406006, 'f1': 0.6043165326118469}\n",
            "\n",
            "2024-05-29 18:02:33 :: encode posts per user in batch ...\n",
            "2024-05-29 18:02:33 :: First two user ids in current batch: [160478571] and [615471554]\n",
            "called:  (706, 768)\n",
            "called:  (335, 768)\n",
            "called:  (326, 768)\n",
            "called:  (352, 768)\n",
            "called:  (2189, 768)\n",
            "called:  (1237, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.6582, recall: 0.5965, f1: 0.6258, accuracy: 0.6271, batch_loss: 0.5426, loss: 0.6421 ||:  55%|#####5    | 11/20 [22:10<17:16, 115.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 18:04:08 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 18:04:08 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:04:08 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 18:04:08 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:04:08 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:04:08 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.6581709384918213, 'recall': 0.5964673757553101, 'f1': 0.6258018612861633}\n",
            "\n",
            "2024-05-29 18:04:08 :: encode posts per user in batch ...\n",
            "2024-05-29 18:04:08 :: First two user ids in current batch: [1388907403] and [4750884312]\n",
            "called:  (313, 768)\n",
            "called:  (482, 768)\n",
            "called:  (822, 768)\n",
            "called:  (900, 768)\n",
            "called:  (276, 768)\n",
            "called:  (226, 768)\n",
            "called:  (283, 768)\n",
            "called:  (2037, 768)\n",
            "called:  (1230, 768)\n",
            "called:  (228, 768)\n",
            "called:  (493, 768)\n",
            "called:  (216, 768)\n",
            "called:  (1560, 768)\n",
            "called:  (514, 768)\n",
            "called:  (207, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.6676, recall: 0.6179, f1: 0.6418, accuracy: 0.6380, batch_loss: 0.5119, loss: 0.6313 ||:  60%|######    | 12/20 [24:47<17:03, 127.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 18:06:45 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 18:06:45 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:06:45 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 18:06:45 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:06:45 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:06:45 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.667560338973999, 'recall': 0.6178659796714783, 'f1': 0.6417525410652161}\n",
            "\n",
            "2024-05-29 18:06:45 :: encode posts per user in batch ...\n",
            "2024-05-29 18:06:45 :: First two user ids in current batch: [1248740485] and [792931958]\n",
            "called:  (632, 768)\n",
            "called:  (1543, 768)\n",
            "called:  (254, 768)\n",
            "called:  (262, 768)\n",
            "called:  (515, 768)\n",
            "called:  (389, 768)\n",
            "called:  (451, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.6785, recall: 0.6342, f1: 0.6556, accuracy: 0.6508, batch_loss: 0.4658, loss: 0.6186 ||:  65%|######5   | 13/20 [26:02<13:03, 111.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 18:08:00 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 18:08:00 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:08:00 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 18:08:00 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:08:00 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:08:00 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.6785275936126709, 'recall': 0.6341742873191833, 'f1': 0.6556016206741333}\n",
            "\n",
            "2024-05-29 18:08:00 :: encode posts per user in batch ...\n",
            "2024-05-29 18:08:00 :: First two user ids in current batch: [18789726] and [376025371]\n",
            "called:  (222, 768)\n",
            "called:  (1065, 768)\n",
            "called:  (573, 768)\n",
            "called:  (2042, 768)\n",
            "called:  (464, 768)\n",
            "called:  (216, 768)\n",
            "called:  (499, 768)\n",
            "called:  (297, 768)\n",
            "called:  (269, 768)\n",
            "called:  (237, 768)\n",
            "called:  (377, 768)\n",
            "called:  (338, 768)\n",
            "called:  (2062, 768)\n",
            "called:  (286, 768)\n",
            "called:  (201, 768)\n",
            "called:  (716, 768)\n",
            "called:  (304, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.6888, recall: 0.6521, f1: 0.6700, accuracy: 0.6641, batch_loss: 0.4393, loss: 0.6057 ||:  70%|#######   | 14/20 [29:01<13:12, 132.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 18:10:59 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 18:10:59 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:10:59 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 18:10:59 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:10:59 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:10:59 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.6888387799263, 'recall': 0.6520811319351196, 'f1': 0.6699561476707458}\n",
            "\n",
            "2024-05-29 18:10:59 :: encode posts per user in batch ...\n",
            "2024-05-29 18:10:59 :: First two user ids in current batch: [2904189462] and [49245292]\n",
            "called:  (1572, 768)\n",
            "called:  (257, 768)\n",
            "called:  (320, 768)\n",
            "called:  (498, 768)\n",
            "called:  (207, 768)\n",
            "called:  (360, 768)\n",
            "called:  (283, 768)\n",
            "called:  (947, 768)\n",
            "called:  (520, 768)\n",
            "called:  (323, 768)\n",
            "called:  (641, 768)\n",
            "called:  (1270, 768)\n",
            "called:  (220, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.7005, recall: 0.6600, f1: 0.6797, accuracy: 0.6750, batch_loss: 0.3663, loss: 0.5898 ||:  75%|#######5  | 15/20 [31:10<10:56, 131.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 18:13:08 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 18:13:08 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:13:08 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 18:13:08 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:13:08 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:13:08 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.7005290985107422, 'recall': 0.6600199341773987, 'f1': 0.6796715259552002}\n",
            "\n",
            "2024-05-29 18:13:08 :: encode posts per user in batch ...\n",
            "2024-05-29 18:13:08 :: First two user ids in current batch: [1347790417] and [89280386]\n",
            "called:  (598, 768)\n",
            "called:  (831, 768)\n",
            "called:  (329, 768)\n",
            "called:  (244, 768)\n",
            "called:  (914, 768)\n",
            "called:  (225, 768)\n",
            "called:  (541, 768)\n",
            "called:  (523, 768)\n",
            "called:  (259, 768)\n",
            "called:  (555, 768)\n",
            "called:  (296, 768)\n",
            "called:  (483, 768)\n",
            "called:  (786, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.7103, recall: 0.6692, f1: 0.6891, accuracy: 0.6846, batch_loss: 0.3787, loss: 0.5766 ||:  80%|########  | 16/20 [33:15<08:36, 129.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 18:15:13 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 18:15:13 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:15:13 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 18:15:13 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:15:13 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:15:13 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.7103174328804016, 'recall': 0.6691588759422302, 'f1': 0.6891241669654846}\n",
            "\n",
            "2024-05-29 18:15:13 :: encode posts per user in batch ...\n",
            "2024-05-29 18:15:13 :: First two user ids in current batch: [1286880470] and [2827666793]\n",
            "called:  (1983, 768)\n",
            "called:  (279, 768)\n",
            "called:  (233, 768)\n",
            "called:  (230, 768)\n",
            "called:  (1638, 768)\n",
            "called:  (373, 768)\n",
            "called:  (942, 768)\n",
            "called:  (1103, 768)\n",
            "called:  (477, 768)\n",
            "called:  (1601, 768)\n",
            "called:  (685, 768)\n",
            "called:  (390, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.7162, recall: 0.6794, f1: 0.6973, accuracy: 0.6939, batch_loss: 0.4067, loss: 0.5666 ||:  85%|########5 | 17/20 [36:02<07:01, 140.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 18:17:59 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 18:17:59 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:17:59 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 18:17:59 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:17:59 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:17:59 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.7161531448364258, 'recall': 0.6793622970581055, 'f1': 0.6972727179527283}\n",
            "\n",
            "2024-05-29 18:18:00 :: encode posts per user in batch ...\n",
            "2024-05-29 18:18:00 :: First two user ids in current batch: [410260914] and [60189637]\n",
            "called:  (511, 768)\n",
            "called:  (426, 768)\n",
            "called:  (464, 768)\n",
            "called:  (795, 768)\n",
            "called:  (835, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.7239, recall: 0.6891, f1: 0.7061, accuracy: 0.7044, batch_loss: 0.2412, loss: 0.5485 ||:  90%|######### | 18/20 [37:13<03:59, 119.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 18:19:10 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 18:19:10 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:19:10 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 18:19:10 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:19:10 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:19:10 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.7238938212394714, 'recall': 0.6891322731971741, 'f1': 0.7060855031013489}\n",
            "\n",
            "2024-05-29 18:19:11 :: encode posts per user in batch ...\n",
            "2024-05-29 18:19:11 :: First two user ids in current batch: [271703104] and [268452328]\n",
            "called:  (2668, 768)\n",
            "called:  (464, 768)\n",
            "called:  (622, 768)\n",
            "called:  (231, 768)\n",
            "called:  (213, 768)\n",
            "called:  (376, 768)\n",
            "called:  (413, 768)\n",
            "called:  (493, 768)\n",
            "called:  (503, 768)\n",
            "called:  (332, 768)\n",
            "called:  (284, 768)\n",
            "called:  (2116, 768)\n",
            "called:  (383, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.7330, recall: 0.7001, f1: 0.7162, accuracy: 0.7155, batch_loss: 0.2396, loss: 0.5323 ||:  95%|#########5| 19/20 [39:48<02:10, 130.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 18:21:46 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 18:21:46 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:21:46 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 18:21:46 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:21:46 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:21:46 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.732997477054596, 'recall': 0.7000802159309387, 'f1': 0.716160774230957}\n",
            "\n",
            "2024-05-29 18:21:46 :: encode posts per user in batch ...\n",
            "2024-05-29 18:21:46 :: First two user ids in current batch: [2670304187] and [2511600542]\n",
            "called:  (347, 768)\n",
            "called:  (610, 768)\n",
            "called:  (1594, 768)\n",
            "called:  (323, 768)\n",
            "called:  (2534, 768)\n",
            "called:  (553, 768)\n",
            "called:  (294, 768)\n",
            "called:  (262, 768)\n",
            "called:  (280, 768)\n",
            "called:  (206, 768)\n",
            "called:  (326, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "precision: 0.7381, recall: 0.7073, f1: 0.7224, accuracy: 0.7211, batch_loss: 0.2728, loss: 0.5193 ||: 100%|##########| 20/20 [41:49<00:00, 125.49s/it]\n",
            "  0%|          | 0/7 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 18:23:47 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 18:23:47 :: tensor size after padding: torch.Size([92, 200, 768])\n",
            "2024-05-29 18:23:47 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([92, 200, 768])]\n",
            "2024-05-29 18:23:47 :: post masking: content [torch.Size([92, 200])]\n",
            "new tenor size: torch.Size([92, 200, 768])\n",
            "2024-05-29 18:23:47 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([92, 200, 768])\n",
            "2024-05-29 18:23:47 :: post reprsentation shape : torch.Size([92, 768])\n",
            "{'precision': 0.7381144165992737, 'recall': 0.707335889339447, 'f1': 0.72239750623703}\n",
            "\n",
            "{'precision': 0.7381144165992737, 'recall': 0.707335889339447, 'f1': 0.72239750623703}\n",
            "\n",
            "2024-05-29 18:23:47 :: encode posts per user in batch ...\n",
            "2024-05-29 18:23:47 :: First two user ids in current batch: [904613676] and [404244193]\n",
            "called:  (251, 768)\n",
            "called:  (772, 768)\n",
            "called:  (242, 768)\n",
            "called:  (212, 768)\n",
            "called:  (1276, 768)\n",
            "called:  (874, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9265, recall: 1.0000, f1: 0.9618, accuracy: 0.9609, batch_loss: 0.1045, loss: 0.1045 ||:  14%|#4        | 1/7 [01:04<06:25, 64.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 18:24:51 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 18:24:51 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:24:51 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 18:24:51 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:24:51 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:24:51 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9264705777168274, 'recall': 1.0, 'f1': 0.9618321061134338}\n",
            "\n",
            "2024-05-29 18:24:51 :: encode posts per user in batch ...\n",
            "2024-05-29 18:24:51 :: First two user ids in current batch: [2980729907] and [2846269209]\n",
            "called:  (666, 768)\n",
            "called:  (265, 768)\n",
            "called:  (309, 768)\n",
            "called:  (1923, 768)\n",
            "called:  (2606, 768)\n",
            "called:  (232, 768)\n",
            "called:  (431, 768)\n",
            "called:  (523, 768)\n",
            "called:  (226, 768)\n",
            "called:  (201, 768)\n",
            "called:  (207, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9197, recall: 1.0000, f1: 0.9582, accuracy: 0.9570, batch_loss: 0.1167, loss: 0.1106 ||:  29%|##8       | 2/7 [03:10<08:22, 100.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 18:26:57 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 18:26:57 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:26:57 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 18:26:57 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:26:57 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:26:57 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9197080135345459, 'recall': 1.0, 'f1': 0.9581748843193054}\n",
            "\n",
            "2024-05-29 18:26:57 :: encode posts per user in batch ...\n",
            "2024-05-29 18:26:57 :: First two user ids in current batch: [2614000926] and [2338341656]\n",
            "called:  (215, 768)\n",
            "called:  (285, 768)\n",
            "called:  (216, 768)\n",
            "called:  (297, 768)\n",
            "called:  (985, 768)\n",
            "called:  (310, 768)\n",
            "called:  (449, 768)\n",
            "called:  (246, 768)\n",
            "called:  (1604, 768)\n",
            "called:  (207, 768)\n",
            "called:  (226, 768)\n",
            "called:  (1078, 768)\n",
            "called:  (371, 768)\n",
            "called:  (932, 768)\n",
            "called:  (608, 768)\n",
            "called:  (507, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9037, recall: 1.0000, f1: 0.9494, accuracy: 0.9453, batch_loss: 0.1543, loss: 0.1252 ||:  43%|####2     | 3/7 [05:27<07:49, 117.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 18:29:14 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 18:29:14 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:29:14 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 18:29:14 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:29:14 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:29:14 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9036697149276733, 'recall': 1.0, 'f1': 0.9493975639343262}\n",
            "\n",
            "2024-05-29 18:29:14 :: encode posts per user in batch ...\n",
            "2024-05-29 18:29:14 :: First two user ids in current batch: [37499488] and [762927001]\n",
            "called:  (302, 768)\n",
            "called:  (223, 768)\n",
            "called:  (269, 768)\n",
            "called:  (2229, 768)\n",
            "called:  (401, 768)\n",
            "called:  (214, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9085, recall: 0.9926, f1: 0.9487, accuracy: 0.9434, batch_loss: 0.1335, loss: 0.1273 ||:  57%|#####7    | 4/7 [06:38<04:56, 98.98s/it] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 18:30:25 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 18:30:25 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:30:25 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 18:30:25 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:30:25 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:30:25 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9084745645523071, 'recall': 0.9925925731658936, 'f1': 0.9486725330352783}\n",
            "\n",
            "2024-05-29 18:30:25 :: encode posts per user in batch ...\n",
            "2024-05-29 18:30:25 :: First two user ids in current batch: [4333099131] and [14583151]\n",
            "called:  (351, 768)\n",
            "called:  (303, 768)\n",
            "called:  (1122, 768)\n",
            "called:  (1008, 768)\n",
            "called:  (249, 768)\n",
            "called:  (366, 768)\n",
            "called:  (1477, 768)\n",
            "called:  (324, 768)\n",
            "called:  (292, 768)\n",
            "called:  (421, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9123, recall: 0.9940, f1: 0.9514, accuracy: 0.9469, batch_loss: 0.0966, loss: 0.1211 ||:  71%|#######1  | 5/7 [08:18<03:18, 99.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 18:32:05 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 18:32:05 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:32:05 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 18:32:05 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:32:05 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:32:05 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9123287796974182, 'recall': 0.9940298795700073, 'f1': 0.9514285326004028}\n",
            "\n",
            "2024-05-29 18:32:05 :: encode posts per user in batch ...\n",
            "2024-05-29 18:32:05 :: First two user ids in current batch: [2495337330] and [712175472]\n",
            "called:  (241, 768)\n",
            "called:  (522, 768)\n",
            "called:  (336, 768)\n",
            "called:  (236, 768)\n",
            "called:  (318, 768)\n",
            "called:  (218, 768)\n",
            "called:  (222, 768)\n",
            "called:  (289, 768)\n",
            "called:  (440, 768)\n",
            "called:  (751, 768)\n",
            "called:  (352, 768)\n",
            "called:  (1311, 768)\n",
            "called:  (232, 768)\n",
            "called:  (348, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9167, recall: 0.9950, f1: 0.9542, accuracy: 0.9505, batch_loss: 0.1049, loss: 0.1184 ||:  86%|########5 | 6/7 [09:59<01:39, 99.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 18:33:46 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 18:33:46 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:33:46 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 18:33:46 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:33:46 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:33:46 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9166666865348816, 'recall': 0.9949748516082764, 'f1': 0.9542168378829956}\n",
            "\n",
            "2024-05-29 18:33:46 :: encode posts per user in batch ...\n",
            "2024-05-29 18:33:46 :: First two user ids in current batch: [2647458960] and [242941732]\n",
            "called:  (1194, 768)\n",
            "called:  (219, 768)\n",
            "called:  (989, 768)\n",
            "called:  (329, 768)\n",
            "called:  (283, 768)\n",
            "called:  (947, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "precision: 0.9168, recall: 0.9954, f1: 0.9545, accuracy: 0.9513, batch_loss: 0.0998, loss: 0.1158 ||: 100%|##########| 7/7 [10:58<00:00, 94.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 18:34:45 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 18:34:45 :: tensor size after padding: torch.Size([74, 200, 768])\n",
            "2024-05-29 18:34:45 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([74, 200, 768])]\n",
            "2024-05-29 18:34:45 :: post masking: content [torch.Size([74, 200])]\n",
            "new tenor size: torch.Size([74, 200, 768])\n",
            "2024-05-29 18:34:45 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([74, 200, 768])\n",
            "2024-05-29 18:34:45 :: post reprsentation shape : torch.Size([74, 768])\n",
            "{'precision': 0.916844367980957, 'recall': 0.9953703880310059, 'f1': 0.9544950127601624}\n",
            "\n",
            "{'precision': 0.916844367980957, 'recall': 0.9953703880310059, 'f1': 0.9544950127601624}\n",
            "\n",
            "Metrics at the end of epoch: 0 {'best_epoch': 0, 'peak_worker_0_memory_MB': 1742.69921875, 'peak_gpu_0_memory_MB': 814.828125, 'training_duration': '0:52:48.085518', 'epoch': 0, 'training_precision': 0.7381144165992737, 'training_recall': 0.707335889339447, 'training_f1': 0.72239750623703, 'training_accuracy': 0.7210776545166403, 'training_loss': 0.519289817661047, 'training_worker_0_memory_MB': 1742.69921875, 'training_gpu_0_memory_MB': 814.828125, 'validation_precision': 0.916844367980957, 'validation_recall': 0.9953703880310059, 'validation_f1': 0.9544950127601624, 'validation_accuracy': 0.9513064133016627, 'validation_loss': 0.11576131944145475, 'best_validation_precision': 0.916844367980957, 'best_validation_recall': 0.9953703880310059, 'best_validation_f1': 0.9544950127601624, 'best_validation_accuracy': 0.9513064133016627, 'best_validation_loss': 0.11576131944145475}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/cuda/memory.py:330: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
            "  warnings.warn(\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 18:34:46 :: encode posts per user in batch ...\n",
            "2024-05-29 18:34:46 :: First two user ids in current batch: [2428303988] and [1029337302]\n",
            "called:  (2037, 768)\n",
            "called:  (325, 768)\n",
            "called:  (383, 768)\n",
            "called:  (515, 768)\n",
            "called:  (441, 768)\n",
            "called:  (279, 768)\n",
            "called:  (812, 768)\n",
            "called:  (235, 768)\n",
            "called:  (493, 768)\n",
            "called:  (279, 768)\n",
            "called:  (2317, 768)\n",
            "called:  (326, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.8814, recall: 0.8814, f1: 0.8814, accuracy: 0.8906, batch_loss: 0.2007, loss: 0.2007 ||:   5%|5         | 1/20 [02:22<45:05, 142.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 18:37:09 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 18:37:09 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:37:09 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 18:37:09 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:37:09 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:37:09 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.8813559412956238, 'recall': 0.8813559412956238, 'f1': 0.8813559412956238}\n",
            "\n",
            "2024-05-29 18:37:09 :: encode posts per user in batch ...\n",
            "2024-05-29 18:37:09 :: First two user ids in current batch: [15173851] and [2423855642]\n",
            "called:  (556, 768)\n",
            "called:  (800, 768)\n",
            "called:  (644, 768)\n",
            "called:  (716, 768)\n",
            "called:  (254, 768)\n",
            "called:  (213, 768)\n",
            "called:  (263, 768)\n",
            "called:  (706, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9370, recall: 0.8947, f1: 0.9154, accuracy: 0.9141, batch_loss: 0.1943, loss: 0.1975 ||:  10%|#         | 2/20 [03:55<33:56, 113.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 18:38:41 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 18:38:41 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:38:41 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 18:38:41 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:38:41 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:38:41 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9370078444480896, 'recall': 0.8947368264198303, 'f1': 0.9153845906257629}\n",
            "\n",
            "2024-05-29 18:38:42 :: encode posts per user in batch ...\n",
            "2024-05-29 18:38:42 :: First two user ids in current batch: [192651677] and [2862168354]\n",
            "called:  (1983, 768)\n",
            "called:  (208, 768)\n",
            "called:  (222, 768)\n",
            "called:  (356, 768)\n",
            "called:  (437, 768)\n",
            "called:  (231, 768)\n",
            "called:  (430, 768)\n",
            "called:  (2534, 768)\n",
            "called:  (598, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9421, recall: 0.8905, f1: 0.9156, accuracy: 0.9141, batch_loss: 0.2031, loss: 0.1994 ||:  15%|#5        | 3/20 [05:54<32:49, 115.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 18:40:41 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 18:40:41 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:40:41 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 18:40:41 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:40:41 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:40:41 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.942105233669281, 'recall': 0.8905472755432129, 'f1': 0.9156010150909424}\n",
            "\n",
            "2024-05-29 18:40:41 :: encode posts per user in batch ...\n",
            "2024-05-29 18:40:41 :: First two user ids in current batch: [741802180462530560] and [3069326950]\n",
            "called:  (280, 768)\n",
            "called:  (383, 768)\n",
            "called:  (226, 768)\n",
            "called:  (937, 768)\n",
            "called:  (482, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9488, recall: 0.8926, f1: 0.9198, accuracy: 0.9180, batch_loss: 0.1473, loss: 0.1863 ||:  20%|##        | 4/20 [06:47<24:17, 91.10s/it] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 18:41:34 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 18:41:34 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:41:34 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 18:41:34 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:41:34 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:41:34 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9488189220428467, 'recall': 0.8925926089286804, 'f1': 0.919847309589386}\n",
            "\n",
            "2024-05-29 18:41:34 :: encode posts per user in batch ...\n",
            "2024-05-29 18:41:34 :: First two user ids in current batch: [2876499075] and [559763818]\n",
            "called:  (2668, 768)\n",
            "called:  (634, 768)\n",
            "called:  (622, 768)\n",
            "called:  (610, 768)\n",
            "called:  (225, 768)\n",
            "called:  (360, 768)\n",
            "called:  (535, 768)\n",
            "called:  (1230, 768)\n",
            "called:  (266, 768)\n",
            "called:  (523, 768)\n",
            "called:  (284, 768)\n",
            "called:  (207, 768)\n",
            "called:  (313, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9436, recall: 0.8853, f1: 0.9135, accuracy: 0.9109, batch_loss: 0.1845, loss: 0.1860 ||:  25%|##5       | 5/20 [09:11<27:34, 110.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 18:43:58 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 18:43:58 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:43:58 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 18:43:58 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:43:58 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:43:58 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9435736536979675, 'recall': 0.8852941393852234, 'f1': 0.9135053157806396}\n",
            "\n",
            "2024-05-29 18:43:58 :: encode posts per user in batch ...\n",
            "2024-05-29 18:43:58 :: First two user ids in current batch: [2796087290] and [254304033]\n",
            "called:  (1230, 768)\n",
            "called:  (338, 768)\n",
            "called:  (655, 768)\n",
            "called:  (514, 768)\n",
            "called:  (201, 768)\n",
            "called:  (464, 768)\n",
            "called:  (942, 768)\n",
            "called:  (651, 768)\n",
            "called:  (282, 768)\n",
            "called:  (439, 768)\n",
            "called:  (249, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9476, recall: 0.8786, f1: 0.9118, accuracy: 0.9089, batch_loss: 0.1495, loss: 0.1799 ||:  30%|###       | 6/20 [11:02<25:47, 110.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 18:45:49 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 18:45:49 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:45:49 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 18:45:49 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:45:49 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:45:49 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9476439952850342, 'recall': 0.8786407709121704, 'f1': 0.9118387699127197}\n",
            "\n",
            "2024-05-29 18:45:49 :: encode posts per user in batch ...\n",
            "2024-05-29 18:45:49 :: First two user ids in current batch: [2217957470] and [538583166]\n",
            "called:  (2042, 768)\n",
            "called:  (786, 768)\n",
            "called:  (2068, 768)\n",
            "called:  (1567, 768)\n",
            "called:  (529, 768)\n",
            "called:  (947, 768)\n",
            "called:  (468, 768)\n",
            "called:  (1096, 768)\n",
            "called:  (389, 768)\n",
            "called:  (784, 768)\n",
            "called:  (207, 768)\n",
            "called:  (332, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9555, recall: 0.8773, f1: 0.9147, accuracy: 0.9107, batch_loss: 0.1302, loss: 0.1728 ||:  35%|###5      | 7/20 [14:08<29:15, 135.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 18:48:54 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 18:48:54 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:48:54 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 18:48:54 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:48:54 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:48:54 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.955456554889679, 'recall': 0.8773006200790405, 'f1': 0.914712131023407}\n",
            "\n",
            "2024-05-29 18:48:55 :: encode posts per user in batch ...\n",
            "2024-05-29 18:48:55 :: First two user ids in current batch: [18602793] and [583962278]\n",
            "called:  (1572, 768)\n",
            "called:  (900, 768)\n",
            "called:  (498, 768)\n",
            "called:  (2062, 768)\n",
            "called:  (283, 768)\n",
            "called:  (352, 768)\n",
            "called:  (377, 768)\n",
            "called:  (914, 768)\n",
            "called:  (1237, 768)\n",
            "called:  (255, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9543, recall: 0.8775, f1: 0.9143, accuracy: 0.9121, batch_loss: 0.1575, loss: 0.1709 ||:  40%|####      | 8/20 [16:32<27:34, 137.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 18:51:18 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 18:51:18 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:51:18 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 18:51:18 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:51:18 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:51:18 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9542743563652039, 'recall': 0.8775137066841125, 'f1': 0.9142857193946838}\n",
            "\n",
            "2024-05-29 18:51:19 :: encode posts per user in batch ...\n",
            "2024-05-29 18:51:19 :: First two user ids in current batch: [3078785295] and [391715234]\n",
            "called:  (1025, 768)\n",
            "called:  (456, 768)\n",
            "called:  (1012, 768)\n",
            "called:  (241, 768)\n",
            "called:  (410, 768)\n",
            "called:  (641, 768)\n",
            "called:  (483, 768)\n",
            "called:  (323, 768)\n",
            "called:  (230, 768)\n",
            "called:  (551, 768)\n",
            "called:  (822, 768)\n",
            "called:  (1284, 768)\n",
            "called:  (257, 768)\n",
            "called:  (323, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9575, recall: 0.8811, f1: 0.9177, accuracy: 0.9158, batch_loss: 0.1279, loss: 0.1661 ||:  45%|####5     | 9/20 [18:51<25:23, 138.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 18:53:38 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 18:53:38 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:53:38 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 18:53:38 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:53:38 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:53:38 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9575220942497253, 'recall': 0.8811075091362, 'f1': 0.9177268743515015}\n",
            "\n",
            "2024-05-29 18:53:38 :: encode posts per user in batch ...\n",
            "2024-05-29 18:53:38 :: First two user ids in current batch: [98515559] and [2617094568]\n",
            "called:  (861, 768)\n",
            "called:  (267, 768)\n",
            "called:  (458, 768)\n",
            "called:  (328, 768)\n",
            "called:  (632, 768)\n",
            "called:  (304, 768)\n",
            "called:  (444, 768)\n",
            "called:  (220, 768)\n",
            "called:  (420, 768)\n",
            "called:  (1594, 768)\n",
            "called:  (385, 768)\n",
            "called:  (451, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9601, recall: 0.8853, f1: 0.9212, accuracy: 0.9195, batch_loss: 0.1177, loss: 0.1613 ||:  50%|#####     | 10/20 [20:46<21:52, 131.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 18:55:33 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 18:55:33 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:55:33 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 18:55:33 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:55:33 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:55:33 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.960127592086792, 'recall': 0.8852941393852234, 'f1': 0.921193540096283}\n",
            "\n",
            "2024-05-29 18:55:33 :: encode posts per user in batch ...\n",
            "2024-05-29 18:55:33 :: First two user ids in current batch: [800763867852783616] and [563144075]\n",
            "called:  (453, 768)\n",
            "called:  (685, 768)\n",
            "called:  (297, 768)\n",
            "called:  (959, 768)\n",
            "called:  (288, 768)\n",
            "called:  (520, 768)\n",
            "called:  (2189, 768)\n",
            "called:  (464, 768)\n",
            "called:  (347, 768)\n",
            "called:  (795, 768)\n",
            "called:  (294, 768)\n",
            "called:  (373, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9640, recall: 0.8861, f1: 0.9234, accuracy: 0.9212, batch_loss: 0.1187, loss: 0.1574 ||:  55%|#####5    | 11/20 [23:07<20:05, 133.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 18:57:53 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 18:57:53 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:57:53 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 18:57:53 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:57:53 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:57:53 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9639769196510315, 'recall': 0.8860927224159241, 'f1': 0.9233954548835754}\n",
            "\n",
            "2024-05-29 18:57:54 :: encode posts per user in batch ...\n",
            "2024-05-29 18:57:54 :: First two user ids in current batch: [1302230832] and [1974176420]\n",
            "called:  (1103, 768)\n",
            "called:  (296, 768)\n",
            "called:  (358, 768)\n",
            "called:  (236, 768)\n",
            "called:  (420, 768)\n",
            "called:  (389, 768)\n",
            "called:  (555, 768)\n",
            "called:  (2116, 768)\n",
            "called:  (835, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9657, recall: 0.8882, f1: 0.9253, accuracy: 0.9232, batch_loss: 0.1804, loss: 0.1593 ||:  60%|######    | 12/20 [25:01<17:03, 127.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 18:59:48 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 18:59:48 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:59:48 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 18:59:48 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:59:48 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 18:59:48 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9656538963317871, 'recall': 0.8882138729095459, 'f1': 0.9253165125846863}\n",
            "\n",
            "2024-05-29 18:59:48 :: encode posts per user in batch ...\n",
            "2024-05-29 18:59:48 :: First two user ids in current batch: [777045150983782400] and [3124575371]\n",
            "called:  (259, 768)\n",
            "called:  (413, 768)\n",
            "called:  (426, 768)\n",
            "called:  (850, 768)\n",
            "called:  (511, 768)\n",
            "called:  (326, 768)\n",
            "called:  (539, 768)\n",
            "called:  (232, 768)\n",
            "called:  (276, 768)\n",
            "called:  (840, 768)\n",
            "called:  (2298, 768)\n",
            "called:  (600, 768)\n",
            "called:  (541, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9680, recall: 0.8843, f1: 0.9243, accuracy: 0.9225, batch_loss: 0.1715, loss: 0.1602 ||:  65%|######5   | 13/20 [27:19<15:16, 130.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 19:02:06 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 19:02:06 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:02:06 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 19:02:06 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:02:06 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:02:06 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9680196642875671, 'recall': 0.884269654750824, 'f1': 0.9242513179779053}\n",
            "\n",
            "2024-05-29 19:02:06 :: encode posts per user in batch ...\n",
            "2024-05-29 19:02:06 :: First two user ids in current batch: [2431273993] and [4750884312]\n",
            "called:  (376, 768)\n",
            "called:  (493, 768)\n",
            "called:  (388, 768)\n",
            "called:  (290, 768)\n",
            "called:  (499, 768)\n",
            "called:  (371, 768)\n",
            "called:  (397, 768)\n",
            "called:  (1059, 768)\n",
            "called:  (573, 768)\n",
            "called:  (269, 768)\n",
            "called:  (237, 768)\n",
            "called:  (288, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9698, recall: 0.8819, f1: 0.9238, accuracy: 0.9230, batch_loss: 0.1681, loss: 0.1608 ||:  70%|#######   | 14/20 [28:59<12:10, 121.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 19:03:46 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 19:03:46 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:03:46 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 19:03:46 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:03:46 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:03:46 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9698376059532166, 'recall': 0.8818565607070923, 'f1': 0.9237569570541382}\n",
            "\n",
            "2024-05-29 19:03:46 :: encode posts per user in batch ...\n",
            "2024-05-29 19:03:46 :: First two user ids in current batch: [4150201096] and [4799805917]\n",
            "called:  (216, 768)\n",
            "called:  (854, 768)\n",
            "called:  (616, 768)\n",
            "called:  (294, 768)\n",
            "called:  (413, 768)\n",
            "called:  (228, 768)\n",
            "called:  (337, 768)\n",
            "called:  (1909, 768)\n",
            "called:  (229, 768)\n",
            "called:  (1463, 768)\n",
            "called:  (527, 768)\n",
            "called:  (262, 768)\n",
            "called:  (1065, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9650, recall: 0.8837, f1: 0.9225, accuracy: 0.9229, batch_loss: 0.1967, loss: 0.1632 ||:  75%|#######5  | 15/20 [31:20<10:37, 127.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 19:06:07 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 19:06:07 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:06:07 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 19:06:07 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:06:07 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:06:07 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9649507403373718, 'recall': 0.8836509585380554, 'f1': 0.9225131273269653}\n",
            "\n",
            "2024-05-29 19:06:07 :: encode posts per user in batch ...\n",
            "2024-05-29 19:06:07 :: First two user ids in current batch: [621199655] and [790574553206587392]\n",
            "called:  (1543, 768)\n",
            "called:  (335, 768)\n",
            "called:  (206, 768)\n",
            "called:  (830, 768)\n",
            "called:  (231, 768)\n",
            "called:  (1270, 768)\n",
            "called:  (477, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9640, recall: 0.8823, f1: 0.9213, accuracy: 0.9219, batch_loss: 0.1486, loss: 0.1623 ||:  80%|########  | 16/20 [32:48<07:42, 115.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 19:07:35 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 19:07:35 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:07:35 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 19:07:35 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:07:35 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:07:35 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9639917612075806, 'recall': 0.8822975754737854, 'f1': 0.9213372468948364}\n",
            "\n",
            "2024-05-29 19:07:35 :: encode posts per user in batch ...\n",
            "2024-05-29 19:07:35 :: First two user ids in current batch: [417313780] and [1015553905]\n",
            "called:  (673, 768)\n",
            "called:  (283, 768)\n",
            "called:  (1638, 768)\n",
            "called:  (618, 768)\n",
            "called:  (262, 768)\n",
            "called:  (936, 768)\n",
            "called:  (390, 768)\n",
            "called:  (1560, 768)\n",
            "called:  (329, 768)\n",
            "called:  (223, 768)\n",
            "called:  (336, 768)\n",
            "called:  (1181, 768)\n",
            "called:  (692, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9660, recall: 0.8829, f1: 0.9226, accuracy: 0.9233, batch_loss: 0.0971, loss: 0.1584 ||:  85%|########5 | 17/20 [35:28<06:26, 129.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 19:10:15 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 19:10:15 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:10:15 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 19:10:15 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:10:15 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:10:15 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9660193920135498, 'recall': 0.8828749060630798, 'f1': 0.9225776195526123}\n",
            "\n",
            "2024-05-29 19:10:15 :: encode posts per user in batch ...\n",
            "2024-05-29 19:10:15 :: First two user ids in current batch: [438397543] and [387578432]\n",
            "called:  (950, 768)\n",
            "called:  (233, 768)\n",
            "called:  (458, 768)\n",
            "called:  (244, 768)\n",
            "called:  (804, 768)\n",
            "called:  (569, 768)\n",
            "called:  (299, 768)\n",
            "called:  (524, 768)\n",
            "called:  (320, 768)\n",
            "called:  (323, 768)\n",
            "called:  (942, 768)\n",
            "called:  (517, 768)\n",
            "called:  (831, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9649, recall: 0.8795, f1: 0.9202, accuracy: 0.9214, batch_loss: 0.2302, loss: 0.1624 ||:  90%|######### | 18/20 [37:33<04:15, 127.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 19:12:20 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 19:12:20 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:12:20 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 19:12:20 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:12:20 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:12:20 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9648798704147339, 'recall': 0.8795282244682312, 'f1': 0.9202291965484619}\n",
            "\n",
            "2024-05-29 19:12:20 :: encode posts per user in batch ...\n",
            "2024-05-29 19:12:20 :: First two user ids in current batch: [3213548897] and [36017470]\n",
            "called:  (412, 768)\n",
            "called:  (503, 768)\n",
            "called:  (376, 768)\n",
            "called:  (1362, 768)\n",
            "called:  (320, 768)\n",
            "called:  (263, 768)\n",
            "called:  (826, 768)\n",
            "called:  (259, 768)\n",
            "called:  (464, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9664, recall: 0.8785, f1: 0.9204, accuracy: 0.9223, batch_loss: 0.1544, loss: 0.1620 ||:  95%|#########5| 19/20 [39:05<01:57, 117.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 19:13:52 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 19:13:52 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:13:52 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 19:13:52 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:13:52 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:13:52 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9663716554641724, 'recall': 0.8785197138786316, 'f1': 0.9203540086746216}\n",
            "\n",
            "2024-05-29 19:13:52 :: encode posts per user in batch ...\n",
            "2024-05-29 19:13:52 :: First two user ids in current batch: [271703104] and [954379651]\n",
            "called:  (216, 768)\n",
            "called:  (1772, 768)\n",
            "called:  (326, 768)\n",
            "called:  (222, 768)\n",
            "called:  (553, 768)\n",
            "called:  (1601, 768)\n",
            "called:  (407, 768)\n",
            "called:  (627, 768)\n",
            "called:  (465, 768)\n",
            "called:  (286, 768)\n",
            "called:  (254, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "precision: 0.9676, recall: 0.8757, f1: 0.9193, accuracy: 0.9212, batch_loss: 0.1402, loss: 0.1609 ||: 100%|##########| 20/20 [41:00<00:00, 123.01s/it]\n",
            "  0%|          | 0/7 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 19:15:47 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 19:15:47 :: tensor size after padding: torch.Size([92, 200, 768])\n",
            "2024-05-29 19:15:47 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([92, 200, 768])]\n",
            "2024-05-29 19:15:47 :: post masking: content [torch.Size([92, 200])]\n",
            "new tenor size: torch.Size([92, 200, 768])\n",
            "2024-05-29 19:15:47 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([92, 200, 768])\n",
            "2024-05-29 19:15:47 :: post reprsentation shape : torch.Size([92, 768])\n",
            "{'precision': 0.967576801776886, 'recall': 0.8756756782531738, 'f1': 0.9193352460861206}\n",
            "\n",
            "{'precision': 0.967576801776886, 'recall': 0.8756756782531738, 'f1': 0.9193352460861206}\n",
            "\n",
            "2024-05-29 19:15:47 :: encode posts per user in batch ...\n",
            "2024-05-29 19:15:47 :: First two user ids in current batch: [19769659] and [2326131139]\n",
            "called:  (352, 768)\n",
            "called:  (223, 768)\n",
            "called:  (772, 768)\n",
            "called:  (236, 768)\n",
            "called:  (324, 768)\n",
            "called:  (318, 768)\n",
            "called:  (222, 768)\n",
            "called:  (251, 768)\n",
            "called:  (608, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9841, recall: 0.9688, f1: 0.9764, accuracy: 0.9766, batch_loss: 0.0632, loss: 0.0632 ||:  14%|#4        | 1/7 [01:06<06:37, 66.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 19:16:53 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 19:16:53 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:16:53 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 19:16:53 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:16:53 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:16:53 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9841269850730896, 'recall': 0.96875, 'f1': 0.9763779044151306}\n",
            "\n",
            "2024-05-29 19:16:53 :: encode posts per user in batch ...\n",
            "2024-05-29 19:16:53 :: First two user ids in current batch: [2495337330] and [2473809860]\n",
            "called:  (329, 768)\n",
            "called:  (214, 768)\n",
            "called:  (522, 768)\n",
            "called:  (1311, 768)\n",
            "called:  (431, 768)\n",
            "called:  (874, 768)\n",
            "called:  (449, 768)\n",
            "called:  (303, 768)\n",
            "called:  (269, 768)\n",
            "called:  (336, 768)\n",
            "called:  (985, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9921, recall: 0.9690, f1: 0.9804, accuracy: 0.9805, batch_loss: 0.0262, loss: 0.0447 ||:  29%|##8       | 2/7 [02:51<07:25, 89.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 19:18:38 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 19:18:38 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:18:38 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 19:18:38 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:18:38 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:18:38 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9920634627342224, 'recall': 0.9689922332763672, 'f1': 0.9803920984268188}\n",
            "\n",
            "2024-05-29 19:18:38 :: encode posts per user in batch ...\n",
            "2024-05-29 19:18:38 :: First two user ids in current batch: [3309440615] and [3196226090]\n",
            "called:  (371, 768)\n",
            "called:  (201, 768)\n",
            "called:  (932, 768)\n",
            "called:  (242, 768)\n",
            "called:  (440, 768)\n",
            "called:  (265, 768)\n",
            "called:  (216, 768)\n",
            "called:  (207, 768)\n",
            "called:  (283, 768)\n",
            "called:  (1122, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9899, recall: 0.9751, f1: 0.9825, accuracy: 0.9818, batch_loss: 0.0542, loss: 0.0479 ||:  43%|####2     | 3/7 [04:12<05:42, 85.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 19:19:59 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 19:19:59 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:19:59 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 19:19:59 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:19:59 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:19:59 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9898989796638489, 'recall': 0.9751243591308594, 'f1': 0.9824562072753906}\n",
            "\n",
            "2024-05-29 19:20:00 :: encode posts per user in batch ...\n",
            "2024-05-29 19:20:00 :: First two user ids in current batch: [490014120] and [257090362]\n",
            "called:  (366, 768)\n",
            "called:  (1194, 768)\n",
            "called:  (401, 768)\n",
            "called:  (285, 768)\n",
            "called:  (310, 768)\n",
            "called:  (302, 768)\n",
            "called:  (947, 768)\n",
            "called:  (1276, 768)\n",
            "called:  (2606, 768)\n",
            "called:  (666, 768)\n",
            "called:  (1008, 768)\n",
            "called:  (207, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9850, recall: 0.9741, f1: 0.9795, accuracy: 0.9785, batch_loss: 0.0714, loss: 0.0537 ||:  57%|#####7    | 4/7 [06:43<05:33, 111.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 19:22:30 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 19:22:30 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:22:30 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 19:22:30 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:22:30 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:22:30 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9850187301635742, 'recall': 0.9740740656852722, 'f1': 0.979515790939331}\n",
            "\n",
            "2024-05-29 19:22:30 :: encode posts per user in batch ...\n",
            "2024-05-29 19:22:30 :: First two user ids in current batch: [746496955300249601] and [741720266938556419]\n",
            "called:  (507, 768)\n",
            "called:  (348, 768)\n",
            "called:  (989, 768)\n",
            "called:  (218, 768)\n",
            "called:  (246, 768)\n",
            "called:  (212, 768)\n",
            "called:  (292, 768)\n",
            "called:  (523, 768)\n",
            "called:  (1604, 768)\n",
            "called:  (1078, 768)\n",
            "called:  (309, 768)\n",
            "called:  (226, 768)\n",
            "called:  (351, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9881, recall: 0.9735, f1: 0.9807, accuracy: 0.9797, batch_loss: 0.0714, loss: 0.0573 ||:  71%|#######1  | 5/7 [08:44<03:49, 114.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 19:24:31 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 19:24:31 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:24:31 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 19:24:31 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:24:31 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:24:31 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9880596995353699, 'recall': 0.9735293984413147, 'f1': 0.9807407259941101}\n",
            "\n",
            "2024-05-29 19:24:31 :: encode posts per user in batch ...\n",
            "2024-05-29 19:24:31 :: First two user ids in current batch: [3343259593] and [965712074]\n",
            "called:  (232, 768)\n",
            "called:  (1923, 768)\n",
            "called:  (241, 768)\n",
            "called:  (226, 768)\n",
            "called:  (289, 768)\n",
            "called:  (751, 768)\n",
            "called:  (232, 768)\n",
            "called:  (2229, 768)\n",
            "called:  (297, 768)\n",
            "called:  (421, 768)\n",
            "called:  (249, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9899, recall: 0.9752, f1: 0.9825, accuracy: 0.9818, batch_loss: 0.0222, loss: 0.0514 ||:  86%|########5 | 6/7 [10:40<01:55, 115.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 19:26:27 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 19:26:27 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:26:27 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 19:26:27 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:26:27 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:26:27 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.989924430847168, 'recall': 0.9751861095428467, 'f1': 0.9825000166893005}\n",
            "\n",
            "2024-05-29 19:26:27 :: encode posts per user in batch ...\n",
            "2024-05-29 19:26:27 :: First two user ids in current batch: [713552831022809088] and [752409962375024645]\n",
            "called:  (215, 768)\n",
            "called:  (219, 768)\n",
            "called:  (1477, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "precision: 0.9906, recall: 0.9769, f1: 0.9837, accuracy: 0.9834, batch_loss: 0.0143, loss: 0.0461 ||: 100%|##########| 7/7 [11:14<00:00, 96.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 19:27:01 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 19:27:01 :: tensor size after padding: torch.Size([74, 200, 768])\n",
            "2024-05-29 19:27:01 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([74, 200, 768])]\n",
            "2024-05-29 19:27:01 :: post masking: content [torch.Size([74, 200])]\n",
            "new tenor size: torch.Size([74, 200, 768])\n",
            "2024-05-29 19:27:01 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([74, 200, 768])\n",
            "2024-05-29 19:27:01 :: post reprsentation shape : torch.Size([74, 768])\n",
            "{'precision': 0.9906103014945984, 'recall': 0.9768518805503845, 'f1': 0.9836829900741577}\n",
            "\n",
            "{'precision': 0.9906103014945984, 'recall': 0.9768518805503845, 'f1': 0.9836829900741577}\n",
            "\n",
            "Metrics at the end of epoch: 1 {'best_epoch': 1, 'peak_worker_0_memory_MB': 2066.77734375, 'peak_gpu_0_memory_MB': 1572.69140625, 'training_duration': '1:45:04.322033', 'epoch': 1, 'training_precision': 0.967576801776886, 'training_recall': 0.8756756782531738, 'training_f1': 0.9193352460861206, 'training_accuracy': 0.9211568938193344, 'training_loss': 0.16092434488236904, 'training_worker_0_memory_MB': 2066.77734375, 'training_gpu_0_memory_MB': 1572.69140625, 'validation_precision': 0.9906103014945984, 'validation_recall': 0.9768518805503845, 'validation_f1': 0.9836829900741577, 'validation_accuracy': 0.9833729216152018, 'validation_loss': 0.04612130991050175, 'best_validation_precision': 0.9906103014945984, 'best_validation_recall': 0.9768518805503845, 'best_validation_f1': 0.9836829900741577, 'best_validation_accuracy': 0.9833729216152018, 'best_validation_loss': 0.04612130991050175}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/cuda/memory.py:330: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
            "  warnings.warn(\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 19:27:04 :: encode posts per user in batch ...\n",
            "2024-05-29 19:27:04 :: First two user ids in current batch: [780893663870132224] and [755648295029080064]\n",
            "called:  (850, 768)\n",
            "called:  (1284, 768)\n",
            "called:  (326, 768)\n",
            "called:  (503, 768)\n",
            "called:  (235, 768)\n",
            "called:  (231, 768)\n",
            "called:  (511, 768)\n",
            "called:  (282, 768)\n",
            "called:  (360, 768)\n",
            "called:  (936, 768)\n",
            "called:  (237, 768)\n",
            "called:  (236, 768)\n",
            "called:  (1096, 768)\n",
            "called:  (1463, 768)\n",
            "called:  (716, 768)\n",
            "called:  (2189, 768)\n",
            "called:  (279, 768)\n",
            "called:  (465, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9667, recall: 0.9062, f1: 0.9355, accuracy: 0.9375, batch_loss: 0.1121, loss: 0.1121 ||:   5%|5         | 1/20 [03:12<1:00:58, 192.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 19:30:16 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 19:30:16 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:30:16 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 19:30:16 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:30:16 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:30:16 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9666666388511658, 'recall': 0.90625, 'f1': 0.9354838132858276}\n",
            "\n",
            "2024-05-29 19:30:16 :: encode posts per user in batch ...\n",
            "2024-05-29 19:30:16 :: First two user ids in current batch: [84362356] and [583938958]\n",
            "called:  (323, 768)\n",
            "called:  (541, 768)\n",
            "called:  (835, 768)\n",
            "called:  (262, 768)\n",
            "called:  (634, 768)\n",
            "called:  (573, 768)\n",
            "called:  (706, 768)\n",
            "called:  (413, 768)\n",
            "called:  (900, 768)\n",
            "called:  (254, 768)\n",
            "called:  (1909, 768)\n",
            "called:  (389, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9750, recall: 0.8797, f1: 0.9249, accuracy: 0.9258, batch_loss: 0.0969, loss: 0.1045 ||:  10%|#         | 2/20 [05:21<46:29, 154.97s/it]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 19:32:25 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 19:32:25 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:32:25 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 19:32:25 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:32:25 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:32:25 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9750000238418579, 'recall': 0.8796992301940918, 'f1': 0.9249011874198914}\n",
            "\n",
            "2024-05-29 19:32:25 :: encode posts per user in batch ...\n",
            "2024-05-29 19:32:25 :: First two user ids in current batch: [3015971504] and [84159349]\n",
            "called:  (376, 768)\n",
            "called:  (464, 768)\n",
            "called:  (373, 768)\n",
            "called:  (352, 768)\n",
            "called:  (263, 768)\n",
            "called:  (692, 768)\n",
            "called:  (267, 768)\n",
            "called:  (453, 768)\n",
            "called:  (2037, 768)\n",
            "called:  (1594, 768)\n",
            "called:  (347, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9669, recall: 0.8838, f1: 0.9235, accuracy: 0.9245, batch_loss: 0.1087, loss: 0.1059 ||:  15%|#5        | 3/20 [07:25<39:54, 140.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 19:34:29 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 19:34:29 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:34:29 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 19:34:29 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:34:29 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:34:29 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9668508172035217, 'recall': 0.8838383555412292, 'f1': 0.9234827756881714}\n",
            "\n",
            "2024-05-29 19:34:29 :: encode posts per user in batch ...\n",
            "2024-05-29 19:34:29 :: First two user ids in current batch: [566477640] and [719841011179110400]\n",
            "called:  (233, 768)\n",
            "called:  (336, 768)\n",
            "called:  (959, 768)\n",
            "called:  (257, 768)\n",
            "called:  (286, 768)\n",
            "called:  (804, 768)\n",
            "called:  (477, 768)\n",
            "called:  (1230, 768)\n",
            "called:  (313, 768)\n",
            "called:  (337, 768)\n",
            "called:  (208, 768)\n",
            "called:  (458, 768)\n",
            "called:  (390, 768)\n",
            "called:  (244, 768)\n",
            "called:  (229, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9633, recall: 0.8872, f1: 0.9237, accuracy: 0.9238, batch_loss: 0.1252, loss: 0.1107 ||:  20%|##        | 4/20 [09:30<35:52, 134.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 19:36:34 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 19:36:34 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:36:34 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 19:36:34 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:36:34 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:36:34 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9632652997970581, 'recall': 0.8872180581092834, 'f1': 0.923678994178772}\n",
            "\n",
            "2024-05-29 19:36:34 :: encode posts per user in batch ...\n",
            "2024-05-29 19:36:34 :: First two user ids in current batch: [1206517537] and [3433372481]\n",
            "called:  (266, 768)\n",
            "called:  (950, 768)\n",
            "called:  (294, 768)\n",
            "called:  (294, 768)\n",
            "called:  (493, 768)\n",
            "called:  (1601, 768)\n",
            "called:  (288, 768)\n",
            "called:  (320, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9701, recall: 0.8743, f1: 0.9197, accuracy: 0.9203, batch_loss: 0.1818, loss: 0.1250 ||:  25%|##5       | 5/20 [10:59<29:32, 118.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 19:38:03 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 19:38:03 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:38:03 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 19:38:03 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:38:03 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:38:03 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.970099687576294, 'recall': 0.8742514848709106, 'f1': 0.9196850657463074}\n",
            "\n",
            "2024-05-29 19:38:03 :: encode posts per user in batch ...\n",
            "2024-05-29 19:38:03 :: First two user ids in current batch: [1169875706] and [2575799245]\n",
            "called:  (323, 768)\n",
            "called:  (482, 768)\n",
            "called:  (207, 768)\n",
            "called:  (259, 768)\n",
            "called:  (641, 768)\n",
            "called:  (297, 768)\n",
            "called:  (514, 768)\n",
            "called:  (288, 768)\n",
            "called:  (1772, 768)\n",
            "called:  (356, 768)\n",
            "called:  (1567, 768)\n",
            "called:  (830, 768)\n",
            "called:  (262, 768)\n",
            "called:  (241, 768)\n",
            "called:  (335, 768)\n",
            "called:  (299, 768)\n",
            "called:  (1230, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9749, recall: 0.8858, f1: 0.9282, accuracy: 0.9297, batch_loss: 0.0612, loss: 0.1143 ||:  30%|###       | 6/20 [13:52<31:54, 136.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 19:40:56 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 19:40:56 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:40:56 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 19:40:56 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:40:56 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:40:56 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9748603105545044, 'recall': 0.8857868313789368, 'f1': 0.9281914830207825}\n",
            "\n",
            "2024-05-29 19:40:56 :: encode posts per user in batch ...\n",
            "2024-05-29 19:40:56 :: First two user ids in current batch: [53654843] and [160478571]\n",
            "called:  (304, 768)\n",
            "called:  (1025, 768)\n",
            "called:  (222, 768)\n",
            "called:  (854, 768)\n",
            "called:  (426, 768)\n",
            "called:  (826, 768)\n",
            "called:  (942, 768)\n",
            "called:  (2042, 768)\n",
            "called:  (499, 768)\n",
            "called:  (673, 768)\n",
            "called:  (1362, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9738, recall: 0.8891, f1: 0.9295, accuracy: 0.9308, batch_loss: 0.1216, loss: 0.1154 ||:  35%|###5      | 7/20 [16:29<31:04, 143.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 19:43:33 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 19:43:33 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:43:33 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 19:43:33 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:43:33 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:43:33 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.973809540271759, 'recall': 0.8891304135322571, 'f1': 0.9295454025268555}\n",
            "\n",
            "2024-05-29 19:43:33 :: encode posts per user in batch ...\n",
            "2024-05-29 19:43:33 :: First two user ids in current batch: [364476473] and [706742329294454784]\n",
            "called:  (329, 768)\n",
            "called:  (296, 768)\n",
            "called:  (1181, 768)\n",
            "called:  (622, 768)\n",
            "called:  (784, 768)\n",
            "called:  (280, 768)\n",
            "called:  (439, 768)\n",
            "called:  (610, 768)\n",
            "called:  (441, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9772, recall: 0.8973, f1: 0.9356, accuracy: 0.9365, batch_loss: 0.0724, loss: 0.1100 ||:  40%|####      | 8/20 [17:58<25:13, 126.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 19:45:02 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 19:45:02 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:45:02 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 19:45:02 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:45:02 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:45:02 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.977225661277771, 'recall': 0.8973383903503418, 'f1': 0.935579776763916}\n",
            "\n",
            "2024-05-29 19:45:02 :: encode posts per user in batch ...\n",
            "2024-05-29 19:45:02 :: First two user ids in current batch: [288689885] and [3867407957]\n",
            "called:  (383, 768)\n",
            "called:  (2116, 768)\n",
            "called:  (553, 768)\n",
            "called:  (1638, 768)\n",
            "called:  (2298, 768)\n",
            "called:  (397, 768)\n",
            "called:  (338, 768)\n",
            "called:  (437, 768)\n",
            "called:  (1270, 768)\n",
            "called:  (498, 768)\n",
            "called:  (539, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9724, recall: 0.8995, f1: 0.9345, accuracy: 0.9358, batch_loss: 0.1207, loss: 0.1112 ||:  45%|####5     | 9/20 [20:54<26:00, 141.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 19:47:59 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 19:47:59 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:47:59 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 19:47:59 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:47:59 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:47:59 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9723756909370422, 'recall': 0.8994889259338379, 'f1': 0.9345133304595947}\n",
            "\n",
            "2024-05-29 19:47:59 :: encode posts per user in batch ...\n",
            "2024-05-29 19:47:59 :: First two user ids in current batch: [2804112536] and [195332085]\n",
            "called:  (627, 768)\n",
            "called:  (1065, 768)\n",
            "called:  (812, 768)\n",
            "called:  (618, 768)\n",
            "called:  (220, 768)\n",
            "called:  (420, 768)\n",
            "called:  (255, 768)\n",
            "called:  (515, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9735, recall: 0.8989, f1: 0.9347, accuracy: 0.9359, batch_loss: 0.1333, loss: 0.1134 ||:  50%|#####     | 10/20 [22:30<21:15, 127.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 19:49:34 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 19:49:34 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:49:34 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 19:49:34 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:49:34 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:49:34 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9734659790992737, 'recall': 0.8989280462265015, 'f1': 0.9347133636474609}\n",
            "\n",
            "2024-05-29 19:49:34 :: encode posts per user in batch ...\n",
            "2024-05-29 19:49:34 :: First two user ids in current batch: [450917673] and [1316829918]\n",
            "called:  (216, 768)\n",
            "called:  (598, 768)\n",
            "called:  (914, 768)\n",
            "called:  (520, 768)\n",
            "called:  (232, 768)\n",
            "called:  (430, 768)\n",
            "called:  (388, 768)\n",
            "called:  (383, 768)\n",
            "called:  (468, 768)\n",
            "called:  (230, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9742, recall: 0.8966, f1: 0.9338, accuracy: 0.9354, batch_loss: 0.1292, loss: 0.1148 ||:  55%|#####5    | 11/20 [24:09<17:48, 118.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 19:51:13 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 19:51:13 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:51:13 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 19:51:13 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:51:13 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:51:13 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.97420334815979, 'recall': 0.8966480493545532, 'f1': 0.9338181614875793}\n",
            "\n",
            "2024-05-29 19:51:13 :: encode posts per user in batch ...\n",
            "2024-05-29 19:51:13 :: First two user ids in current batch: [18478207] and [591844354]\n",
            "called:  (444, 768)\n",
            "called:  (524, 768)\n",
            "called:  (1983, 768)\n",
            "called:  (377, 768)\n",
            "called:  (1103, 768)\n",
            "called:  (937, 768)\n",
            "called:  (222, 768)\n",
            "called:  (231, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9748, recall: 0.8913, f1: 0.9312, accuracy: 0.9329, batch_loss: 0.1049, loss: 0.1140 ||:  60%|######    | 12/20 [25:46<14:58, 112.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 19:52:50 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 19:52:50 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:52:50 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 19:52:50 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:52:50 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:52:50 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9748252034187317, 'recall': 0.8913043737411499, 'f1': 0.9311957359313965}\n",
            "\n",
            "2024-05-29 19:52:50 :: encode posts per user in batch ...\n",
            "2024-05-29 19:52:50 :: First two user ids in current batch: [852605054] and [268934850]\n",
            "called:  (644, 768)\n",
            "called:  (529, 768)\n",
            "called:  (523, 768)\n",
            "called:  (207, 768)\n",
            "called:  (458, 768)\n",
            "called:  (279, 768)\n",
            "called:  (2668, 768)\n",
            "called:  (412, 768)\n",
            "called:  (283, 768)\n",
            "called:  (332, 768)\n",
            "called:  (223, 768)\n",
            "called:  (600, 768)\n",
            "called:  (410, 768)\n",
            "called:  (249, 768)\n",
            "called:  (632, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9758, recall: 0.8926, f1: 0.9324, accuracy: 0.9333, batch_loss: 0.1121, loss: 0.1138 ||:  65%|######5   | 13/20 [28:19<14:31, 124.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 19:55:23 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 19:55:23 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:55:23 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 19:55:23 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:55:23 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:55:23 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9757652878761292, 'recall': 0.8926487565040588, 'f1': 0.9323583245277405}\n",
            "\n",
            "2024-05-29 19:55:23 :: encode posts per user in batch ...\n",
            "2024-05-29 19:55:23 :: First two user ids in current batch: [161333345] and [2490745602]\n",
            "called:  (685, 768)\n",
            "called:  (800, 768)\n",
            "called:  (651, 768)\n",
            "called:  (464, 768)\n",
            "called:  (569, 768)\n",
            "called:  (616, 768)\n",
            "called:  (2317, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9766, recall: 0.8929, f1: 0.9329, accuracy: 0.9330, batch_loss: 0.1056, loss: 0.1133 ||:  70%|#######   | 14/20 [30:10<12:02, 120.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 19:57:14 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 19:57:14 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:57:14 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 19:57:14 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:57:14 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:57:14 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.976580798625946, 'recall': 0.8929336071014404, 'f1': 0.9328858256340027}\n",
            "\n",
            "2024-05-29 19:57:14 :: encode posts per user in batch ...\n",
            "2024-05-29 19:57:14 :: First two user ids in current batch: [36486030] and [796441228871135232]\n",
            "called:  (263, 768)\n",
            "called:  (325, 768)\n",
            "called:  (2062, 768)\n",
            "called:  (320, 768)\n",
            "called:  (283, 768)\n",
            "called:  (2068, 768)\n",
            "called:  (226, 768)\n",
            "called:  (290, 768)\n",
            "called:  (451, 768)\n",
            "called:  (216, 768)\n",
            "called:  (254, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9760, recall: 0.8924, f1: 0.9324, accuracy: 0.9323, batch_loss: 0.1392, loss: 0.1150 ||:  75%|#######5  | 15/20 [32:11<10:03, 120.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 19:59:15 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 19:59:15 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:59:15 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 19:59:15 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:59:15 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 19:59:15 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9760348796844482, 'recall': 0.892430305480957, 'f1': 0.9323621392250061}\n",
            "\n",
            "2024-05-29 19:59:15 :: encode posts per user in batch ...\n",
            "2024-05-29 19:59:15 :: First two user ids in current batch: [974441856] and [4095353712]\n",
            "called:  (517, 768)\n",
            "called:  (483, 768)\n",
            "called:  (493, 768)\n",
            "called:  (328, 768)\n",
            "called:  (822, 768)\n",
            "called:  (385, 768)\n",
            "called:  (786, 768)\n",
            "called:  (376, 768)\n",
            "called:  (326, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9775, recall: 0.8941, f1: 0.9339, accuracy: 0.9341, batch_loss: 0.0648, loss: 0.1119 ||:  80%|########  | 16/20 [33:37<07:21, 110.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 20:00:42 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 20:00:42 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:00:42 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 20:00:42 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:00:42 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:00:42 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9774590134620667, 'recall': 0.8940955996513367, 'f1': 0.933920681476593}\n",
            "\n",
            "2024-05-29 20:00:42 :: encode posts per user in batch ...\n",
            "2024-05-29 20:00:42 :: First two user ids in current batch: [30698846] and [109065844]\n",
            "called:  (555, 768)\n",
            "called:  (407, 768)\n",
            "called:  (1543, 768)\n",
            "called:  (228, 768)\n",
            "called:  (389, 768)\n",
            "called:  (535, 768)\n",
            "called:  (795, 768)\n",
            "called:  (201, 768)\n",
            "called:  (527, 768)\n",
            "called:  (323, 768)\n",
            "called:  (831, 768)\n",
            "called:  (213, 768)\n",
            "called:  (2534, 768)\n",
            "called:  (655, 768)\n",
            "called:  (1572, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9768, recall: 0.8913, f1: 0.9321, accuracy: 0.9324, batch_loss: 0.1753, loss: 0.1156 ||:  85%|########5 | 17/20 [36:50<06:44, 134.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 20:03:54 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 20:03:54 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:03:54 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 20:03:54 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:03:54 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:03:54 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9767667055130005, 'recall': 0.8913427591323853, 'f1': 0.9321016669273376}\n",
            "\n",
            "2024-05-29 20:03:54 :: encode posts per user in batch ...\n",
            "2024-05-29 20:03:54 :: First two user ids in current batch: [156951756] and [760292934436519936]\n",
            "called:  (1012, 768)\n",
            "called:  (269, 768)\n",
            "called:  (942, 768)\n",
            "called:  (861, 768)\n",
            "called:  (1237, 768)\n",
            "called:  (284, 768)\n",
            "called:  (1059, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9778, recall: 0.8904, f1: 0.9320, accuracy: 0.9332, batch_loss: 0.1277, loss: 0.1163 ||:  90%|######### | 18/20 [38:30<04:09, 124.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 20:05:34 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 20:05:34 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:05:34 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 20:05:34 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:05:34 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:05:34 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9777777791023254, 'recall': 0.8903878331184387, 'f1': 0.9320387840270996}\n",
            "\n",
            "2024-05-29 20:05:34 :: encode posts per user in batch ...\n",
            "2024-05-29 20:05:34 :: First two user ids in current batch: [390021266] and [46761421]\n",
            "called:  (1560, 768)\n",
            "called:  (326, 768)\n",
            "called:  (206, 768)\n",
            "called:  (464, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9788, recall: 0.8900, f1: 0.9323, accuracy: 0.9338, batch_loss: 0.1090, loss: 0.1159 ||:  95%|#########5| 19/20 [39:24<01:43, 103.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 20:06:28 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 20:06:28 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:06:28 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 20:06:28 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:06:28 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:06:28 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9787985682487488, 'recall': 0.8899598121643066, 'f1': 0.9322674870491028}\n",
            "\n",
            "2024-05-29 20:06:28 :: encode posts per user in batch ...\n",
            "2024-05-29 20:06:28 :: First two user ids in current batch: [2593250539] and [178896182]\n",
            "called:  (947, 768)\n",
            "called:  (556, 768)\n",
            "called:  (276, 768)\n",
            "called:  (551, 768)\n",
            "called:  (371, 768)\n",
            "called:  (456, 768)\n",
            "called:  (358, 768)\n",
            "called:  (420, 768)\n",
            "called:  (259, 768)\n",
            "called:  (413, 768)\n",
            "called:  (840, 768)\n",
            "called:  (225, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "precision: 0.9788, recall: 0.8896, f1: 0.9320, accuracy: 0.9334, batch_loss: 0.2059, loss: 0.1204 ||: 100%|##########| 20/20 [41:10<00:00, 123.51s/it]\n",
            "  0%|          | 0/7 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 20:08:14 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 20:08:14 :: tensor size after padding: torch.Size([92, 200, 768])\n",
            "2024-05-29 20:08:14 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([92, 200, 768])]\n",
            "2024-05-29 20:08:14 :: post masking: content [torch.Size([92, 200])]\n",
            "new tenor size: torch.Size([92, 200, 768])\n",
            "2024-05-29 20:08:14 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([92, 200, 768])\n",
            "2024-05-29 20:08:14 :: post reprsentation shape : torch.Size([92, 768])\n",
            "{'precision': 0.9787595868110657, 'recall': 0.8895753026008606, 'f1': 0.9320388436317444}\n",
            "\n",
            "{'precision': 0.9787595868110657, 'recall': 0.8895753026008606, 'f1': 0.9320388436317444}\n",
            "\n",
            "2024-05-29 20:08:14 :: encode posts per user in batch ...\n",
            "2024-05-29 20:08:14 :: First two user ids in current batch: [753579350] and [1907082865]\n",
            "called:  (232, 768)\n",
            "called:  (1477, 768)\n",
            "called:  (214, 768)\n",
            "called:  (507, 768)\n",
            "called:  (989, 768)\n",
            "called:  (310, 768)\n",
            "called:  (201, 768)\n",
            "called:  (292, 768)\n",
            "called:  (222, 768)\n",
            "called:  (249, 768)\n",
            "called:  (421, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 1.0000, recall: 0.9846, f1: 0.9922, accuracy: 0.9922, batch_loss: 0.0529, loss: 0.0529 ||:  14%|#4        | 1/7 [01:28<08:49, 88.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 20:09:42 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 20:09:42 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:09:42 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 20:09:42 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:09:42 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:09:42 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 1.0, 'recall': 0.9846153855323792, 'f1': 0.9922481179237366}\n",
            "\n",
            "2024-05-29 20:09:42 :: encode posts per user in batch ...\n",
            "2024-05-29 20:09:42 :: First two user ids in current batch: [128937010] and [38324326]\n",
            "called:  (1604, 768)\n",
            "called:  (772, 768)\n",
            "called:  (218, 768)\n",
            "called:  (336, 768)\n",
            "called:  (223, 768)\n",
            "called:  (351, 768)\n",
            "called:  (215, 768)\n",
            "called:  (932, 768)\n",
            "called:  (219, 768)\n",
            "called:  (251, 768)\n",
            "called:  (283, 768)\n",
            "called:  (440, 768)\n",
            "called:  (522, 768)\n",
            "called:  (324, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9924, recall: 0.9850, f1: 0.9887, accuracy: 0.9883, batch_loss: 0.0359, loss: 0.0444 ||:  29%|##8       | 2/7 [03:22<08:37, 103.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 20:11:36 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 20:11:36 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:11:36 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 20:11:36 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:11:36 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:11:36 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9924242496490479, 'recall': 0.9849624037742615, 'f1': 0.9886792302131653}\n",
            "\n",
            "2024-05-29 20:11:37 :: encode posts per user in batch ...\n",
            "2024-05-29 20:11:37 :: First two user ids in current batch: [1049206752] and [246770942]\n",
            "called:  (371, 768)\n",
            "called:  (303, 768)\n",
            "called:  (401, 768)\n",
            "called:  (265, 768)\n",
            "called:  (431, 768)\n",
            "called:  (352, 768)\n",
            "called:  (1122, 768)\n",
            "called:  (207, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9898, recall: 0.9898, f1: 0.9898, accuracy: 0.9896, batch_loss: 0.0196, loss: 0.0361 ||:  43%|####2     | 3/7 [04:29<05:46, 86.67s/it] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 20:12:43 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 20:12:43 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:12:43 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 20:12:43 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:12:43 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:12:43 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9897959232330322, 'recall': 0.9897959232330322, 'f1': 0.9897959232330322}\n",
            "\n",
            "2024-05-29 20:12:43 :: encode posts per user in batch ...\n",
            "2024-05-29 20:12:43 :: First two user ids in current batch: [573251982] and [457228958]\n",
            "called:  (348, 768)\n",
            "called:  (226, 768)\n",
            "called:  (269, 768)\n",
            "called:  (666, 768)\n",
            "called:  (608, 768)\n",
            "called:  (329, 768)\n",
            "called:  (985, 768)\n",
            "called:  (1923, 768)\n",
            "called:  (216, 768)\n",
            "called:  (1276, 768)\n",
            "called:  (523, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9815, recall: 0.9888, f1: 0.9852, accuracy: 0.9844, batch_loss: 0.0899, loss: 0.0496 ||:  57%|#####7    | 4/7 [06:28<04:58, 99.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 20:14:42 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 20:14:42 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:14:42 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 20:14:42 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:14:42 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:14:42 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9815497994422913, 'recall': 0.9888476133346558, 'f1': 0.9851851463317871}\n",
            "\n",
            "2024-05-29 20:14:42 :: encode posts per user in batch ...\n",
            "2024-05-29 20:14:42 :: First two user ids in current batch: [2790567881] and [766529990]\n",
            "called:  (242, 768)\n",
            "called:  (1008, 768)\n",
            "called:  (226, 768)\n",
            "called:  (232, 768)\n",
            "called:  (1078, 768)\n",
            "called:  (236, 768)\n",
            "called:  (285, 768)\n",
            "called:  (302, 768)\n",
            "called:  (947, 768)\n",
            "called:  (207, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9796, recall: 0.9882, f1: 0.9839, accuracy: 0.9828, batch_loss: 0.0245, loss: 0.0446 ||:  71%|#######1  | 5/7 [07:55<03:10, 95.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 20:16:10 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 20:16:10 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:16:10 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 20:16:10 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:16:10 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:16:10 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9795918464660645, 'recall': 0.9882352948188782, 'f1': 0.9838945865631104}\n",
            "\n",
            "2024-05-29 20:16:10 :: encode posts per user in batch ...\n",
            "2024-05-29 20:16:10 :: First two user ids in current batch: [67954601] and [41614074]\n",
            "called:  (1311, 768)\n",
            "called:  (289, 768)\n",
            "called:  (318, 768)\n",
            "called:  (366, 768)\n",
            "called:  (241, 768)\n",
            "called:  (246, 768)\n",
            "called:  (2229, 768)\n",
            "called:  (309, 768)\n",
            "called:  (2606, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9800, recall: 0.9899, f1: 0.9850, accuracy: 0.9844, batch_loss: 0.0159, loss: 0.0398 ||:  86%|########5 | 6/7 [10:00<01:45, 105.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 20:18:15 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 20:18:15 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:18:15 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 20:18:15 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:18:15 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:18:15 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9800498485565186, 'recall': 0.989924430847168, 'f1': 0.9849623441696167}\n",
            "\n",
            "2024-05-29 20:18:15 :: encode posts per user in batch ...\n",
            "2024-05-29 20:18:15 :: First two user ids in current batch: [401085902] and [867283314]\n",
            "called:  (1194, 768)\n",
            "called:  (449, 768)\n",
            "called:  (874, 768)\n",
            "called:  (751, 768)\n",
            "called:  (212, 768)\n",
            "called:  (297, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "precision: 0.9794, recall: 0.9907, f1: 0.9850, accuracy: 0.9846, batch_loss: 0.0220, loss: 0.0372 ||: 100%|##########| 7/7 [11:02<00:00, 94.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 20:19:16 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 20:19:16 :: tensor size after padding: torch.Size([74, 200, 768])\n",
            "2024-05-29 20:19:16 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([74, 200, 768])]\n",
            "2024-05-29 20:19:16 :: post masking: content [torch.Size([74, 200])]\n",
            "new tenor size: torch.Size([74, 200, 768])\n",
            "2024-05-29 20:19:16 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([74, 200, 768])\n",
            "2024-05-29 20:19:16 :: post reprsentation shape : torch.Size([74, 768])\n",
            "{'precision': 0.9794050455093384, 'recall': 0.9907407164573669, 'f1': 0.9850403070449829}\n",
            "\n",
            "{'precision': 0.9794050455093384, 'recall': 0.9907407164573669, 'f1': 0.9850403070449829}\n",
            "\n",
            "Metrics at the end of epoch: 2 {'best_epoch': 2, 'peak_worker_0_memory_MB': 2067.55859375, 'peak_gpu_0_memory_MB': 1573.1474609375, 'training_duration': '2:37:19.035462', 'epoch': 2, 'training_precision': 0.9787595868110657, 'training_recall': 0.8895753026008606, 'training_f1': 0.9320388436317444, 'training_accuracy': 0.9334389857369255, 'training_loss': 0.12038053460419178, 'training_worker_0_memory_MB': 2067.55859375, 'training_gpu_0_memory_MB': 1573.1474609375, 'validation_precision': 0.9794050455093384, 'validation_recall': 0.9907407164573669, 'validation_f1': 0.9850403070449829, 'validation_accuracy': 0.9845605700712589, 'validation_loss': 0.03724400220172746, 'best_validation_precision': 0.9794050455093384, 'best_validation_recall': 0.9907407164573669, 'best_validation_f1': 0.9850403070449829, 'best_validation_accuracy': 0.9845605700712589, 'best_validation_loss': 0.03724400220172746}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/cuda/memory.py:330: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
            "  warnings.warn(\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 20:19:18 :: encode posts per user in batch ...\n",
            "2024-05-29 20:19:18 :: First two user ids in current batch: [2504216281] and [1229425452]\n",
            "called:  (444, 768)\n",
            "called:  (413, 768)\n",
            "called:  (499, 768)\n",
            "called:  (573, 768)\n",
            "called:  (373, 768)\n",
            "called:  (286, 768)\n",
            "called:  (288, 768)\n",
            "called:  (244, 768)\n",
            "called:  (326, 768)\n",
            "called:  (376, 768)\n",
            "called:  (555, 768)\n",
            "called:  (377, 768)\n",
            "called:  (673, 768)\n",
            "called:  (332, 768)\n",
            "called:  (551, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9804, recall: 0.9259, f1: 0.9524, accuracy: 0.9609, batch_loss: 0.0932, loss: 0.0932 ||:   5%|5         | 1/20 [01:57<37:15, 117.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 20:21:15 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 20:21:15 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:21:15 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 20:21:15 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:21:15 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:21:15 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9803921580314636, 'recall': 0.9259259104728699, 'f1': 0.9523809552192688}\n",
            "\n",
            "2024-05-29 20:21:15 :: encode posts per user in batch ...\n",
            "2024-05-29 20:21:15 :: First two user ids in current batch: [1577595481] and [106682211]\n",
            "called:  (950, 768)\n",
            "called:  (477, 768)\n",
            "called:  (280, 768)\n",
            "called:  (430, 768)\n",
            "called:  (2298, 768)\n",
            "called:  (329, 768)\n",
            "called:  (511, 768)\n",
            "called:  (453, 768)\n",
            "called:  (458, 768)\n",
            "called:  (254, 768)\n",
            "called:  (412, 768)\n",
            "called:  (706, 768)\n",
            "called:  (231, 768)\n",
            "called:  (786, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9732, recall: 0.9237, f1: 0.9478, accuracy: 0.9531, batch_loss: 0.1067, loss: 0.1000 ||:  10%|#         | 2/20 [04:21<39:58, 133.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 20:23:39 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 20:23:39 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:23:39 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 20:23:39 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:23:39 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:23:39 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9732142686843872, 'recall': 0.9237288236618042, 'f1': 0.947826087474823}\n",
            "\n",
            "2024-05-29 20:23:39 :: encode posts per user in batch ...\n",
            "2024-05-29 20:23:39 :: First two user ids in current batch: [244786774] and [801631260703653888]\n",
            "called:  (464, 768)\n",
            "called:  (569, 768)\n",
            "called:  (1543, 768)\n",
            "called:  (716, 768)\n",
            "called:  (229, 768)\n",
            "called:  (464, 768)\n",
            "called:  (335, 768)\n",
            "called:  (2534, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9760, recall: 0.9006, f1: 0.9368, accuracy: 0.9427, batch_loss: 0.0959, loss: 0.0986 ||:  15%|#5        | 3/20 [06:18<35:36, 125.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 20:25:36 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 20:25:36 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:25:36 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 20:25:36 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:25:36 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:25:36 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.976047933101654, 'recall': 0.90055251121521, 'f1': 0.9367815852165222}\n",
            "\n",
            "2024-05-29 20:25:36 :: encode posts per user in batch ...\n",
            "2024-05-29 20:25:36 :: First two user ids in current batch: [400511939] and [285977037]\n",
            "called:  (413, 768)\n",
            "called:  (795, 768)\n",
            "called:  (830, 768)\n",
            "called:  (337, 768)\n",
            "called:  (835, 768)\n",
            "called:  (2062, 768)\n",
            "called:  (360, 768)\n",
            "called:  (2189, 768)\n",
            "called:  (1096, 768)\n",
            "called:  (644, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9735, recall: 0.8907, f1: 0.9302, accuracy: 0.9355, batch_loss: 0.0877, loss: 0.0959 ||:  20%|##        | 4/20 [08:58<37:06, 139.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 20:28:16 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 20:28:16 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:28:16 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 20:28:16 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:28:16 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:28:16 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9734513163566589, 'recall': 0.8906882405281067, 'f1': 0.9302325248718262}\n",
            "\n",
            "2024-05-29 20:28:16 :: encode posts per user in batch ...\n",
            "2024-05-29 20:28:16 :: First two user ids in current batch: [700950213360427012] and [798360561264115712]\n",
            "called:  (439, 768)\n",
            "called:  (352, 768)\n",
            "called:  (527, 768)\n",
            "called:  (325, 768)\n",
            "called:  (388, 768)\n",
            "called:  (634, 768)\n",
            "called:  (515, 768)\n",
            "called:  (1103, 768)\n",
            "called:  (1270, 768)\n",
            "called:  (514, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9794, recall: 0.9019, f1: 0.9390, accuracy: 0.9422, batch_loss: 0.0521, loss: 0.0871 ||:  25%|##5       | 5/20 [10:46<31:58, 127.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 20:30:04 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 20:30:04 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:30:04 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 20:30:04 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:30:04 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:30:04 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9793814420700073, 'recall': 0.9018987417221069, 'f1': 0.9390444755554199}\n",
            "\n",
            "2024-05-29 20:30:04 :: encode posts per user in batch ...\n",
            "2024-05-29 20:30:04 :: First two user ids in current batch: [2741334519] and [2243710677]\n",
            "called:  (914, 768)\n",
            "called:  (201, 768)\n",
            "called:  (598, 768)\n",
            "called:  (299, 768)\n",
            "called:  (259, 768)\n",
            "called:  (410, 768)\n",
            "called:  (556, 768)\n",
            "called:  (284, 768)\n",
            "called:  (900, 768)\n",
            "called:  (812, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9803, recall: 0.9018, f1: 0.9394, accuracy: 0.9414, batch_loss: 0.0918, loss: 0.0879 ||:  30%|###       | 6/20 [12:25<27:35, 118.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 20:31:43 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 20:31:43 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:31:43 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 20:31:43 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:31:43 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:31:43 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9803370833396912, 'recall': 0.9018087983131409, 'f1': 0.9394347071647644}\n",
            "\n",
            "2024-05-29 20:31:43 :: encode posts per user in batch ...\n",
            "2024-05-29 20:31:43 :: First two user ids in current batch: [2918966551] and [446668784]\n",
            "called:  (230, 768)\n",
            "called:  (225, 768)\n",
            "called:  (257, 768)\n",
            "called:  (1025, 768)\n",
            "called:  (692, 768)\n",
            "called:  (840, 768)\n",
            "called:  (356, 768)\n",
            "called:  (420, 768)\n",
            "called:  (503, 768)\n",
            "called:  (493, 768)\n",
            "called:  (784, 768)\n",
            "called:  (249, 768)\n",
            "called:  (622, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9831, recall: 0.8985, f1: 0.9389, accuracy: 0.9408, batch_loss: 0.1770, loss: 0.1007 ||:  35%|###5      | 7/20 [14:26<25:48, 119.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 20:33:44 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 20:33:44 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:33:44 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 20:33:44 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:33:44 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:33:44 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9830917716026306, 'recall': 0.8984547257423401, 'f1': 0.9388696551322937}\n",
            "\n",
            "2024-05-29 20:33:44 :: encode posts per user in batch ...\n",
            "2024-05-29 20:33:44 :: First two user ids in current batch: [554055291] and [3007014726]\n",
            "called:  (358, 768)\n",
            "called:  (313, 768)\n",
            "called:  (655, 768)\n",
            "called:  (529, 768)\n",
            "called:  (226, 768)\n",
            "called:  (616, 768)\n",
            "called:  (632, 768)\n",
            "called:  (464, 768)\n",
            "called:  (458, 768)\n",
            "called:  (233, 768)\n",
            "called:  (397, 768)\n",
            "called:  (383, 768)\n",
            "called:  (347, 768)\n",
            "called:  (1059, 768)\n",
            "called:  (263, 768)\n",
            "called:  (1567, 768)\n",
            "called:  (290, 768)\n",
            "called:  (216, 768)\n",
            "called:  (1237, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9851, recall: 0.8990, f1: 0.9401, accuracy: 0.9424, batch_loss: 0.0604, loss: 0.0956 ||:  40%|####      | 8/20 [17:16<27:04, 135.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 20:36:34 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 20:36:34 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:36:34 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 20:36:34 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:36:34 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:36:34 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9851064085960388, 'recall': 0.8990291357040405, 'f1': 0.9401015639305115}\n",
            "\n",
            "2024-05-29 20:36:34 :: encode posts per user in batch ...\n",
            "2024-05-29 20:36:34 :: First two user ids in current batch: [78507635] and [930303488]\n",
            "called:  (283, 768)\n",
            "called:  (235, 768)\n",
            "called:  (206, 768)\n",
            "called:  (627, 768)\n",
            "called:  (279, 768)\n",
            "called:  (465, 768)\n",
            "called:  (2037, 768)\n",
            "called:  (1909, 768)\n",
            "called:  (861, 768)\n",
            "called:  (222, 768)\n",
            "called:  (426, 768)\n",
            "called:  (220, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9848, recall: 0.8993, f1: 0.9401, accuracy: 0.9427, batch_loss: 0.1724, loss: 0.1041 ||:  45%|####5     | 9/20 [19:28<24:36, 134.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 20:38:46 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 20:38:46 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:38:46 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 20:38:46 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:38:46 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:38:46 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9847908616065979, 'recall': 0.8993055820465088, 'f1': 0.9401089549064636}\n",
            "\n",
            "2024-05-29 20:38:46 :: encode posts per user in batch ...\n",
            "2024-05-29 20:38:46 :: First two user ids in current batch: [2790661073] and [2865113403]\n",
            "called:  (1463, 768)\n",
            "called:  (241, 768)\n",
            "called:  (283, 768)\n",
            "called:  (213, 768)\n",
            "called:  (959, 768)\n",
            "called:  (524, 768)\n",
            "called:  (269, 768)\n",
            "called:  (1012, 768)\n",
            "called:  (323, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9866, recall: 0.8994, f1: 0.9410, accuracy: 0.9422, batch_loss: 0.0808, loss: 0.1018 ||:  50%|#####     | 10/20 [21:10<20:43, 124.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 20:40:28 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 20:40:28 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:40:28 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 20:40:28 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:40:28 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:40:28 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9866220951080322, 'recall': 0.8993902206420898, 'f1': 0.9409888386726379}\n",
            "\n",
            "2024-05-29 20:40:28 :: encode posts per user in batch ...\n",
            "2024-05-29 20:40:28 :: First two user ids in current batch: [3437394741] and [552526204]\n",
            "called:  (610, 768)\n",
            "called:  (1065, 768)\n",
            "called:  (232, 768)\n",
            "called:  (320, 768)\n",
            "called:  (323, 768)\n",
            "called:  (390, 768)\n",
            "called:  (266, 768)\n",
            "called:  (493, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9846, recall: 0.9015, f1: 0.9413, accuracy: 0.9432, batch_loss: 0.0917, loss: 0.1009 ||:  55%|#####5    | 11/20 [22:26<16:24, 109.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 20:41:44 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 20:41:44 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:41:44 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 20:41:44 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:41:44 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:41:44 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9846389889717102, 'recall': 0.9015471339225769, 'f1': 0.9412628412246704}\n",
            "\n",
            "2024-05-29 20:41:44 :: encode posts per user in batch ...\n",
            "2024-05-29 20:41:44 :: First two user ids in current batch: [366302854] and [405410100]\n",
            "called:  (2317, 768)\n",
            "called:  (1560, 768)\n",
            "called:  (831, 768)\n",
            "called:  (1230, 768)\n",
            "called:  (389, 768)\n",
            "called:  (942, 768)\n",
            "called:  (279, 768)\n",
            "called:  (1601, 768)\n",
            "called:  (407, 768)\n",
            "called:  (1362, 768)\n",
            "called:  (483, 768)\n",
            "called:  (498, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9844, recall: 0.9073, f1: 0.9443, accuracy: 0.9466, batch_loss: 0.0883, loss: 0.0998 ||:  60%|######    | 12/20 [25:40<18:01, 135.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 20:44:58 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 20:44:58 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:44:58 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 20:44:58 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:44:58 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:44:58 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9844192862510681, 'recall': 0.9073107242584229, 'f1': 0.9442934393882751}\n",
            "\n",
            "2024-05-29 20:44:58 :: encode posts per user in batch ...\n",
            "2024-05-29 20:44:58 :: First two user ids in current batch: [806661615802122240] and [1190381972]\n",
            "called:  (1594, 768)\n",
            "called:  (385, 768)\n",
            "called:  (520, 768)\n",
            "called:  (942, 768)\n",
            "called:  (850, 768)\n",
            "called:  (231, 768)\n",
            "called:  (2668, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9815, recall: 0.9051, f1: 0.9418, accuracy: 0.9447, batch_loss: 0.1212, loss: 0.1015 ||:  65%|######5   | 13/20 [27:36<15:05, 129.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 20:46:54 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 20:46:54 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:46:54 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 20:46:54 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:46:54 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:46:54 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9815303683280945, 'recall': 0.9051094651222229, 'f1': 0.9417721629142761}\n",
            "\n",
            "2024-05-29 20:46:54 :: encode posts per user in batch ...\n",
            "2024-05-29 20:46:54 :: First two user ids in current batch: [2279792912] and [877474579]\n",
            "called:  (216, 768)\n",
            "called:  (468, 768)\n",
            "called:  (1284, 768)\n",
            "called:  (237, 768)\n",
            "called:  (936, 768)\n",
            "called:  (376, 768)\n",
            "called:  (541, 768)\n",
            "called:  (456, 768)\n",
            "called:  (263, 768)\n",
            "called:  (236, 768)\n",
            "called:  (207, 768)\n",
            "called:  (328, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9830, recall: 0.9009, f1: 0.9402, accuracy: 0.9425, batch_loss: 0.1087, loss: 0.1020 ||:  70%|#######   | 14/20 [29:22<12:13, 122.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 20:48:40 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 20:48:40 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:48:40 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 20:48:40 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:48:40 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:48:40 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9829890727996826, 'recall': 0.9008908867835999, 'f1': 0.9401510953903198}\n",
            "\n",
            "2024-05-29 20:48:40 :: encode posts per user in batch ...\n",
            "2024-05-29 20:48:40 :: First two user ids in current batch: [406564080] and [21981999]\n",
            "called:  (641, 768)\n",
            "called:  (389, 768)\n",
            "called:  (228, 768)\n",
            "called:  (294, 768)\n",
            "called:  (1772, 768)\n",
            "called:  (2042, 768)\n",
            "called:  (1572, 768)\n",
            "called:  (1181, 768)\n",
            "called:  (437, 768)\n",
            "called:  (326, 768)\n",
            "called:  (297, 768)\n",
            "called:  (535, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9842, recall: 0.9028, f1: 0.9417, accuracy: 0.9437, batch_loss: 0.0692, loss: 0.0998 ||:  75%|#######5  | 15/20 [31:57<11:01, 132.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 20:51:15 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 20:51:15 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:51:15 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 20:51:15 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:51:15 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:51:15 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9842164516448975, 'recall': 0.9027921557426453, 'f1': 0.9417475461959839}\n",
            "\n",
            "2024-05-29 20:51:15 :: encode posts per user in batch ...\n",
            "2024-05-29 20:51:15 :: First two user ids in current batch: [1702159368] and [449480815]\n",
            "called:  (517, 768)\n",
            "called:  (826, 768)\n",
            "called:  (523, 768)\n",
            "called:  (288, 768)\n",
            "called:  (259, 768)\n",
            "called:  (1638, 768)\n",
            "called:  (618, 768)\n",
            "called:  (262, 768)\n",
            "called:  (947, 768)\n",
            "called:  (262, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9851, recall: 0.9001, f1: 0.9407, accuracy: 0.9429, batch_loss: 0.0713, loss: 0.0980 ||:  80%|########  | 16/20 [33:49<08:25, 126.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 20:53:08 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 20:53:08 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:53:08 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 20:53:08 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:53:08 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:53:08 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9851379990577698, 'recall': 0.9000970125198364, 'f1': 0.9406993985176086}\n",
            "\n",
            "2024-05-29 20:53:08 :: encode posts per user in batch ...\n",
            "2024-05-29 20:53:08 :: First two user ids in current batch: [82766288] and [18931850]\n",
            "called:  (854, 768)\n",
            "called:  (296, 768)\n",
            "called:  (304, 768)\n",
            "called:  (338, 768)\n",
            "called:  (539, 768)\n",
            "called:  (254, 768)\n",
            "called:  (223, 768)\n",
            "called:  (804, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9861, recall: 0.8984, f1: 0.9402, accuracy: 0.9421, batch_loss: 0.1186, loss: 0.0992 ||:  85%|########5 | 17/20 [35:07<05:34, 111.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 20:54:25 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 20:54:25 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:54:25 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 20:54:25 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:54:25 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:54:25 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9860557913780212, 'recall': 0.8983666300773621, 'f1': 0.9401710033416748}\n",
            "\n",
            "2024-05-29 20:54:25 :: encode posts per user in batch ...\n",
            "2024-05-29 20:54:25 :: First two user ids in current batch: [1963704404] and [283280241]\n",
            "called:  (1983, 768)\n",
            "called:  (323, 768)\n",
            "called:  (326, 768)\n",
            "called:  (207, 768)\n",
            "called:  (2068, 768)\n",
            "called:  (2116, 768)\n",
            "called:  (822, 768)\n",
            "called:  (336, 768)\n",
            "called:  (208, 768)\n",
            "called:  (383, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9869, recall: 0.8948, f1: 0.9386, accuracy: 0.9401, batch_loss: 0.1290, loss: 0.1009 ||:  90%|######### | 18/20 [37:40<04:08, 124.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 20:56:58 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 20:56:58 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:56:58 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 20:56:58 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:56:58 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:56:58 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9869036674499512, 'recall': 0.8948261141777039, 'f1': 0.9386121034622192}\n",
            "\n",
            "2024-05-29 20:56:58 :: encode posts per user in batch ...\n",
            "2024-05-29 20:56:58 :: First two user ids in current batch: [251213136] and [1642162190]\n",
            "called:  (267, 768)\n",
            "called:  (1230, 768)\n",
            "called:  (800, 768)\n",
            "called:  (282, 768)\n",
            "called:  (651, 768)\n",
            "called:  (451, 768)\n",
            "called:  (441, 768)\n",
            "called:  (600, 768)\n",
            "called:  (222, 768)\n",
            "called:  (320, 768)\n",
            "called:  (685, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9876, recall: 0.8917, f1: 0.9372, accuracy: 0.9387, batch_loss: 0.1593, loss: 0.1040 ||:  95%|#########5| 19/20 [39:38<02:02, 122.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 20:58:56 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 20:58:56 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:58:56 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 20:58:56 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:58:56 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 20:58:56 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9875555634498596, 'recall': 0.891653299331665, 'f1': 0.9371573328971863}\n",
            "\n",
            "2024-05-29 20:58:56 :: encode posts per user in batch ...\n",
            "2024-05-29 20:58:56 :: First two user ids in current batch: [2968214963] and [1974109692]\n",
            "called:  (255, 768)\n",
            "called:  (937, 768)\n",
            "called:  (294, 768)\n",
            "called:  (553, 768)\n",
            "called:  (482, 768)\n",
            "called:  (371, 768)\n",
            "called:  (276, 768)\n",
            "called:  (420, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "precision: 0.9871, recall: 0.8888, f1: 0.9354, accuracy: 0.9370, batch_loss: 0.1347, loss: 0.1055 ||: 100%|##########| 20/20 [40:52<00:00, 122.63s/it]\n",
            "  0%|          | 0/7 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 21:00:10 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 21:00:10 :: tensor size after padding: torch.Size([92, 200, 768])\n",
            "2024-05-29 21:00:10 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([92, 200, 768])]\n",
            "2024-05-29 21:00:10 :: post masking: content [torch.Size([92, 200])]\n",
            "new tenor size: torch.Size([92, 200, 768])\n",
            "2024-05-29 21:00:10 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([92, 200, 768])\n",
            "2024-05-29 21:00:10 :: post reprsentation shape : torch.Size([92, 768])\n",
            "{'precision': 0.9871355295181274, 'recall': 0.8888030648231506, 'f1': 0.9353920817375183}\n",
            "\n",
            "{'precision': 0.9871355295181274, 'recall': 0.8888030648231506, 'f1': 0.9353920817375183}\n",
            "\n",
            "2024-05-29 21:00:10 :: encode posts per user in batch ...\n",
            "2024-05-29 21:00:10 :: First two user ids in current batch: [1730529132] and [283343890]\n",
            "called:  (216, 768)\n",
            "called:  (351, 768)\n",
            "called:  (421, 768)\n",
            "called:  (207, 768)\n",
            "called:  (1311, 768)\n",
            "called:  (214, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9848, recall: 0.9848, f1: 0.9848, accuracy: 0.9844, batch_loss: 0.0459, loss: 0.0459 ||:  14%|#4        | 1/7 [00:52<05:17, 52.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 21:01:03 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 21:01:03 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:01:03 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 21:01:03 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:01:03 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:01:03 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9848484992980957, 'recall': 0.9848484992980957, 'f1': 0.9848484992980957}\n",
            "\n",
            "2024-05-29 21:01:03 :: encode posts per user in batch ...\n",
            "2024-05-29 21:01:03 :: First two user ids in current batch: [289517716] and [1969705825]\n",
            "called:  (772, 768)\n",
            "called:  (348, 768)\n",
            "called:  (236, 768)\n",
            "called:  (507, 768)\n",
            "called:  (292, 768)\n",
            "called:  (218, 768)\n",
            "called:  (431, 768)\n",
            "called:  (310, 768)\n",
            "called:  (371, 768)\n",
            "called:  (874, 768)\n",
            "called:  (241, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9931, recall: 0.9931, f1: 0.9931, accuracy: 0.9922, batch_loss: 0.0076, loss: 0.0267 ||:  29%|##8       | 2/7 [02:15<05:52, 70.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 21:02:26 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 21:02:26 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:02:26 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 21:02:26 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:02:26 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:02:26 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9930555820465088, 'recall': 0.9930555820465088, 'f1': 0.9930555820465088}\n",
            "\n",
            "2024-05-29 21:02:26 :: encode posts per user in batch ...\n",
            "2024-05-29 21:02:26 :: First two user ids in current batch: [1561040862] and [319927976]\n",
            "called:  (1477, 768)\n",
            "called:  (232, 768)\n",
            "called:  (249, 768)\n",
            "called:  (989, 768)\n",
            "called:  (318, 768)\n",
            "called:  (251, 768)\n",
            "called:  (352, 768)\n",
            "called:  (522, 768)\n",
            "called:  (1923, 768)\n",
            "called:  (226, 768)\n",
            "called:  (232, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9906, recall: 0.9953, f1: 0.9929, accuracy: 0.9922, batch_loss: 0.0276, loss: 0.0270 ||:  43%|####2     | 3/7 [04:02<05:48, 87.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 21:04:13 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 21:04:13 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:04:13 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 21:04:13 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:04:13 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:04:13 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9905660152435303, 'recall': 0.9952606558799744, 'f1': 0.9929077625274658}\n",
            "\n",
            "2024-05-29 21:04:13 :: encode posts per user in batch ...\n",
            "2024-05-29 21:04:13 :: First two user ids in current batch: [227392175] and [712363806299545600]\n",
            "called:  (215, 768)\n",
            "called:  (2229, 768)\n",
            "called:  (212, 768)\n",
            "called:  (246, 768)\n",
            "called:  (219, 768)\n",
            "called:  (302, 768)\n",
            "called:  (523, 768)\n",
            "called:  (440, 768)\n",
            "called:  (207, 768)\n",
            "called:  (222, 768)\n",
            "called:  (283, 768)\n",
            "called:  (1194, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9927, recall: 0.9963, f1: 0.9945, accuracy: 0.9941, batch_loss: 0.0121, loss: 0.0233 ||:  57%|#####7    | 4/7 [05:45<04:40, 93.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 21:05:56 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 21:05:56 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:05:56 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 21:05:56 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:05:56 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:05:56 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9927007555961609, 'recall': 0.9963369965553284, 'f1': 0.994515597820282}\n",
            "\n",
            "2024-05-29 21:05:56 :: encode posts per user in batch ...\n",
            "2024-05-29 21:05:56 :: First two user ids in current batch: [143854547] and [811208472838729728]\n",
            "called:  (401, 768)\n",
            "called:  (223, 768)\n",
            "called:  (751, 768)\n",
            "called:  (336, 768)\n",
            "called:  (1122, 768)\n",
            "called:  (1276, 768)\n",
            "called:  (242, 768)\n",
            "called:  (324, 768)\n",
            "called:  (303, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9881, recall: 0.9940, f1: 0.9910, accuracy: 0.9906, batch_loss: 0.0890, loss: 0.0364 ||:  71%|#######1  | 5/7 [07:20<03:07, 93.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 21:07:31 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 21:07:31 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:07:31 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 21:07:31 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:07:31 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:07:31 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9880596995353699, 'recall': 0.9939939975738525, 'f1': 0.9910179376602173}\n",
            "\n",
            "2024-05-29 21:07:31 :: encode posts per user in batch ...\n",
            "2024-05-29 21:07:31 :: First two user ids in current batch: [61814345] and [1618708531]\n",
            "called:  (932, 768)\n",
            "called:  (947, 768)\n",
            "called:  (269, 768)\n",
            "called:  (289, 768)\n",
            "called:  (608, 768)\n",
            "called:  (329, 768)\n",
            "called:  (285, 768)\n",
            "called:  (265, 768)\n",
            "called:  (1604, 768)\n",
            "called:  (366, 768)\n",
            "called:  (297, 768)\n",
            "called:  (226, 768)\n",
            "called:  (309, 768)\n",
            "called:  (1078, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9877, recall: 0.9926, f1: 0.9901, accuracy: 0.9896, batch_loss: 0.0575, loss: 0.0399 ||:  86%|########5 | 6/7 [09:27<01:45, 105.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 21:09:38 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 21:09:38 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:09:38 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 21:09:38 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:09:38 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:09:38 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9876543283462524, 'recall': 0.9925558567047119, 'f1': 0.9900990128517151}\n",
            "\n",
            "2024-05-29 21:09:38 :: encode posts per user in batch ...\n",
            "2024-05-29 21:09:38 :: First two user ids in current batch: [38006938] and [2967547485]\n",
            "called:  (2606, 768)\n",
            "called:  (666, 768)\n",
            "called:  (985, 768)\n",
            "called:  (1008, 768)\n",
            "called:  (449, 768)\n",
            "called:  (201, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "precision: 0.9885, recall: 0.9931, f1: 0.9908, accuracy: 0.9905, batch_loss: 0.0068, loss: 0.0352 ||: 100%|##########| 7/7 [10:57<00:00, 93.87s/it] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 21:11:07 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 21:11:07 :: tensor size after padding: torch.Size([74, 200, 768])\n",
            "2024-05-29 21:11:07 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([74, 200, 768])]\n",
            "2024-05-29 21:11:07 :: post masking: content [torch.Size([74, 200])]\n",
            "new tenor size: torch.Size([74, 200, 768])\n",
            "2024-05-29 21:11:07 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([74, 200, 768])\n",
            "2024-05-29 21:11:07 :: post reprsentation shape : torch.Size([74, 768])\n",
            "{'precision': 0.9884792566299438, 'recall': 0.9930555820465088, 'f1': 0.9907621145248413}\n",
            "\n",
            "{'precision': 0.9884792566299438, 'recall': 0.9930555820465088, 'f1': 0.9907621145248413}\n",
            "\n",
            "Metrics at the end of epoch: 3 {'best_epoch': 3, 'peak_worker_0_memory_MB': 2067.90234375, 'peak_gpu_0_memory_MB': 1573.1474609375, 'training_duration': '3:29:10.171051', 'epoch': 3, 'training_precision': 0.9871355295181274, 'training_recall': 0.8888030648231506, 'training_f1': 0.9353920817375183, 'training_accuracy': 0.9370047543581617, 'training_loss': 0.10551146045327187, 'training_worker_0_memory_MB': 2067.90234375, 'training_gpu_0_memory_MB': 1573.1474609375, 'validation_precision': 0.9884792566299438, 'validation_recall': 0.9930555820465088, 'validation_f1': 0.9907621145248413, 'validation_accuracy': 0.9904988123515439, 'validation_loss': 0.03520463187513607, 'best_validation_precision': 0.9884792566299438, 'best_validation_recall': 0.9930555820465088, 'best_validation_f1': 0.9907621145248413, 'best_validation_accuracy': 0.9904988123515439, 'best_validation_loss': 0.03520463187513607}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/cuda/memory.py:330: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
            "  warnings.warn(\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 21:11:09 :: encode posts per user in batch ...\n",
            "2024-05-29 21:11:09 :: First two user ids in current batch: [965350130] and [817588767183618048]\n",
            "called:  (377, 768)\n",
            "called:  (1543, 768)\n",
            "called:  (835, 768)\n",
            "called:  (936, 768)\n",
            "called:  (230, 768)\n",
            "called:  (942, 768)\n",
            "called:  (430, 768)\n",
            "called:  (511, 768)\n",
            "called:  (410, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 1.0000, recall: 0.8852, f1: 0.9391, accuracy: 0.9453, batch_loss: 0.0710, loss: 0.0710 ||:   5%|5         | 1/20 [01:45<33:27, 105.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 21:12:54 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 21:12:54 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:12:54 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 21:12:54 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:12:54 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:12:54 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 1.0, 'recall': 0.8852459192276001, 'f1': 0.939130425453186}\n",
            "\n",
            "2024-05-29 21:12:55 :: encode posts per user in batch ...\n",
            "2024-05-29 21:12:55 :: First two user ids in current batch: [52139876] and [20472126]\n",
            "called:  (385, 768)\n",
            "called:  (390, 768)\n",
            "called:  (241, 768)\n",
            "called:  (373, 768)\n",
            "called:  (1772, 768)\n",
            "called:  (527, 768)\n",
            "called:  (326, 768)\n",
            "called:  (553, 768)\n",
            "called:  (1012, 768)\n",
            "called:  (389, 768)\n",
            "called:  (290, 768)\n",
            "called:  (244, 768)\n",
            "called:  (213, 768)\n",
            "called:  (336, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9835, recall: 0.8947, f1: 0.9370, accuracy: 0.9375, batch_loss: 0.1378, loss: 0.1044 ||:  10%|#         | 2/20 [03:53<35:35, 118.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 21:15:02 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 21:15:02 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:15:02 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 21:15:02 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:15:02 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:15:02 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9834710955619812, 'recall': 0.8947368264198303, 'f1': 0.9370078444480896}\n",
            "\n",
            "2024-05-29 21:15:02 :: encode posts per user in batch ...\n",
            "2024-05-29 21:15:02 :: First two user ids in current batch: [2573307627] and [283280241]\n",
            "called:  (937, 768)\n",
            "called:  (1983, 768)\n",
            "called:  (412, 768)\n",
            "called:  (850, 768)\n",
            "called:  (254, 768)\n",
            "called:  (383, 768)\n",
            "called:  (313, 768)\n",
            "called:  (294, 768)\n",
            "called:  (2068, 768)\n",
            "called:  (464, 768)\n",
            "called:  (2534, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9783, recall: 0.9000, f1: 0.9375, accuracy: 0.9375, batch_loss: 0.1086, loss: 0.1058 ||:  15%|#5        | 3/20 [06:40<39:55, 140.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 21:17:50 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 21:17:50 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:17:50 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 21:17:50 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:17:50 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:17:50 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.97826087474823, 'recall': 0.8999999761581421, 'f1': 0.9375}\n",
            "\n",
            "2024-05-29 21:17:50 :: encode posts per user in batch ...\n",
            "2024-05-29 21:17:50 :: First two user ids in current batch: [2235795476] and [1522322629]\n",
            "called:  (1638, 768)\n",
            "called:  (441, 768)\n",
            "called:  (233, 768)\n",
            "called:  (222, 768)\n",
            "called:  (320, 768)\n",
            "called:  (262, 768)\n",
            "called:  (347, 768)\n",
            "called:  (323, 768)\n",
            "called:  (437, 768)\n",
            "called:  (1270, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9832, recall: 0.9105, f1: 0.9455, accuracy: 0.9473, batch_loss: 0.0737, loss: 0.0978 ||:  20%|##        | 4/20 [08:22<33:24, 125.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 21:19:31 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 21:19:31 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:19:31 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 21:19:31 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:19:31 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:19:31 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9831932783126831, 'recall': 0.9105058312416077, 'f1': 0.9454545378684998}\n",
            "\n",
            "2024-05-29 21:19:31 :: encode posts per user in batch ...\n",
            "2024-05-29 21:19:31 :: First two user ids in current batch: [877474579] and [1029337302]\n",
            "called:  (861, 768)\n",
            "called:  (299, 768)\n",
            "called:  (208, 768)\n",
            "called:  (231, 768)\n",
            "called:  (458, 768)\n",
            "called:  (616, 768)\n",
            "called:  (263, 768)\n",
            "called:  (535, 768)\n",
            "called:  (600, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9797, recall: 0.9034, f1: 0.9400, accuracy: 0.9422, batch_loss: 0.1440, loss: 0.1070 ||:  25%|##5       | 5/20 [09:47<27:43, 110.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 21:20:56 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 21:20:56 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:20:56 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 21:20:56 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:20:56 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:20:56 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9797297120094299, 'recall': 0.9034267663955688, 'f1': 0.940032422542572}\n",
            "\n",
            "2024-05-29 21:20:56 :: encode posts per user in batch ...\n",
            "2024-05-29 21:20:56 :: First two user ids in current batch: [2643252453] and [625510444]\n",
            "called:  (2116, 768)\n",
            "called:  (337, 768)\n",
            "called:  (493, 768)\n",
            "called:  (444, 768)\n",
            "called:  (900, 768)\n",
            "called:  (706, 768)\n",
            "called:  (569, 768)\n",
            "called:  (1096, 768)\n",
            "called:  (283, 768)\n",
            "called:  (655, 768)\n",
            "called:  (325, 768)\n",
            "called:  (376, 768)\n",
            "called:  (598, 768)\n",
            "called:  (371, 768)\n",
            "called:  (539, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9806, recall: 0.9124, f1: 0.9453, accuracy: 0.9466, batch_loss: 0.0753, loss: 0.1017 ||:  30%|###       | 6/20 [12:35<30:24, 130.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 21:23:44 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 21:23:44 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:23:44 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 21:23:44 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:23:44 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:23:44 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9806094169616699, 'recall': 0.9123711585998535, 'f1': 0.9452603459358215}\n",
            "\n",
            "2024-05-29 21:23:44 :: encode posts per user in batch ...\n",
            "2024-05-29 21:23:44 :: First two user ids in current batch: [326843908] and [2291296526]\n",
            "called:  (284, 768)\n",
            "called:  (804, 768)\n",
            "called:  (232, 768)\n",
            "called:  (254, 768)\n",
            "called:  (1601, 768)\n",
            "called:  (556, 768)\n",
            "called:  (632, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9838, recall: 0.9142, f1: 0.9477, accuracy: 0.9475, batch_loss: 0.0702, loss: 0.0972 ||:  35%|###5      | 7/20 [14:02<25:11, 116.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 21:25:12 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 21:25:12 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:25:12 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 21:25:12 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:25:12 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:25:12 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9838337302207947, 'recall': 0.9141631126403809, 'f1': 0.9477196931838989}\n",
            "\n",
            "2024-05-29 21:25:12 :: encode posts per user in batch ...\n",
            "2024-05-29 21:25:12 :: First two user ids in current batch: [722076794] and [43310694]\n",
            "called:  (555, 768)\n",
            "called:  (451, 768)\n",
            "called:  (2298, 768)\n",
            "called:  (439, 768)\n",
            "called:  (262, 768)\n",
            "called:  (541, 768)\n",
            "called:  (1103, 768)\n",
            "called:  (206, 768)\n",
            "called:  (822, 768)\n",
            "called:  (255, 768)\n",
            "called:  (641, 768)\n",
            "called:  (304, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9857, recall: 0.9163, f1: 0.9498, accuracy: 0.9502, batch_loss: 0.0633, loss: 0.0930 ||:  40%|####      | 8/20 [16:16<24:22, 121.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 21:27:26 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 21:27:26 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:27:26 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 21:27:26 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:27:26 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:27:26 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9856850504875183, 'recall': 0.9163498282432556, 'f1': 0.9497537016868591}\n",
            "\n",
            "2024-05-29 21:27:26 :: encode posts per user in batch ...\n",
            "2024-05-29 21:27:26 :: First two user ids in current batch: [16205293] and [258637444]\n",
            "called:  (283, 768)\n",
            "called:  (269, 768)\n",
            "called:  (420, 768)\n",
            "called:  (279, 768)\n",
            "called:  (282, 768)\n",
            "called:  (800, 768)\n",
            "called:  (1065, 768)\n",
            "called:  (464, 768)\n",
            "called:  (1230, 768)\n",
            "called:  (279, 768)\n",
            "called:  (237, 768)\n",
            "called:  (465, 768)\n",
            "called:  (2317, 768)\n",
            "called:  (515, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9870, recall: 0.9049, f1: 0.9442, accuracy: 0.9453, batch_loss: 0.2581, loss: 0.1113 ||:  45%|####5     | 9/20 [18:51<24:14, 132.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 21:30:00 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 21:30:00 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:30:00 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 21:30:00 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:30:00 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:30:00 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9870370626449585, 'recall': 0.9049236178398132, 'f1': 0.9441984295845032}\n",
            "\n",
            "2024-05-29 21:30:01 :: encode posts per user in batch ...\n",
            "2024-05-29 21:30:01 :: First two user ids in current batch: [1974176420] and [353910331]\n",
            "called:  (644, 768)\n",
            "called:  (950, 768)\n",
            "called:  (266, 768)\n",
            "called:  (498, 768)\n",
            "called:  (323, 768)\n",
            "called:  (2037, 768)\n",
            "called:  (267, 768)\n",
            "called:  (323, 768)\n",
            "called:  (376, 768)\n",
            "called:  (207, 768)\n",
            "called:  (358, 768)\n",
            "called:  (1025, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9867, recall: 0.8997, f1: 0.9412, accuracy: 0.9422, batch_loss: 0.2604, loss: 0.1262 ||:  50%|#####     | 10/20 [21:01<21:54, 131.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 21:32:10 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 21:32:10 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:32:10 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 21:32:10 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:32:10 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:32:10 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9866666793823242, 'recall': 0.8996960520744324, 'f1': 0.9411764740943909}\n",
            "\n",
            "2024-05-29 21:32:10 :: encode posts per user in batch ...\n",
            "2024-05-29 21:32:10 :: First two user ids in current batch: [729051858] and [163766999]\n",
            "called:  (503, 768)\n",
            "called:  (959, 768)\n",
            "called:  (1572, 768)\n",
            "called:  (514, 768)\n",
            "called:  (280, 768)\n",
            "called:  (812, 768)\n",
            "called:  (2062, 768)\n",
            "called:  (2668, 768)\n",
            "called:  (795, 768)\n",
            "called:  (259, 768)\n",
            "called:  (426, 768)\n",
            "called:  (332, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9879, recall: 0.9034, f1: 0.9438, accuracy: 0.9446, batch_loss: 0.0521, loss: 0.1195 ||:  55%|#####5    | 11/20 [24:01<21:56, 146.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 21:35:10 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 21:35:10 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:35:10 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 21:35:10 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:35:10 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:35:10 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9879336357116699, 'recall': 0.9034482836723328, 'f1': 0.9438040256500244}\n",
            "\n",
            "2024-05-29 21:35:10 :: encode posts per user in batch ...\n",
            "2024-05-29 21:35:10 :: First two user ids in current batch: [4095353712] and [431229229]\n",
            "called:  (1230, 768)\n",
            "called:  (529, 768)\n",
            "called:  (296, 768)\n",
            "called:  (326, 768)\n",
            "called:  (222, 768)\n",
            "called:  (610, 768)\n",
            "called:  (831, 768)\n",
            "called:  (360, 768)\n",
            "called:  (551, 768)\n",
            "called:  (356, 768)\n",
            "called:  (235, 768)\n",
            "called:  (201, 768)\n",
            "called:  (294, 768)\n",
            "called:  (216, 768)\n",
            "called:  (226, 768)\n",
            "called:  (1560, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9889, recall: 0.9038, f1: 0.9444, accuracy: 0.9453, batch_loss: 0.0642, loss: 0.1149 ||:  60%|######    | 12/20 [26:22<19:17, 144.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 21:37:31 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 21:37:31 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:37:31 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 21:37:31 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:37:31 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:37:31 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9889196753501892, 'recall': 0.903797447681427, 'f1': 0.944444477558136}\n",
            "\n",
            "2024-05-29 21:37:31 :: encode posts per user in batch ...\n",
            "2024-05-29 21:37:31 :: First two user ids in current batch: [1581797316] and [177770314]\n",
            "called:  (716, 768)\n",
            "called:  (673, 768)\n",
            "called:  (520, 768)\n",
            "called:  (499, 768)\n",
            "called:  (388, 768)\n",
            "called:  (223, 768)\n",
            "called:  (830, 768)\n",
            "called:  (627, 768)\n",
            "called:  (389, 768)\n",
            "called:  (786, 768)\n",
            "called:  (288, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9898, recall: 0.9038, f1: 0.9449, accuracy: 0.9453, batch_loss: 0.1010, loss: 0.1138 ||:  65%|######5   | 13/20 [28:12<15:39, 134.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 21:39:21 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 21:39:21 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:39:21 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 21:39:21 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:39:21 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:39:21 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.989847719669342, 'recall': 0.9038238525390625, 'f1': 0.9448819160461426}\n",
            "\n",
            "2024-05-29 21:39:21 :: encode posts per user in batch ...\n",
            "2024-05-29 21:39:21 :: First two user ids in current batch: [1017014683] and [258200262]\n",
            "called:  (692, 768)\n",
            "called:  (216, 768)\n",
            "called:  (249, 768)\n",
            "called:  (840, 768)\n",
            "called:  (453, 768)\n",
            "called:  (231, 768)\n",
            "called:  (517, 768)\n",
            "called:  (1463, 768)\n",
            "called:  (523, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9894, recall: 0.9017, f1: 0.9435, accuracy: 0.9436, batch_loss: 0.1097, loss: 0.1135 ||:  70%|#######   | 14/20 [29:53<12:25, 124.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 21:41:02 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 21:41:02 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:41:02 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 21:41:02 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:41:02 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:41:02 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9894490242004395, 'recall': 0.9017093777656555, 'f1': 0.9435439109802246}\n",
            "\n",
            "2024-05-29 21:41:02 :: encode posts per user in batch ...\n",
            "2024-05-29 21:41:02 :: First two user ids in current batch: [2901079435] and [1493259607]\n",
            "called:  (1362, 768)\n",
            "called:  (1284, 768)\n",
            "called:  (483, 768)\n",
            "called:  (338, 768)\n",
            "called:  (397, 768)\n",
            "called:  (947, 768)\n",
            "called:  (207, 768)\n",
            "called:  (634, 768)\n",
            "called:  (524, 768)\n",
            "called:  (942, 768)\n",
            "called:  (456, 768)\n",
            "called:  (297, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9891, recall: 0.9024, f1: 0.9438, accuracy: 0.9437, batch_loss: 0.1225, loss: 0.1141 ||:  75%|#######5  | 15/20 [32:14<10:47, 129.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 21:43:24 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 21:43:24 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:43:24 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 21:43:24 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:43:24 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:43:24 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9890829920768738, 'recall': 0.9023904204368591, 'f1': 0.9437500238418579}\n",
            "\n",
            "2024-05-29 21:43:24 :: encode posts per user in batch ...\n",
            "2024-05-29 21:43:24 :: First two user ids in current batch: [270206792] and [38893198]\n",
            "called:  (383, 768)\n",
            "called:  (458, 768)\n",
            "called:  (335, 768)\n",
            "called:  (468, 768)\n",
            "called:  (622, 768)\n",
            "called:  (2042, 768)\n",
            "called:  (477, 768)\n",
            "called:  (413, 768)\n",
            "called:  (329, 768)\n",
            "called:  (326, 768)\n",
            "called:  (328, 768)\n",
            "called:  (854, 768)\n",
            "called:  (618, 768)\n",
            "called:  (420, 768)\n",
            "called:  (784, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9877, recall: 0.9023, f1: 0.9430, accuracy: 0.9434, batch_loss: 0.0956, loss: 0.1130 ||:  80%|########  | 16/20 [34:45<09:03, 135.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 21:45:55 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 21:45:55 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:45:55 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 21:45:55 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:45:55 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:45:55 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9876543283462524, 'recall': 0.902255654335022, 'f1': 0.943025529384613}\n",
            "\n",
            "2024-05-29 21:45:55 :: encode posts per user in batch ...\n",
            "2024-05-29 21:45:55 :: First two user ids in current batch: [4802063834] and [207624369]\n",
            "called:  (1181, 768)\n",
            "called:  (1567, 768)\n",
            "called:  (493, 768)\n",
            "called:  (464, 768)\n",
            "called:  (257, 768)\n",
            "called:  (259, 768)\n",
            "called:  (352, 768)\n",
            "called:  (1909, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9864, recall: 0.9052, f1: 0.9440, accuracy: 0.9449, batch_loss: 0.1179, loss: 0.1133 ||:  85%|########5 | 17/20 [36:40<06:28, 129.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 21:47:49 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 21:47:49 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:47:49 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 21:47:49 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:47:49 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:47:49 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9863547682762146, 'recall': 0.9051878452301025, 'f1': 0.9440298080444336}\n",
            "\n",
            "2024-05-29 21:47:49 :: encode posts per user in batch ...\n",
            "2024-05-29 21:47:49 :: First two user ids in current batch: [31550805] and [3373054042]\n",
            "called:  (228, 768)\n",
            "called:  (220, 768)\n",
            "called:  (288, 768)\n",
            "called:  (229, 768)\n",
            "called:  (482, 768)\n",
            "called:  (651, 768)\n",
            "called:  (914, 768)\n",
            "called:  (320, 768)\n",
            "called:  (236, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9852, recall: 0.9058, f1: 0.9438, accuracy: 0.9449, batch_loss: 0.1240, loss: 0.1138 ||:  90%|######### | 18/20 [37:55<03:46, 113.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 21:49:04 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 21:49:04 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:49:04 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 21:49:04 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:49:04 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:49:04 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9852262139320374, 'recall': 0.9057725071907043, 'f1': 0.9438301920890808}\n",
            "\n",
            "2024-05-29 21:49:04 :: encode posts per user in batch ...\n",
            "2024-05-29 21:49:04 :: First two user ids in current batch: [1599347305] and [261655297]\n",
            "called:  (1594, 768)\n",
            "called:  (286, 768)\n",
            "called:  (1059, 768)\n",
            "called:  (685, 768)\n",
            "called:  (1237, 768)\n",
            "called:  (826, 768)\n",
            "called:  (2189, 768)\n",
            "called:  (413, 768)\n",
            "called:  (407, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9861, recall: 0.9073, f1: 0.9451, accuracy: 0.9457, batch_loss: 0.0816, loss: 0.1121 ||:  95%|#########5| 19/20 [40:20<02:02, 122.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 21:51:30 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 21:51:30 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:51:30 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 21:51:30 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:51:30 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:51:30 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9861111044883728, 'recall': 0.9073482155799866, 'f1': 0.9450914859771729}\n",
            "\n",
            "2024-05-29 21:51:30 :: encode posts per user in batch ...\n",
            "2024-05-29 21:51:30 :: First two user ids in current batch: [2326154136] and [1940562578]\n",
            "called:  (263, 768)\n",
            "called:  (225, 768)\n",
            "called:  (573, 768)\n",
            "called:  (276, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "precision: 0.9866, recall: 0.9089, f1: 0.9461, accuracy: 0.9469, batch_loss: 0.0800, loss: 0.1105 ||: 100%|##########| 20/20 [40:52<00:00, 122.60s/it]\n",
            "  0%|          | 0/7 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 21:52:01 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 21:52:01 :: tensor size after padding: torch.Size([92, 200, 768])\n",
            "2024-05-29 21:52:01 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([92, 200, 768])]\n",
            "2024-05-29 21:52:01 :: post masking: content [torch.Size([92, 200])]\n",
            "new tenor size: torch.Size([92, 200, 768])\n",
            "2024-05-29 21:52:01 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([92, 200, 768])\n",
            "2024-05-29 21:52:01 :: post reprsentation shape : torch.Size([92, 768])\n",
            "{'precision': 0.9865884184837341, 'recall': 0.9088802933692932, 'f1': 0.9461414813995361}\n",
            "\n",
            "{'precision': 0.9865884184837341, 'recall': 0.9088802933692932, 'f1': 0.9461414813995361}\n",
            "\n",
            "2024-05-29 21:52:01 :: encode posts per user in batch ...\n",
            "2024-05-29 21:52:01 :: First two user ids in current batch: [344251848] and [2755739349]\n",
            "called:  (207, 768)\n",
            "called:  (329, 768)\n",
            "called:  (522, 768)\n",
            "called:  (303, 768)\n",
            "called:  (947, 768)\n",
            "called:  (507, 768)\n",
            "called:  (348, 768)\n",
            "called:  (371, 768)\n",
            "called:  (222, 768)\n",
            "called:  (232, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 1.0000, recall: 1.0000, f1: 1.0000, accuracy: 1.0000, batch_loss: 0.0065, loss: 0.0065 ||:  14%|#4        | 1/7 [01:15<07:30, 75.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 21:53:16 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 21:53:16 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:53:16 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 21:53:16 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:53:16 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:53:16 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
            "\n",
            "2024-05-29 21:53:16 :: encode posts per user in batch ...\n",
            "2024-05-29 21:53:16 :: First two user ids in current batch: [714082286098976768] and [777149527]\n",
            "called:  (772, 768)\n",
            "called:  (309, 768)\n",
            "called:  (1276, 768)\n",
            "called:  (336, 768)\n",
            "called:  (352, 768)\n",
            "called:  (421, 768)\n",
            "called:  (608, 768)\n",
            "called:  (289, 768)\n",
            "called:  (292, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9922, recall: 0.9845, f1: 0.9883, accuracy: 0.9883, batch_loss: 0.0888, loss: 0.0476 ||:  29%|##8       | 2/7 [02:38<06:40, 80.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 21:54:40 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 21:54:40 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:54:40 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 21:54:40 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:54:40 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:54:40 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9921875, 'recall': 0.9844961166381836, 'f1': 0.9883268475532532}\n",
            "\n",
            "2024-05-29 21:54:40 :: encode posts per user in batch ...\n",
            "2024-05-29 21:54:40 :: First two user ids in current batch: [2647458960] and [932944561]\n",
            "called:  (251, 768)\n",
            "called:  (318, 768)\n",
            "called:  (2606, 768)\n",
            "called:  (207, 768)\n",
            "called:  (218, 768)\n",
            "called:  (246, 768)\n",
            "called:  (366, 768)\n",
            "called:  (1008, 768)\n",
            "called:  (302, 768)\n",
            "called:  (297, 768)\n",
            "called:  (285, 768)\n",
            "called:  (265, 768)\n",
            "called:  (1604, 768)\n",
            "called:  (874, 768)\n",
            "called:  (2229, 768)\n",
            "called:  (440, 768)\n",
            "called:  (324, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9950, recall: 0.9851, f1: 0.9900, accuracy: 0.9896, batch_loss: 0.0126, loss: 0.0360 ||:  43%|####2     | 3/7 [05:45<08:34, 128.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 21:57:46 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 21:57:46 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:57:46 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 21:57:46 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:57:46 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:57:46 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9950000047683716, 'recall': 0.9851484894752502, 'f1': 0.9900497198104858}\n",
            "\n",
            "2024-05-29 21:57:46 :: encode posts per user in batch ...\n",
            "2024-05-29 21:57:46 :: First two user ids in current batch: [432043324] and [3409020874]\n",
            "called:  (226, 768)\n",
            "called:  (219, 768)\n",
            "called:  (1078, 768)\n",
            "called:  (1923, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9924, recall: 0.9848, f1: 0.9886, accuracy: 0.9883, batch_loss: 0.0564, loss: 0.0411 ||:  57%|#####7    | 4/7 [06:50<05:11, 103.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 21:58:51 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 21:58:51 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:58:51 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 21:58:51 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:58:51 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 21:58:51 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9923664331436157, 'recall': 0.9848484992980957, 'f1': 0.9885931611061096}\n",
            "\n",
            "2024-05-29 21:58:51 :: encode posts per user in batch ...\n",
            "2024-05-29 21:58:51 :: First two user ids in current batch: [3135460644] and [153933177]\n",
            "called:  (1122, 768)\n",
            "called:  (985, 768)\n",
            "called:  (249, 768)\n",
            "called:  (1311, 768)\n",
            "called:  (269, 768)\n",
            "called:  (989, 768)\n",
            "called:  (401, 768)\n",
            "called:  (215, 768)\n",
            "called:  (523, 768)\n",
            "called:  (932, 768)\n",
            "called:  (1477, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9938, recall: 0.9847, f1: 0.9892, accuracy: 0.9891, batch_loss: 0.0118, loss: 0.0352 ||:  71%|#######1  | 5/7 [08:58<03:44, 112.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 22:00:59 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 22:00:59 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:00:59 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 22:00:59 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:00:59 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:00:59 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9938080310821533, 'recall': 0.9846625924110413, 'f1': 0.9892141819000244}\n",
            "\n",
            "2024-05-29 22:00:59 :: encode posts per user in batch ...\n",
            "2024-05-29 22:00:59 :: First two user ids in current batch: [2744988489] and [2465566448]\n",
            "called:  (201, 768)\n",
            "called:  (236, 768)\n",
            "called:  (241, 768)\n",
            "called:  (1194, 768)\n",
            "called:  (449, 768)\n",
            "called:  (216, 768)\n",
            "called:  (666, 768)\n",
            "called:  (223, 768)\n",
            "called:  (431, 768)\n",
            "called:  (751, 768)\n",
            "called:  (310, 768)\n",
            "called:  (351, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9948, recall: 0.9847, f1: 0.9897, accuracy: 0.9896, batch_loss: 0.0447, loss: 0.0368 ||:  86%|########5 | 6/7 [10:27<01:44, 104.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 22:02:28 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 22:02:28 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:02:28 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 22:02:28 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:02:28 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:02:28 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9948453903198242, 'recall': 0.9846938848495483, 'f1': 0.9897436499595642}\n",
            "\n",
            "2024-05-29 22:02:28 :: encode posts per user in batch ...\n",
            "2024-05-29 22:02:28 :: First two user ids in current batch: [23457444] and [1960053332]\n",
            "called:  (212, 768)\n",
            "called:  (226, 768)\n",
            "called:  (214, 768)\n",
            "called:  (242, 768)\n",
            "called:  (232, 768)\n",
            "called:  (283, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "precision: 0.9953, recall: 0.9838, f1: 0.9895, accuracy: 0.9893, batch_loss: 0.0156, loss: 0.0338 ||: 100%|##########| 7/7 [10:57<00:00, 93.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 22:02:59 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 22:02:59 :: tensor size after padding: torch.Size([74, 200, 768])\n",
            "2024-05-29 22:02:59 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([74, 200, 768])]\n",
            "2024-05-29 22:02:59 :: post masking: content [torch.Size([74, 200])]\n",
            "new tenor size: torch.Size([74, 200, 768])\n",
            "2024-05-29 22:02:59 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([74, 200, 768])\n",
            "2024-05-29 22:02:59 :: post reprsentation shape : torch.Size([74, 768])\n",
            "{'precision': 0.9953161478042603, 'recall': 0.9837962985038757, 'f1': 0.9895226955413818}\n",
            "\n",
            "{'precision': 0.9953161478042603, 'recall': 0.9837962985038757, 'f1': 0.9895226955413818}\n",
            "\n",
            "Metrics at the end of epoch: 4 {'best_epoch': 4, 'peak_worker_0_memory_MB': 2070.80859375, 'peak_gpu_0_memory_MB': 1573.1474609375, 'training_duration': '4:21:01.653271', 'epoch': 4, 'training_precision': 0.9865884184837341, 'training_recall': 0.9088802933692932, 'training_f1': 0.9461414813995361, 'training_accuracy': 0.9469096671949286, 'training_loss': 0.11054278463125229, 'training_worker_0_memory_MB': 2070.80859375, 'training_gpu_0_memory_MB': 1573.1474609375, 'validation_precision': 0.9953161478042603, 'validation_recall': 0.9837962985038757, 'validation_f1': 0.9895226955413818, 'validation_accuracy': 0.9893111638954869, 'validation_loss': 0.03378113305994442, 'best_validation_precision': 0.9953161478042603, 'best_validation_recall': 0.9837962985038757, 'best_validation_f1': 0.9895226955413818, 'best_validation_accuracy': 0.9893111638954869, 'best_validation_loss': 0.03378113305994442}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/cuda/memory.py:330: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
            "  warnings.warn(\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 22:03:00 :: encode posts per user in batch ...\n",
            "2024-05-29 22:03:00 :: First two user ids in current batch: [753047225979248640] and [88198660]\n",
            "called:  (468, 768)\n",
            "called:  (267, 768)\n",
            "called:  (1230, 768)\n",
            "called:  (294, 768)\n",
            "called:  (535, 768)\n",
            "called:  (854, 768)\n",
            "called:  (1270, 768)\n",
            "called:  (1230, 768)\n",
            "called:  (320, 768)\n",
            "called:  (826, 768)\n",
            "called:  (1567, 768)\n",
            "called:  (1543, 768)\n",
            "called:  (410, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 1.0000, recall: 0.9138, f1: 0.9550, accuracy: 0.9609, batch_loss: 0.0761, loss: 0.0761 ||:   5%|5         | 1/20 [02:47<53:05, 167.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 22:05:48 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 22:05:48 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:05:48 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 22:05:48 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:05:48 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:05:48 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 1.0, 'recall': 0.9137930870056152, 'f1': 0.9549549221992493}\n",
            "\n",
            "2024-05-29 22:05:48 :: encode posts per user in batch ...\n",
            "2024-05-29 22:05:48 :: First two user ids in current batch: [98682856] and [346973955]\n",
            "called:  (835, 768)\n",
            "called:  (254, 768)\n",
            "called:  (616, 768)\n",
            "called:  (527, 768)\n",
            "called:  (389, 768)\n",
            "called:  (233, 768)\n",
            "called:  (464, 768)\n",
            "called:  (1909, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 1.0000, recall: 0.9048, f1: 0.9500, accuracy: 0.9531, batch_loss: 0.0742, loss: 0.0752 ||:  10%|#         | 2/20 [04:26<38:10, 127.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 22:07:27 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 22:07:27 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:07:27 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 22:07:27 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:07:27 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:07:27 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 1.0, 'recall': 0.9047619104385376, 'f1': 0.949999988079071}\n",
            "\n",
            "2024-05-29 22:07:27 :: encode posts per user in batch ...\n",
            "2024-05-29 22:07:27 :: First two user ids in current batch: [2992646334] and [718148177765998593]\n",
            "called:  (950, 768)\n",
            "called:  (937, 768)\n",
            "called:  (263, 768)\n",
            "called:  (503, 768)\n",
            "called:  (804, 768)\n",
            "called:  (441, 768)\n",
            "called:  (437, 768)\n",
            "called:  (795, 768)\n",
            "called:  (257, 768)\n",
            "called:  (216, 768)\n",
            "called:  (237, 768)\n",
            "called:  (279, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 1.0000, recall: 0.8802, f1: 0.9363, accuracy: 0.9401, batch_loss: 0.1086, loss: 0.0863 ||:  15%|#5        | 3/20 [06:23<34:42, 122.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 22:09:24 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 22:09:24 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:09:24 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 22:09:24 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:09:24 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:09:24 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 1.0, 'recall': 0.8802083134651184, 'f1': 0.9362881183624268}\n",
            "\n",
            "2024-05-29 22:09:24 :: encode posts per user in batch ...\n",
            "2024-05-29 22:09:24 :: First two user ids in current batch: [139571936] and [2996392185]\n",
            "called:  (651, 768)\n",
            "called:  (225, 768)\n",
            "called:  (634, 768)\n",
            "called:  (784, 768)\n",
            "called:  (356, 768)\n",
            "called:  (326, 768)\n",
            "called:  (284, 768)\n",
            "called:  (1237, 768)\n",
            "called:  (337, 768)\n",
            "called:  (692, 768)\n",
            "called:  (236, 768)\n",
            "called:  (249, 768)\n",
            "called:  (388, 768)\n",
            "called:  (451, 768)\n",
            "called:  (959, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 1.0000, recall: 0.8923, f1: 0.9431, accuracy: 0.9453, batch_loss: 0.0611, loss: 0.0800 ||:  20%|##        | 4/20 [08:46<34:49, 130.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 22:11:47 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 22:11:47 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:11:47 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 22:11:47 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:11:47 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:11:47 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 1.0, 'recall': 0.892307698726654, 'f1': 0.9430894255638123}\n",
            "\n",
            "2024-05-29 22:11:47 :: encode posts per user in batch ...\n",
            "2024-05-29 22:11:47 :: First two user ids in current batch: [2322832632] and [253374465]\n",
            "called:  (222, 768)\n",
            "called:  (304, 768)\n",
            "called:  (685, 768)\n",
            "called:  (1463, 768)\n",
            "called:  (426, 768)\n",
            "called:  (335, 768)\n",
            "called:  (216, 768)\n",
            "called:  (936, 768)\n",
            "called:  (1638, 768)\n",
            "called:  (520, 768)\n",
            "called:  (861, 768)\n",
            "called:  (514, 768)\n",
            "called:  (914, 768)\n",
            "called:  (296, 768)\n",
            "called:  (325, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 1.0000, recall: 0.8910, f1: 0.9423, accuracy: 0.9453, batch_loss: 0.0766, loss: 0.0793 ||:  25%|##5       | 5/20 [11:20<34:44, 138.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 22:14:20 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 22:14:20 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:14:20 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 22:14:20 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:14:20 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:14:20 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 1.0, 'recall': 0.8909657597541809, 'f1': 0.9423394203186035}\n",
            "\n",
            "2024-05-29 22:14:21 :: encode posts per user in batch ...\n",
            "2024-05-29 22:14:21 :: First two user ids in current batch: [36336381] and [234536621]\n",
            "called:  (482, 768)\n",
            "called:  (840, 768)\n",
            "called:  (288, 768)\n",
            "called:  (371, 768)\n",
            "called:  (313, 768)\n",
            "called:  (232, 768)\n",
            "called:  (800, 768)\n",
            "called:  (786, 768)\n",
            "called:  (622, 768)\n",
            "called:  (627, 768)\n",
            "called:  (850, 768)\n",
            "called:  (231, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 1.0000, recall: 0.8984, f1: 0.9465, accuracy: 0.9492, batch_loss: 0.1127, loss: 0.0849 ||:  30%|###       | 6/20 [13:17<30:40, 131.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 22:16:17 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 22:16:17 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:16:17 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 22:16:17 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:16:17 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:16:17 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 1.0, 'recall': 0.8984375, 'f1': 0.9465020298957825}\n",
            "\n",
            "2024-05-29 22:16:17 :: encode posts per user in batch ...\n",
            "2024-05-29 22:16:17 :: First two user ids in current batch: [340888369] and [360043989]\n",
            "called:  (290, 768)\n",
            "called:  (641, 768)\n",
            "called:  (294, 768)\n",
            "called:  (458, 768)\n",
            "called:  (385, 768)\n",
            "called:  (283, 768)\n",
            "called:  (241, 768)\n",
            "called:  (598, 768)\n",
            "called:  (262, 768)\n",
            "called:  (523, 768)\n",
            "called:  (942, 768)\n",
            "called:  (456, 768)\n",
            "called:  (2062, 768)\n",
            "called:  (397, 768)\n",
            "called:  (420, 768)\n",
            "called:  (524, 768)\n",
            "called:  (830, 768)\n",
            "called:  (716, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9975, recall: 0.9024, f1: 0.9476, accuracy: 0.9498, batch_loss: 0.0737, loss: 0.0833 ||:  35%|###5      | 7/20 [16:19<32:04, 148.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 22:19:19 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 22:19:19 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:19:19 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 22:19:19 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:19:19 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:19:19 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9975489974021912, 'recall': 0.9024389982223511, 'f1': 0.947613537311554}\n",
            "\n",
            "2024-05-29 22:19:19 :: encode posts per user in batch ...\n",
            "2024-05-29 22:19:19 :: First two user ids in current batch: [25336912] and [2730087262]\n",
            "called:  (529, 768)\n",
            "called:  (323, 768)\n",
            "called:  (358, 768)\n",
            "called:  (573, 768)\n",
            "called:  (207, 768)\n",
            "called:  (213, 768)\n",
            "called:  (1096, 768)\n",
            "called:  (229, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9978, recall: 0.8973, f1: 0.9449, accuracy: 0.9473, batch_loss: 0.0809, loss: 0.0830 ||:  40%|####      | 8/20 [17:30<24:43, 123.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 22:20:31 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 22:20:31 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:20:31 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 22:20:31 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:20:31 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:20:31 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9978448152542114, 'recall': 0.8972868323326111, 'f1': 0.9448980093002319}\n",
            "\n",
            "2024-05-29 22:20:31 :: encode posts per user in batch ...\n",
            "2024-05-29 22:20:31 :: First two user ids in current batch: [3644839994] and [512800822]\n",
            "called:  (1181, 768)\n",
            "called:  (220, 768)\n",
            "called:  (483, 768)\n",
            "called:  (413, 768)\n",
            "called:  (266, 768)\n",
            "called:  (407, 768)\n",
            "called:  (517, 768)\n",
            "called:  (420, 768)\n",
            "called:  (269, 768)\n",
            "called:  (222, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9981, recall: 0.9044, f1: 0.9490, accuracy: 0.9505, batch_loss: 0.0573, loss: 0.0801 ||:  45%|####5     | 9/20 [18:58<20:35, 112.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 22:21:58 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 22:21:58 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:21:58 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 22:21:58 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:21:58 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:21:58 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9981167316436768, 'recall': 0.9044368863105774, 'f1': 0.9489704370498657}\n",
            "\n",
            "2024-05-29 22:21:58 :: encode posts per user in batch ...\n",
            "2024-05-29 22:21:58 :: First two user ids in current batch: [1958964175] and [403298160]\n",
            "called:  (831, 768)\n",
            "called:  (539, 768)\n",
            "called:  (1983, 768)\n",
            "called:  (1025, 768)\n",
            "called:  (288, 768)\n",
            "called:  (1560, 768)\n",
            "called:  (444, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9966, recall: 0.9067, f1: 0.9496, accuracy: 0.9508, batch_loss: 0.0673, loss: 0.0789 ||:  50%|#####     | 10/20 [20:47<18:35, 111.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 22:23:48 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 22:23:48 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:23:48 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 22:23:48 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:23:48 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:23:48 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9966386556625366, 'recall': 0.9067278504371643, 'f1': 0.9495596289634705}\n",
            "\n",
            "2024-05-29 22:23:48 :: encode posts per user in batch ...\n",
            "2024-05-29 22:23:48 :: First two user ids in current batch: [2766067037] and [3013962410]\n",
            "called:  (299, 768)\n",
            "called:  (326, 768)\n",
            "called:  (947, 768)\n",
            "called:  (493, 768)\n",
            "called:  (458, 768)\n",
            "called:  (1103, 768)\n",
            "called:  (498, 768)\n",
            "called:  (413, 768)\n",
            "called:  (430, 768)\n",
            "called:  (376, 768)\n",
            "called:  (1012, 768)\n",
            "called:  (644, 768)\n",
            "called:  (553, 768)\n",
            "called:  (244, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9940, recall: 0.9063, f1: 0.9481, accuracy: 0.9489, batch_loss: 0.1361, loss: 0.0841 ||:  55%|#####5    | 11/20 [23:10<18:09, 121.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 22:26:11 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 22:26:11 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:26:11 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 22:26:11 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:26:11 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:26:11 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9939576983451843, 'recall': 0.9063360691070557, 'f1': 0.9481267333030701}\n",
            "\n",
            "2024-05-29 22:26:11 :: encode posts per user in batch ...\n",
            "2024-05-29 22:26:11 :: First two user ids in current batch: [35583947] and [379982847]\n",
            "called:  (208, 768)\n",
            "called:  (389, 768)\n",
            "called:  (297, 768)\n",
            "called:  (282, 768)\n",
            "called:  (383, 768)\n",
            "called:  (610, 768)\n",
            "called:  (254, 768)\n",
            "called:  (263, 768)\n",
            "called:  (439, 768)\n",
            "called:  (464, 768)\n",
            "called:  (2317, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9917, recall: 0.9084, f1: 0.9482, accuracy: 0.9492, batch_loss: 0.1274, loss: 0.0877 ||:  60%|######    | 12/20 [24:58<15:36, 117.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 22:27:59 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 22:27:59 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:27:59 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 22:27:59 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:27:59 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:27:59 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9916666746139526, 'recall': 0.9083969593048096, 'f1': 0.9482071995735168}\n",
            "\n",
            "2024-05-29 22:27:59 :: encode posts per user in batch ...\n",
            "2024-05-29 22:27:59 :: First two user ids in current batch: [389236072] and [2369715162]\n",
            "called:  (360, 768)\n",
            "called:  (206, 768)\n",
            "called:  (1601, 768)\n",
            "called:  (1065, 768)\n",
            "called:  (2668, 768)\n",
            "called:  (900, 768)\n",
            "called:  (2116, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9910, recall: 0.9125, f1: 0.9502, accuracy: 0.9513, batch_loss: 0.0837, loss: 0.0874 ||:  65%|######5   | 13/20 [27:20<14:32, 124.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 22:30:21 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 22:30:21 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:30:21 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 22:30:21 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:30:21 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:30:21 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9910141229629517, 'recall': 0.9125295281410217, 'f1': 0.9501538276672363}\n",
            "\n",
            "2024-05-29 22:30:21 :: encode posts per user in batch ...\n",
            "2024-05-29 22:30:21 :: First two user ids in current batch: [1486789896] and [4860379092]\n",
            "called:  (1362, 768)\n",
            "called:  (207, 768)\n",
            "called:  (255, 768)\n",
            "called:  (262, 768)\n",
            "called:  (223, 768)\n",
            "called:  (2534, 768)\n",
            "called:  (352, 768)\n",
            "called:  (453, 768)\n",
            "called:  (493, 768)\n",
            "called:  (259, 768)\n",
            "called:  (541, 768)\n",
            "called:  (376, 768)\n",
            "called:  (2042, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9917, recall: 0.9107, f1: 0.9495, accuracy: 0.9503, batch_loss: 0.0619, loss: 0.0855 ||:  70%|#######   | 14/20 [30:00<13:32, 135.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 22:33:01 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 22:33:01 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:33:01 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 22:33:01 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:33:01 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:33:01 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.991696298122406, 'recall': 0.9106754064559937, 'f1': 0.9494605660438538}\n",
            "\n",
            "2024-05-29 22:33:01 :: encode posts per user in batch ...\n",
            "2024-05-29 22:33:01 :: First two user ids in current batch: [1395946376] and [207146200]\n",
            "called:  (812, 768)\n",
            "called:  (556, 768)\n",
            "called:  (511, 768)\n",
            "called:  (1572, 768)\n",
            "called:  (2189, 768)\n",
            "called:  (336, 768)\n",
            "called:  (465, 768)\n",
            "called:  (632, 768)\n",
            "called:  (338, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9922, recall: 0.9138, f1: 0.9514, accuracy: 0.9526, batch_loss: 0.0381, loss: 0.0824 ||:  75%|#######5  | 15/20 [32:05<11:00, 132.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 22:35:06 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 22:35:06 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:35:06 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 22:35:06 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:35:06 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:35:06 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9922049045562744, 'recall': 0.9138461351394653, 'f1': 0.9514148235321045}\n",
            "\n",
            "2024-05-29 22:35:06 :: encode posts per user in batch ...\n",
            "2024-05-29 22:35:06 :: First two user ids in current batch: [4761998274] and [2908645429]\n",
            "called:  (226, 768)\n",
            "called:  (942, 768)\n",
            "called:  (320, 768)\n",
            "called:  (464, 768)\n",
            "called:  (618, 768)\n",
            "called:  (477, 768)\n",
            "called:  (673, 768)\n",
            "called:  (822, 768)\n",
            "called:  (1059, 768)\n",
            "called:  (323, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9926, recall: 0.9051, f1: 0.9468, accuracy: 0.9482, batch_loss: 0.1863, loss: 0.0889 ||:  80%|########  | 16/20 [33:58<08:25, 126.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 22:36:59 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 22:36:59 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:36:59 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 22:36:59 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:36:59 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:36:59 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9926393032073975, 'recall': 0.9050815105438232, 'f1': 0.9468405246734619}\n",
            "\n",
            "2024-05-29 22:36:59 :: encode posts per user in batch ...\n",
            "2024-05-29 22:36:59 :: First two user ids in current batch: [952446877] and [29298393]\n",
            "called:  (655, 768)\n",
            "called:  (383, 768)\n",
            "called:  (499, 768)\n",
            "called:  (390, 768)\n",
            "called:  (283, 768)\n",
            "called:  (201, 768)\n",
            "called:  (329, 768)\n",
            "called:  (259, 768)\n",
            "called:  (706, 768)\n",
            "called:  (332, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9931, recall: 0.9034, f1: 0.9461, accuracy: 0.9476, batch_loss: 0.1515, loss: 0.0926 ||:  85%|########5 | 17/20 [35:22<05:41, 113.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 22:38:23 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 22:38:23 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:38:23 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 22:38:23 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:38:23 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:38:23 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9930555820465088, 'recall': 0.9034296274185181, 'f1': 0.946124792098999}\n",
            "\n",
            "2024-05-29 22:38:23 :: encode posts per user in batch ...\n",
            "2024-05-29 22:38:23 :: First two user ids in current batch: [397374653] and [31971128]\n",
            "called:  (347, 768)\n",
            "called:  (569, 768)\n",
            "called:  (2298, 768)\n",
            "called:  (2037, 768)\n",
            "called:  (276, 768)\n",
            "called:  (279, 768)\n",
            "called:  (600, 768)\n",
            "called:  (412, 768)\n",
            "called:  (1594, 768)\n",
            "called:  (323, 768)\n",
            "called:  (228, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9925, recall: 0.8968, f1: 0.9422, accuracy: 0.9440, batch_loss: 0.2167, loss: 0.0995 ||:  90%|######### | 18/20 [37:52<04:09, 124.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 22:40:53 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 22:40:53 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:40:53 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 22:40:53 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:40:53 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:40:53 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.99245285987854, 'recall': 0.8968456983566284, 'f1': 0.9422301650047302}\n",
            "\n",
            "2024-05-29 22:40:53 :: encode posts per user in batch ...\n",
            "2024-05-29 22:40:53 :: First two user ids in current batch: [513451523] and [3354632691]\n",
            "called:  (515, 768)\n",
            "called:  (377, 768)\n",
            "called:  (280, 768)\n",
            "called:  (230, 768)\n",
            "called:  (555, 768)\n",
            "called:  (328, 768)\n",
            "called:  (235, 768)\n",
            "called:  (373, 768)\n",
            "called:  (1284, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9929, recall: 0.9009, f1: 0.9447, accuracy: 0.9461, batch_loss: 0.0479, loss: 0.0967 ||:  95%|#########5| 19/20 [39:17<01:52, 112.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 22:42:18 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 22:42:18 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:42:18 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 22:42:18 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:42:18 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:42:18 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9928951859474182, 'recall': 0.9008863568305969, 'f1': 0.9446556568145752}\n",
            "\n",
            "2024-05-29 22:42:18 :: encode posts per user in batch ...\n",
            "2024-05-29 22:42:18 :: First two user ids in current batch: [173454135] and [254300017]\n",
            "called:  (286, 768)\n",
            "called:  (2068, 768)\n",
            "called:  (551, 768)\n",
            "called:  (1772, 768)\n",
            "called:  (231, 768)\n",
            "called:  (326, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "precision: 0.9932, recall: 0.9004, f1: 0.9445, accuracy: 0.9457, batch_loss: 0.0794, loss: 0.0959 ||: 100%|##########| 20/20 [40:54<00:00, 122.71s/it]\n",
            "  0%|          | 0/7 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 22:43:54 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 22:43:54 :: tensor size after padding: torch.Size([92, 200, 768])\n",
            "2024-05-29 22:43:54 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([92, 200, 768])]\n",
            "2024-05-29 22:43:54 :: post masking: content [torch.Size([92, 200])]\n",
            "new tenor size: torch.Size([92, 200, 768])\n",
            "2024-05-29 22:43:54 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([92, 200, 768])\n",
            "2024-05-29 22:43:54 :: post reprsentation shape : torch.Size([92, 768])\n",
            "{'precision': 0.9931856989860535, 'recall': 0.9003860950469971, 'f1': 0.944511890411377}\n",
            "\n",
            "{'precision': 0.9931856989860535, 'recall': 0.9003860950469971, 'f1': 0.944511890411377}\n",
            "\n",
            "2024-05-29 22:43:55 :: encode posts per user in batch ...\n",
            "2024-05-29 22:43:55 :: First two user ids in current batch: [400430412] and [296048859]\n",
            "called:  (751, 768)\n",
            "called:  (985, 768)\n",
            "called:  (216, 768)\n",
            "called:  (207, 768)\n",
            "called:  (219, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 1.0000, recall: 0.9692, f1: 0.9844, accuracy: 0.9844, batch_loss: 0.0500, loss: 0.0500 ||:  14%|#4        | 1/7 [00:52<05:14, 52.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 22:44:47 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 22:44:47 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:44:47 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 22:44:47 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:44:47 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:44:47 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 1.0, 'recall': 0.9692307710647583, 'f1': 0.984375}\n",
            "\n",
            "2024-05-29 22:44:47 :: encode posts per user in batch ...\n",
            "2024-05-29 22:44:47 :: First two user ids in current batch: [2292183386] and [921619909]\n",
            "called:  (236, 768)\n",
            "called:  (401, 768)\n",
            "called:  (947, 768)\n",
            "called:  (303, 768)\n",
            "called:  (324, 768)\n",
            "called:  (371, 768)\n",
            "called:  (431, 768)\n",
            "called:  (329, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 1.0000, recall: 0.9844, f1: 0.9921, accuracy: 0.9922, batch_loss: 0.0082, loss: 0.0291 ||:  29%|##8       | 2/7 [02:01<05:12, 62.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 22:45:56 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 22:45:56 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:45:56 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 22:45:56 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:45:56 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:45:56 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 1.0, 'recall': 0.984375, 'f1': 0.9921259880065918}\n",
            "\n",
            "2024-05-29 22:45:56 :: encode posts per user in batch ...\n",
            "2024-05-29 22:45:56 :: First two user ids in current batch: [367262245] and [244939232]\n",
            "called:  (318, 768)\n",
            "called:  (269, 768)\n",
            "called:  (201, 768)\n",
            "called:  (309, 768)\n",
            "called:  (522, 768)\n",
            "called:  (507, 768)\n",
            "called:  (1311, 768)\n",
            "called:  (292, 768)\n",
            "called:  (989, 768)\n",
            "called:  (2606, 768)\n",
            "called:  (932, 768)\n",
            "called:  (251, 768)\n",
            "called:  (285, 768)\n",
            "called:  (348, 768)\n",
            "called:  (772, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 1.0000, recall: 0.9900, f1: 0.9950, accuracy: 0.9948, batch_loss: 0.0039, loss: 0.0207 ||:  43%|####2     | 3/7 [04:42<07:09, 107.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 22:48:37 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 22:48:37 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:48:37 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 22:48:37 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:48:37 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:48:37 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 1.0, 'recall': 0.9900000095367432, 'f1': 0.9949748516082764}\n",
            "\n",
            "2024-05-29 22:48:37 :: encode posts per user in batch ...\n",
            "2024-05-29 22:48:37 :: First two user ids in current batch: [149299092] and [3063182396]\n",
            "called:  (2229, 768)\n",
            "called:  (449, 768)\n",
            "called:  (223, 768)\n",
            "called:  (310, 768)\n",
            "called:  (289, 768)\n",
            "called:  (1604, 768)\n",
            "called:  (421, 768)\n",
            "called:  (242, 768)\n",
            "called:  (1008, 768)\n",
            "called:  (207, 768)\n",
            "called:  (1477, 768)\n",
            "called:  (440, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 1.0000, recall: 0.9923, f1: 0.9961, accuracy: 0.9961, batch_loss: 0.0121, loss: 0.0185 ||:  57%|#####7    | 4/7 [06:57<05:54, 118.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 22:50:52 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 22:50:52 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:50:52 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 22:50:52 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:50:52 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:50:52 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 1.0, 'recall': 0.9923076629638672, 'f1': 0.9961389899253845}\n",
            "\n",
            "2024-05-29 22:50:52 :: encode posts per user in batch ...\n",
            "2024-05-29 22:50:52 :: First two user ids in current batch: [287963467] and [737658613]\n",
            "called:  (1194, 768)\n",
            "called:  (249, 768)\n",
            "called:  (1078, 768)\n",
            "called:  (1923, 768)\n",
            "called:  (523, 768)\n",
            "called:  (241, 768)\n",
            "called:  (283, 768)\n",
            "called:  (874, 768)\n",
            "called:  (222, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 1.0000, recall: 0.9937, f1: 0.9968, accuracy: 0.9969, batch_loss: 0.0056, loss: 0.0159 ||:  71%|#######1  | 5/7 [08:40<03:45, 112.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 22:52:35 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 22:52:35 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:52:35 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 22:52:35 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:52:35 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:52:35 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 1.0, 'recall': 0.9936708807945251, 'f1': 0.9968253374099731}\n",
            "\n",
            "2024-05-29 22:52:35 :: encode posts per user in batch ...\n",
            "2024-05-29 22:52:35 :: First two user ids in current batch: [737295271] and [3309440615]\n",
            "called:  (226, 768)\n",
            "called:  (1276, 768)\n",
            "called:  (366, 768)\n",
            "called:  (232, 768)\n",
            "called:  (265, 768)\n",
            "called:  (302, 768)\n",
            "called:  (336, 768)\n",
            "called:  (218, 768)\n",
            "called:  (351, 768)\n",
            "called:  (666, 768)\n",
            "called:  (232, 768)\n",
            "called:  (352, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9949, recall: 0.9923, f1: 0.9936, accuracy: 0.9935, batch_loss: 0.0982, loss: 0.0297 ||:  86%|########5 | 6/7 [10:10<01:44, 104.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 22:54:05 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 22:54:05 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:54:05 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 22:54:05 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:54:05 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:54:05 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9948717951774597, 'recall': 0.9923273921012878, 'f1': 0.9935979843139648}\n",
            "\n",
            "2024-05-29 22:54:05 :: encode posts per user in batch ...\n",
            "2024-05-29 22:54:05 :: First two user ids in current batch: [1050005634] and [700301514]\n",
            "called:  (1122, 768)\n",
            "called:  (297, 768)\n",
            "called:  (214, 768)\n",
            "called:  (608, 768)\n",
            "called:  (215, 768)\n",
            "called:  (212, 768)\n",
            "called:  (246, 768)\n",
            "called:  (226, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "precision: 0.9953, recall: 0.9907, f1: 0.9930, accuracy: 0.9929, batch_loss: 0.0470, loss: 0.0321 ||: 100%|##########| 7/7 [11:07<00:00, 95.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 22:55:02 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 22:55:02 :: tensor size after padding: torch.Size([74, 200, 768])\n",
            "2024-05-29 22:55:02 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([74, 200, 768])]\n",
            "2024-05-29 22:55:02 :: post masking: content [torch.Size([74, 200])]\n",
            "new tenor size: torch.Size([74, 200, 768])\n",
            "2024-05-29 22:55:02 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([74, 200, 768])\n",
            "2024-05-29 22:55:03 :: post reprsentation shape : torch.Size([74, 768])\n",
            "{'precision': 0.9953488111495972, 'recall': 0.9907407164573669, 'f1': 0.9930394887924194}\n",
            "\n",
            "{'precision': 0.9953488111495972, 'recall': 0.9907407164573669, 'f1': 0.9930394887924194}\n",
            "\n",
            "Metrics at the end of epoch: 5 {'best_epoch': 5, 'peak_worker_0_memory_MB': 2071.328125, 'peak_gpu_0_memory_MB': 1573.1474609375, 'training_duration': '5:13:05.321818', 'epoch': 5, 'training_precision': 0.9931856989860535, 'training_recall': 0.9003860950469971, 'training_f1': 0.944511890411377, 'training_accuracy': 0.9457210776545166, 'training_loss': 0.09588195458054542, 'training_worker_0_memory_MB': 2071.328125, 'training_gpu_0_memory_MB': 1573.1474609375, 'validation_precision': 0.9953488111495972, 'validation_recall': 0.9907407164573669, 'validation_f1': 0.9930394887924194, 'validation_accuracy': 0.9928741092636579, 'validation_loss': 0.032140906035367935, 'best_validation_precision': 0.9953488111495972, 'best_validation_recall': 0.9907407164573669, 'best_validation_f1': 0.9930394887924194, 'best_validation_accuracy': 0.9928741092636579, 'best_validation_loss': 0.032140906035367935}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/cuda/memory.py:330: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
            "  warnings.warn(\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 22:55:04 :: encode posts per user in batch ...\n",
            "2024-05-29 22:55:04 :: First two user ids in current batch: [890072059] and [1702159368]\n",
            "called:  (335, 768)\n",
            "called:  (493, 768)\n",
            "called:  (208, 768)\n",
            "called:  (426, 768)\n",
            "called:  (2068, 768)\n",
            "called:  (326, 768)\n",
            "called:  (223, 768)\n",
            "called:  (850, 768)\n",
            "called:  (244, 768)\n",
            "called:  (2042, 768)\n",
            "called:  (632, 768)\n",
            "called:  (616, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 1.0000, recall: 0.8636, f1: 0.9268, accuracy: 0.9297, batch_loss: 0.0755, loss: 0.0755 ||:   5%|5         | 1/20 [02:28<46:56, 148.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 22:57:32 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 22:57:32 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:57:32 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 22:57:32 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:57:32 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:57:32 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 1.0, 'recall': 0.8636363744735718, 'f1': 0.9268292784690857}\n",
            "\n",
            "2024-05-29 22:57:32 :: encode posts per user in batch ...\n",
            "2024-05-29 22:57:32 :: First two user ids in current batch: [36336381] and [3078785295]\n",
            "called:  (1025, 768)\n",
            "called:  (498, 768)\n",
            "called:  (2534, 768)\n",
            "called:  (323, 768)\n",
            "called:  (266, 768)\n",
            "called:  (290, 768)\n",
            "called:  (622, 768)\n",
            "called:  (383, 768)\n",
            "called:  (257, 768)\n",
            "called:  (600, 768)\n",
            "called:  (326, 768)\n",
            "called:  (233, 768)\n",
            "called:  (914, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 1.0000, recall: 0.8841, f1: 0.9385, accuracy: 0.9375, batch_loss: 0.0795, loss: 0.0775 ||:  10%|#         | 2/20 [04:50<43:29, 144.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 22:59:55 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 22:59:55 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:59:55 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 22:59:55 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:59:55 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 22:59:55 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 1.0, 'recall': 0.8840579986572266, 'f1': 0.9384615421295166}\n",
            "\n",
            "2024-05-29 22:59:55 :: encode posts per user in batch ...\n",
            "2024-05-29 22:59:55 :: First two user ids in current batch: [2860592517] and [2497324625]\n",
            "called:  (458, 768)\n",
            "called:  (207, 768)\n",
            "called:  (517, 768)\n",
            "called:  (326, 768)\n",
            "called:  (201, 768)\n",
            "called:  (1237, 768)\n",
            "called:  (328, 768)\n",
            "called:  (1567, 768)\n",
            "called:  (376, 768)\n",
            "called:  (950, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 1.0000, recall: 0.8883, f1: 0.9409, accuracy: 0.9401, batch_loss: 0.0702, loss: 0.0750 ||:  15%|#5        | 3/20 [06:40<36:33, 129.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 23:01:45 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 23:01:45 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:01:45 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 23:01:45 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:01:45 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:01:45 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 1.0, 'recall': 0.8883495330810547, 'f1': 0.9408740401268005}\n",
            "\n",
            "2024-05-29 23:01:45 :: encode posts per user in batch ...\n",
            "2024-05-29 23:01:45 :: First two user ids in current batch: [1546606406] and [4855132048]\n",
            "called:  (2298, 768)\n",
            "called:  (786, 768)\n",
            "called:  (337, 768)\n",
            "called:  (514, 768)\n",
            "called:  (407, 768)\n",
            "called:  (477, 768)\n",
            "called:  (535, 768)\n",
            "called:  (320, 768)\n",
            "called:  (397, 768)\n",
            "called:  (937, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9885, recall: 0.9113, f1: 0.9483, accuracy: 0.9453, batch_loss: 0.0660, loss: 0.0728 ||:  20%|##        | 4/20 [08:43<33:40, 126.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 23:03:47 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 23:03:47 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:03:47 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 23:03:47 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:03:47 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:03:47 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9884615540504456, 'recall': 0.911347508430481, 'f1': 0.9483394622802734}\n",
            "\n",
            "2024-05-29 23:03:47 :: encode posts per user in batch ...\n",
            "2024-05-29 23:03:47 :: First two user ids in current batch: [626812946] and [3551013614]\n",
            "called:  (673, 768)\n",
            "called:  (437, 768)\n",
            "called:  (573, 768)\n",
            "called:  (529, 768)\n",
            "called:  (942, 768)\n",
            "called:  (259, 768)\n",
            "called:  (598, 768)\n",
            "called:  (231, 768)\n",
            "called:  (294, 768)\n",
            "called:  (539, 768)\n",
            "called:  (1560, 768)\n",
            "called:  (444, 768)\n",
            "called:  (207, 768)\n",
            "called:  (541, 768)\n",
            "called:  (468, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9842, recall: 0.9096, f1: 0.9455, accuracy: 0.9437, batch_loss: 0.0916, loss: 0.0766 ||:  25%|##5       | 5/20 [11:14<33:51, 135.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 23:06:19 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 23:06:19 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:06:19 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 23:06:19 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:06:19 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:06:19 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9842271208763123, 'recall': 0.909621000289917, 'f1': 0.9454545378684998}\n",
            "\n",
            "2024-05-29 23:06:19 :: encode posts per user in batch ...\n",
            "2024-05-29 23:06:19 :: First two user ids in current batch: [619131572] and [3098337258]\n",
            "called:  (441, 768)\n",
            "called:  (831, 768)\n",
            "called:  (420, 768)\n",
            "called:  (499, 768)\n",
            "called:  (282, 768)\n",
            "called:  (388, 768)\n",
            "called:  (263, 768)\n",
            "called:  (618, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9868, recall: 0.9142, f1: 0.9491, accuracy: 0.9479, batch_loss: 0.0350, loss: 0.0696 ||:  30%|###       | 6/20 [12:32<26:59, 115.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 23:07:36 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 23:07:36 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:07:36 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 23:07:36 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:07:36 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:07:36 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9867724776268005, 'recall': 0.9142156839370728, 'f1': 0.9491094350814819}\n",
            "\n",
            "2024-05-29 23:07:36 :: encode posts per user in batch ...\n",
            "2024-05-29 23:07:36 :: First two user ids in current batch: [185390750] and [4463347036]\n",
            "called:  (216, 768)\n",
            "called:  (2037, 768)\n",
            "called:  (283, 768)\n",
            "called:  (229, 768)\n",
            "called:  (634, 768)\n",
            "called:  (2668, 768)\n",
            "called:  (900, 768)\n",
            "called:  (296, 768)\n",
            "called:  (225, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9862, recall: 0.9149, f1: 0.9492, accuracy: 0.9487, batch_loss: 0.1153, loss: 0.0761 ||:  35%|###5      | 7/20 [14:38<25:49, 119.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 23:09:42 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 23:09:42 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:09:42 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 23:09:42 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:09:42 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:09:42 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9862385392189026, 'recall': 0.914893627166748, 'f1': 0.9492273926734924}\n",
            "\n",
            "2024-05-29 23:09:42 :: encode posts per user in batch ...\n",
            "2024-05-29 23:09:42 :: First two user ids in current batch: [2928022219] and [112386734]\n",
            "called:  (385, 768)\n",
            "called:  (262, 768)\n",
            "called:  (1772, 768)\n",
            "called:  (515, 768)\n",
            "called:  (336, 768)\n",
            "called:  (1284, 768)\n",
            "called:  (222, 768)\n",
            "called:  (569, 768)\n",
            "called:  (464, 768)\n",
            "called:  (269, 768)\n",
            "called:  (288, 768)\n",
            "called:  (267, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9879, recall: 0.9108, f1: 0.9478, accuracy: 0.9473, batch_loss: 0.0792, loss: 0.0765 ||:  40%|####      | 8/20 [16:43<24:13, 121.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 23:11:48 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 23:11:48 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:11:48 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 23:11:48 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:11:48 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:11:48 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9879032373428345, 'recall': 0.910780668258667, 'f1': 0.9477756023406982}\n",
            "\n",
            "2024-05-29 23:11:48 :: encode posts per user in batch ...\n",
            "2024-05-29 23:11:48 :: First two user ids in current batch: [268999272] and [24637697]\n",
            "called:  (551, 768)\n",
            "called:  (352, 768)\n",
            "called:  (1230, 768)\n",
            "called:  (854, 768)\n",
            "called:  (947, 768)\n",
            "called:  (228, 768)\n",
            "called:  (1909, 768)\n",
            "called:  (861, 768)\n",
            "called:  (826, 768)\n",
            "called:  (383, 768)\n",
            "called:  (376, 768)\n",
            "called:  (706, 768)\n",
            "called:  (453, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9891, recall: 0.9038, f1: 0.9445, accuracy: 0.9444, batch_loss: 0.0993, loss: 0.0791 ||:  45%|####5     | 9/20 [19:26<24:36, 134.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 23:14:31 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 23:14:31 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:14:31 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 23:14:31 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:14:31 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:14:31 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9891107082366943, 'recall': 0.9038142561912537, 'f1': 0.9445406794548035}\n",
            "\n",
            "2024-05-29 23:14:31 :: encode posts per user in batch ...\n",
            "2024-05-29 23:14:31 :: First two user ids in current batch: [3078619973] and [29292159]\n",
            "called:  (936, 768)\n",
            "called:  (231, 768)\n",
            "called:  (1543, 768)\n",
            "called:  (804, 768)\n",
            "called:  (262, 768)\n",
            "called:  (524, 768)\n",
            "called:  (511, 768)\n",
            "called:  (610, 768)\n",
            "called:  (527, 768)\n",
            "called:  (451, 768)\n",
            "called:  (482, 768)\n",
            "called:  (483, 768)\n",
            "called:  (371, 768)\n",
            "called:  (226, 768)\n",
            "called:  (279, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9902, recall: 0.9090, f1: 0.9479, accuracy: 0.9477, batch_loss: 0.0362, loss: 0.0748 ||:  50%|#####     | 10/20 [21:50<22:50, 137.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 23:16:54 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 23:16:54 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:16:54 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 23:16:54 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:16:54 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:16:54 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9902439117431641, 'recall': 0.9089552164077759, 'f1': 0.9478598833084106}\n",
            "\n",
            "2024-05-29 23:16:54 :: encode posts per user in batch ...\n",
            "2024-05-29 23:16:54 :: First two user ids in current batch: [1558388689] and [1325203388]\n",
            "called:  (280, 768)\n",
            "called:  (1230, 768)\n",
            "called:  (1059, 768)\n",
            "called:  (241, 768)\n",
            "called:  (329, 768)\n",
            "called:  (556, 768)\n",
            "called:  (420, 768)\n",
            "called:  (493, 768)\n",
            "called:  (2116, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9910, recall: 0.9087, f1: 0.9481, accuracy: 0.9489, batch_loss: 0.0636, loss: 0.0738 ||:  55%|#####5    | 11/20 [23:42<19:24, 129.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 23:18:46 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 23:18:46 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:18:46 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 23:18:46 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:18:46 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:18:46 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9909502267837524, 'recall': 0.908713698387146, 'f1': 0.948051929473877}\n",
            "\n",
            "2024-05-29 23:18:46 :: encode posts per user in batch ...\n",
            "2024-05-29 23:18:46 :: First two user ids in current batch: [2880102528] and [868870483]\n",
            "called:  (1065, 768)\n",
            "called:  (959, 768)\n",
            "called:  (220, 768)\n",
            "called:  (1181, 768)\n",
            "called:  (655, 768)\n",
            "called:  (1362, 768)\n",
            "called:  (644, 768)\n",
            "called:  (1594, 768)\n",
            "called:  (230, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9903, recall: 0.9082, f1: 0.9474, accuracy: 0.9486, batch_loss: 0.0988, loss: 0.0758 ||:  60%|######    | 12/20 [25:49<17:11, 128.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 23:20:54 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 23:20:54 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:20:54 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 23:20:54 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:20:54 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:20:54 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9902642369270325, 'recall': 0.9081632494926453, 'f1': 0.9474384784698486}\n",
            "\n",
            "2024-05-29 23:20:54 :: encode posts per user in batch ...\n",
            "2024-05-29 23:20:54 :: First two user ids in current batch: [112131431] and [2443619426]\n",
            "called:  (553, 768)\n",
            "called:  (465, 768)\n",
            "called:  (222, 768)\n",
            "called:  (232, 768)\n",
            "called:  (216, 768)\n",
            "called:  (830, 768)\n",
            "called:  (323, 768)\n",
            "called:  (520, 768)\n",
            "called:  (795, 768)\n",
            "called:  (1270, 768)\n",
            "called:  (464, 768)\n",
            "called:  (299, 768)\n",
            "called:  (822, 768)\n",
            "called:  (286, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9909, recall: 0.9031, f1: 0.9450, accuracy: 0.9465, batch_loss: 0.0879, loss: 0.0768 ||:  65%|######5   | 13/20 [27:57<15:00, 128.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 23:23:02 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 23:23:02 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:23:02 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 23:23:02 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:23:02 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:23:02 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.990920901298523, 'recall': 0.9030733108520508, 'f1': 0.944959819316864}\n",
            "\n",
            "2024-05-29 23:23:02 :: encode posts per user in batch ...\n",
            "2024-05-29 23:23:02 :: First two user ids in current batch: [628185788] and [110235652]\n",
            "called:  (840, 768)\n",
            "called:  (254, 768)\n",
            "called:  (237, 768)\n",
            "called:  (284, 768)\n",
            "called:  (297, 768)\n",
            "called:  (389, 768)\n",
            "called:  (288, 768)\n",
            "called:  (413, 768)\n",
            "called:  (812, 768)\n",
            "called:  (325, 768)\n",
            "called:  (313, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9916, recall: 0.9002, f1: 0.9437, accuracy: 0.9448, batch_loss: 0.0848, loss: 0.0773 ||:  70%|#######   | 14/20 [29:35<11:55, 119.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 23:24:39 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 23:24:39 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:24:39 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 23:24:39 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:24:39 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:24:39 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9916368126869202, 'recall': 0.9002169370651245, 'f1': 0.9437180161476135}\n",
            "\n",
            "2024-05-29 23:24:39 :: encode posts per user in batch ...\n",
            "2024-05-29 23:24:39 :: First two user ids in current batch: [2781575143] and [31217858]\n",
            "called:  (356, 768)\n",
            "called:  (1103, 768)\n",
            "called:  (338, 768)\n",
            "called:  (206, 768)\n",
            "called:  (390, 768)\n",
            "called:  (377, 768)\n",
            "called:  (254, 768)\n",
            "called:  (358, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9922, recall: 0.8986, f1: 0.9431, accuracy: 0.9443, batch_loss: 0.1210, loss: 0.0803 ||:  75%|#######5  | 15/20 [30:43<08:38, 103.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 23:25:47 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 23:25:47 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:25:47 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 23:25:47 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:25:47 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:25:47 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9921612739562988, 'recall': 0.8985801339149475, 'f1': 0.9430548548698425}\n",
            "\n",
            "2024-05-29 23:25:47 :: encode posts per user in batch ...\n",
            "2024-05-29 23:25:47 :: First two user ids in current batch: [478645966] and [3238225388]\n",
            "called:  (800, 768)\n",
            "called:  (835, 768)\n",
            "called:  (255, 768)\n",
            "called:  (641, 768)\n",
            "called:  (263, 768)\n",
            "called:  (360, 768)\n",
            "called:  (235, 768)\n",
            "called:  (456, 768)\n",
            "called:  (503, 768)\n",
            "called:  (716, 768)\n",
            "called:  (213, 768)\n",
            "called:  (1463, 768)\n",
            "called:  (942, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9927, recall: 0.9021, f1: 0.9452, accuracy: 0.9463, batch_loss: 0.0559, loss: 0.0787 ||:  80%|########  | 16/20 [32:55<07:28, 112.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 23:27:59 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 23:27:59 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:27:59 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 23:27:59 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:27:59 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:27:59 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9926778078079224, 'recall': 0.9020912647247314, 'f1': 0.9452191591262817}\n",
            "\n",
            "2024-05-29 23:27:59 :: encode posts per user in batch ...\n",
            "2024-05-29 23:27:59 :: First two user ids in current batch: [163535738] and [148841492]\n",
            "called:  (413, 768)\n",
            "called:  (1638, 768)\n",
            "called:  (373, 768)\n",
            "called:  (784, 768)\n",
            "called:  (276, 768)\n",
            "called:  (439, 768)\n",
            "called:  (1572, 768)\n",
            "called:  (283, 768)\n",
            "called:  (685, 768)\n",
            "called:  (1096, 768)\n",
            "called:  (1983, 768)\n",
            "called:  (651, 768)\n",
            "called:  (249, 768)\n",
            "called:  (347, 768)\n",
            "called:  (2062, 768)\n",
            "called:  (294, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9931, recall: 0.8958, f1: 0.9419, accuracy: 0.9430, batch_loss: 0.1407, loss: 0.0824 ||:  85%|########5 | 17/20 [36:24<07:04, 141.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 23:31:28 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 23:31:28 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:31:28 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 23:31:28 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:31:28 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:31:28 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9930898547172546, 'recall': 0.8958147764205933, 'f1': 0.9419476389884949}\n",
            "\n",
            "2024-05-29 23:31:28 :: encode posts per user in batch ...\n",
            "2024-05-29 23:31:28 :: First two user ids in current batch: [56083213] and [2379079476]\n",
            "called:  (410, 768)\n",
            "called:  (458, 768)\n",
            "called:  (464, 768)\n",
            "called:  (323, 768)\n",
            "called:  (1601, 768)\n",
            "called:  (389, 768)\n",
            "called:  (2317, 768)\n",
            "called:  (430, 768)\n",
            "called:  (555, 768)\n",
            "called:  (692, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9934, recall: 0.8971, f1: 0.9428, accuracy: 0.9444, batch_loss: 0.0473, loss: 0.0804 ||:  90%|######### | 18/20 [38:36<04:37, 138.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 23:33:40 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 23:33:40 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:33:40 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 23:33:40 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:33:40 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:33:40 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9934086799621582, 'recall': 0.8971088528633118, 'f1': 0.9428061246871948}\n",
            "\n",
            "2024-05-29 23:33:40 :: encode posts per user in batch ...\n",
            "2024-05-29 23:33:40 :: First two user ids in current batch: [47023417] and [4095353712]\n",
            "called:  (412, 768)\n",
            "called:  (304, 768)\n",
            "called:  (236, 768)\n",
            "called:  (523, 768)\n",
            "called:  (332, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9938, recall: 0.8992, f1: 0.9441, accuracy: 0.9457, batch_loss: 0.0488, loss: 0.0788 ||:  95%|#########5| 19/20 [39:31<01:53, 113.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 23:34:35 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 23:34:35 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:34:35 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 23:34:35 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:34:35 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:34:35 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9937611222267151, 'recall': 0.899193525314331, 'f1': 0.9441152215003967}\n",
            "\n",
            "2024-05-29 23:34:35 :: encode posts per user in batch ...\n",
            "2024-05-29 23:34:35 :: First two user ids in current batch: [3395626274] and [42998660]\n",
            "called:  (627, 768)\n",
            "called:  (259, 768)\n",
            "called:  (1012, 768)\n",
            "called:  (2189, 768)\n",
            "called:  (320, 768)\n",
            "called:  (279, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "precision: 0.9940, recall: 0.9012, f1: 0.9453, accuracy: 0.9465, batch_loss: 0.0337, loss: 0.0765 ||: 100%|##########| 20/20 [40:53<00:00, 122.69s/it]\n",
            "  0%|          | 0/7 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 23:35:58 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 23:35:58 :: tensor size after padding: torch.Size([92, 200, 768])\n",
            "2024-05-29 23:35:58 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([92, 200, 768])]\n",
            "2024-05-29 23:35:58 :: post masking: content [torch.Size([92, 200])]\n",
            "new tenor size: torch.Size([92, 200, 768])\n",
            "2024-05-29 23:35:58 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([92, 200, 768])\n",
            "2024-05-29 23:35:58 :: post reprsentation shape : torch.Size([92, 768])\n",
            "{'precision': 0.9940374493598938, 'recall': 0.9011582732200623, 'f1': 0.9453219771385193}\n",
            "\n",
            "{'precision': 0.9940374493598938, 'recall': 0.9011582732200623, 'f1': 0.9453219771385193}\n",
            "\n",
            "2024-05-29 23:35:58 :: encode posts per user in batch ...\n",
            "2024-05-29 23:35:58 :: First two user ids in current batch: [2257174646] and [2369033719]\n",
            "called:  (215, 768)\n",
            "called:  (1604, 768)\n",
            "called:  (241, 768)\n",
            "called:  (232, 768)\n",
            "called:  (401, 768)\n",
            "called:  (1477, 768)\n",
            "called:  (242, 768)\n",
            "called:  (265, 768)\n",
            "called:  (269, 768)\n",
            "called:  (666, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9839, recall: 1.0000, f1: 0.9919, accuracy: 0.9922, batch_loss: 0.0160, loss: 0.0160 ||:  14%|#4        | 1/7 [01:36<09:36, 96.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 23:37:34 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 23:37:34 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:37:34 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 23:37:34 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:37:34 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:37:34 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9838709831237793, 'recall': 1.0, 'f1': 0.9918699264526367}\n",
            "\n",
            "2024-05-29 23:37:34 :: encode posts per user in batch ...\n",
            "2024-05-29 23:37:34 :: First two user ids in current batch: [2678537893] and [754961997591183360]\n",
            "called:  (285, 768)\n",
            "called:  (874, 768)\n",
            "called:  (421, 768)\n",
            "called:  (1194, 768)\n",
            "called:  (222, 768)\n",
            "called:  (283, 768)\n",
            "called:  (772, 768)\n",
            "called:  (310, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9664, recall: 1.0000, f1: 0.9829, accuracy: 0.9844, batch_loss: 0.0790, loss: 0.0475 ||:  29%|##8       | 2/7 [02:52<07:02, 84.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 23:38:50 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 23:38:50 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:38:50 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 23:38:50 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:38:50 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:38:50 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9663865566253662, 'recall': 1.0, 'f1': 0.9829059839248657}\n",
            "\n",
            "2024-05-29 23:38:50 :: encode posts per user in batch ...\n",
            "2024-05-29 23:38:50 :: First two user ids in current batch: [1638994118] and [466931474]\n",
            "called:  (226, 768)\n",
            "called:  (302, 768)\n",
            "called:  (207, 768)\n",
            "called:  (989, 768)\n",
            "called:  (329, 768)\n",
            "called:  (352, 768)\n",
            "called:  (523, 768)\n",
            "called:  (289, 768)\n",
            "called:  (324, 768)\n",
            "called:  (932, 768)\n",
            "called:  (1078, 768)\n",
            "called:  (303, 768)\n",
            "called:  (449, 768)\n",
            "called:  (1311, 768)\n",
            "called:  (207, 768)\n",
            "called:  (440, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9737, recall: 0.9946, f1: 0.9840, accuracy: 0.9844, batch_loss: 0.0320, loss: 0.0424 ||:  43%|####2     | 3/7 [05:14<07:22, 110.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 23:41:12 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 23:41:12 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:41:12 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 23:41:12 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:41:12 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:41:12 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9736841917037964, 'recall': 0.9946236610412598, 'f1': 0.9840425848960876}\n",
            "\n",
            "2024-05-29 23:41:12 :: encode posts per user in batch ...\n",
            "2024-05-29 23:41:12 :: First two user ids in current batch: [400430412] and [262647165]\n",
            "called:  (223, 768)\n",
            "called:  (1276, 768)\n",
            "called:  (1008, 768)\n",
            "called:  (232, 768)\n",
            "called:  (297, 768)\n",
            "called:  (292, 768)\n",
            "called:  (216, 768)\n",
            "called:  (1122, 768)\n",
            "called:  (431, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9720, recall: 0.9959, f1: 0.9838, accuracy: 0.9844, batch_loss: 0.0757, loss: 0.0507 ||:  57%|#####7    | 4/7 [06:41<05:04, 101.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 23:42:39 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 23:42:39 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:42:39 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 23:42:39 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:42:39 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:42:39 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.972000002861023, 'recall': 0.9959016442298889, 'f1': 0.9838056564331055}\n",
            "\n",
            "2024-05-29 23:42:39 :: encode posts per user in batch ...\n",
            "2024-05-29 23:42:39 :: First two user ids in current batch: [757207454484692992] and [541808511]\n",
            "called:  (236, 768)\n",
            "called:  (1923, 768)\n",
            "called:  (608, 768)\n",
            "called:  (2606, 768)\n",
            "called:  (336, 768)\n",
            "called:  (201, 768)\n",
            "called:  (318, 768)\n",
            "called:  (214, 768)\n",
            "called:  (351, 768)\n",
            "called:  (309, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9778, recall: 0.9904, f1: 0.9841, accuracy: 0.9844, batch_loss: 0.0349, loss: 0.0475 ||:  71%|#######1  | 5/7 [08:37<03:33, 106.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 23:44:35 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 23:44:35 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:44:35 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 23:44:35 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:44:35 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:44:35 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9778481125831604, 'recall': 0.9903846383094788, 'f1': 0.9840764999389648}\n",
            "\n",
            "2024-05-29 23:44:35 :: encode posts per user in batch ...\n",
            "2024-05-29 23:44:35 :: First two user ids in current batch: [3040268161] and [16673030]\n",
            "called:  (348, 768)\n",
            "called:  (371, 768)\n",
            "called:  (249, 768)\n",
            "called:  (251, 768)\n",
            "called:  (2229, 768)\n",
            "called:  (212, 768)\n",
            "called:  (522, 768)\n",
            "called:  (226, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9823, recall: 0.9923, f1: 0.9873, accuracy: 0.9870, batch_loss: 0.0013, loss: 0.0398 ||:  86%|########5 | 6/7 [09:54<01:36, 96.50s/it] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 23:45:52 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 23:45:52 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:45:52 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 23:45:52 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:45:52 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:45:52 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9822784662246704, 'recall': 0.9923273921012878, 'f1': 0.9872773885726929}\n",
            "\n",
            "2024-05-29 23:45:52 :: encode posts per user in batch ...\n",
            "2024-05-29 23:45:52 :: First two user ids in current batch: [295696126] and [3293157922]\n",
            "called:  (219, 768)\n",
            "called:  (751, 768)\n",
            "called:  (366, 768)\n",
            "called:  (947, 768)\n",
            "called:  (218, 768)\n",
            "called:  (246, 768)\n",
            "called:  (507, 768)\n",
            "called:  (985, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "precision: 0.9817, recall: 0.9931, f1: 0.9873, accuracy: 0.9869, batch_loss: 0.0127, loss: 0.0359 ||: 100%|##########| 7/7 [11:02<00:00, 94.63s/it]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/cuda/memory.py:330: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
            "  warnings.warn(\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 23:47:00 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 23:47:00 :: tensor size after padding: torch.Size([74, 200, 768])\n",
            "2024-05-29 23:47:00 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([74, 200, 768])]\n",
            "2024-05-29 23:47:00 :: post masking: content [torch.Size([74, 200])]\n",
            "new tenor size: torch.Size([74, 200, 768])\n",
            "2024-05-29 23:47:00 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([74, 200, 768])\n",
            "2024-05-29 23:47:00 :: post reprsentation shape : torch.Size([74, 768])\n",
            "{'precision': 0.9816933870315552, 'recall': 0.9930555820465088, 'f1': 0.9873418211936951}\n",
            "\n",
            "{'precision': 0.9816933870315552, 'recall': 0.9930555820465088, 'f1': 0.9873418211936951}\n",
            "\n",
            "Metrics at the end of epoch: 6 {'best_epoch': 5, 'peak_worker_0_memory_MB': 2071.5859375, 'peak_gpu_0_memory_MB': 1573.1474609375, 'training_duration': '6:05:02.903367', 'epoch': 6, 'training_precision': 0.9940374493598938, 'training_recall': 0.9011582732200623, 'training_f1': 0.9453219771385193, 'training_accuracy': 0.946513470681458, 'training_loss': 0.07651024255901576, 'training_worker_0_memory_MB': 2071.5859375, 'training_gpu_0_memory_MB': 1573.1474609375, 'validation_precision': 0.9816933870315552, 'validation_recall': 0.9930555820465088, 'validation_f1': 0.9873418211936951, 'validation_accuracy': 0.9869358669833729, 'validation_loss': 0.03594362542831472, 'best_validation_precision': 0.9953488111495972, 'best_validation_recall': 0.9907407164573669, 'best_validation_f1': 0.9930394887924194, 'best_validation_accuracy': 0.9928741092636579, 'best_validation_loss': 0.032140906035367935}\n",
            "2024-05-29 23:47:00 :: encode posts per user in batch ...\n",
            "2024-05-29 23:47:00 :: First two user ids in current batch: [714721383872339968] and [15173851]\n",
            "called:  (220, 768)\n",
            "called:  (835, 768)\n",
            "called:  (352, 768)\n",
            "called:  (262, 768)\n",
            "called:  (830, 768)\n",
            "called:  (376, 768)\n",
            "called:  (231, 768)\n",
            "called:  (231, 768)\n",
            "called:  (389, 768)\n",
            "called:  (290, 768)\n",
            "called:  (465, 768)\n",
            "called:  (511, 768)\n",
            "called:  (244, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9818, recall: 0.8182, f1: 0.8926, accuracy: 0.8984, batch_loss: 0.1075, loss: 0.1075 ||:   5%|5         | 1/20 [01:47<34:09, 107.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 23:48:48 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 23:48:48 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:48:48 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 23:48:48 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:48:48 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:48:48 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9818181991577148, 'recall': 0.8181818127632141, 'f1': 0.8925620317459106}\n",
            "\n",
            "2024-05-29 23:48:48 :: encode posts per user in batch ...\n",
            "2024-05-29 23:48:48 :: First two user ids in current batch: [2232432945] and [2572268096]\n",
            "called:  (255, 768)\n",
            "called:  (284, 768)\n",
            "called:  (262, 768)\n",
            "called:  (267, 768)\n",
            "called:  (259, 768)\n",
            "called:  (535, 768)\n",
            "called:  (523, 768)\n",
            "called:  (444, 768)\n",
            "called:  (437, 768)\n",
            "called:  (410, 768)\n",
            "called:  (1601, 768)\n",
            "called:  (388, 768)\n",
            "called:  (335, 768)\n",
            "called:  (1543, 768)\n",
            "called:  (228, 768)\n",
            "called:  (254, 768)\n",
            "called:  (296, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9826, recall: 0.8626, f1: 0.9187, accuracy: 0.9219, batch_loss: 0.1268, loss: 0.1171 ||:  10%|#         | 2/20 [04:14<39:11, 130.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 23:51:14 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 23:51:14 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:51:14 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 23:51:14 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:51:14 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:51:14 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9826086759567261, 'recall': 0.8625954389572144, 'f1': 0.9186992049217224}\n",
            "\n",
            "2024-05-29 23:51:15 :: encode posts per user in batch ...\n",
            "2024-05-29 23:51:15 :: First two user ids in current batch: [1017014683] and [10255262]\n",
            "called:  (914, 768)\n",
            "called:  (420, 768)\n",
            "called:  (555, 768)\n",
            "called:  (254, 768)\n",
            "called:  (598, 768)\n",
            "called:  (1572, 768)\n",
            "called:  (266, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9781, recall: 0.8861, f1: 0.9299, accuracy: 0.9297, batch_loss: 0.0814, loss: 0.1052 ||:  15%|#5        | 3/20 [05:45<31:56, 112.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 23:52:46 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 23:52:46 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:52:46 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 23:52:46 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:52:46 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:52:46 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9781420826911926, 'recall': 0.8861386179924011, 'f1': 0.9298701286315918}\n",
            "\n",
            "2024-05-29 23:52:46 :: encode posts per user in batch ...\n",
            "2024-05-29 23:52:46 :: First two user ids in current batch: [274176607] and [297139825]\n",
            "called:  (2534, 768)\n",
            "called:  (337, 768)\n",
            "called:  (222, 768)\n",
            "called:  (942, 768)\n",
            "called:  (276, 768)\n",
            "called:  (499, 768)\n",
            "called:  (482, 768)\n",
            "called:  (288, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9789, recall: 0.8889, f1: 0.9317, accuracy: 0.9336, batch_loss: 0.0727, loss: 0.0971 ||:  20%|##        | 4/20 [07:28<28:58, 108.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 23:54:28 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 23:54:28 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:54:28 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 23:54:28 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:54:28 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:54:28 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9789029359817505, 'recall': 0.8888888955116272, 'f1': 0.93172687292099}\n",
            "\n",
            "2024-05-29 23:54:28 :: encode posts per user in batch ...\n",
            "2024-05-29 23:54:28 :: First two user ids in current batch: [3242008588] and [449480815]\n",
            "called:  (524, 768)\n",
            "called:  (304, 768)\n",
            "called:  (468, 768)\n",
            "called:  (390, 768)\n",
            "called:  (207, 768)\n",
            "called:  (201, 768)\n",
            "called:  (1284, 768)\n",
            "called:  (373, 768)\n",
            "called:  (517, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9835, recall: 0.9003, f1: 0.9401, accuracy: 0.9406, batch_loss: 0.0563, loss: 0.0889 ||:  25%|##5       | 5/20 [08:52<24:55, 99.68s/it] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 23:55:52 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 23:55:52 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:55:52 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 23:55:52 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:55:52 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:55:52 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9834983348846436, 'recall': 0.9003021121025085, 'f1': 0.9400630593299866}\n",
            "\n",
            "2024-05-29 23:55:52 :: encode posts per user in batch ...\n",
            "2024-05-29 23:55:52 :: First two user ids in current batch: [1130698574] and [4463347036]\n",
            "called:  (795, 768)\n",
            "called:  (861, 768)\n",
            "called:  (464, 768)\n",
            "called:  (283, 768)\n",
            "called:  (2062, 768)\n",
            "called:  (692, 768)\n",
            "called:  (498, 768)\n",
            "called:  (634, 768)\n",
            "called:  (822, 768)\n",
            "called:  (2668, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9860, recall: 0.8959, f1: 0.9388, accuracy: 0.9401, batch_loss: 0.0756, loss: 0.0867 ||:  30%|###       | 6/20 [11:31<27:57, 119.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-29 23:58:31 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-29 23:58:31 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:58:31 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-29 23:58:31 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:58:31 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-29 23:58:31 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9860334992408752, 'recall': 0.8959391117095947, 'f1': 0.938829779624939}\n",
            "\n",
            "2024-05-29 23:58:31 :: encode posts per user in batch ...\n",
            "2024-05-29 23:58:31 :: First two user ids in current batch: [152883896] and [2636523965]\n",
            "called:  (323, 768)\n",
            "called:  (1567, 768)\n",
            "called:  (441, 768)\n",
            "called:  (716, 768)\n",
            "called:  (1463, 768)\n",
            "called:  (493, 768)\n",
            "called:  (541, 768)\n",
            "called:  (207, 768)\n",
            "called:  (937, 768)\n",
            "called:  (527, 768)\n",
            "called:  (280, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9883, recall: 0.8977, f1: 0.9408, accuracy: 0.9408, batch_loss: 0.0680, loss: 0.0840 ||:  35%|###5      | 7/20 [13:42<26:46, 123.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 00:00:42 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 00:00:42 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:00:42 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-30 00:00:42 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:00:42 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:00:42 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9882628917694092, 'recall': 0.8976545929908752, 'f1': 0.9407821297645569}\n",
            "\n",
            "2024-05-30 00:00:42 :: encode posts per user in batch ...\n",
            "2024-05-30 00:00:42 :: First two user ids in current batch: [2538813181] and [522596064]\n",
            "called:  (840, 768)\n",
            "called:  (383, 768)\n",
            "called:  (458, 768)\n",
            "called:  (942, 768)\n",
            "called:  (326, 768)\n",
            "called:  (632, 768)\n",
            "called:  (673, 768)\n",
            "called:  (323, 768)\n",
            "called:  (320, 768)\n",
            "called:  (360, 768)\n",
            "called:  (600, 768)\n",
            "called:  (1237, 768)\n",
            "called:  (336, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9896, recall: 0.8979, f1: 0.9415, accuracy: 0.9424, batch_loss: 0.0797, loss: 0.0835 ||:  40%|####      | 8/20 [15:54<25:14, 126.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 00:02:54 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 00:02:54 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:02:54 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-30 00:02:54 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:02:54 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:02:54 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9895833134651184, 'recall': 0.8979206085205078, 'f1': 0.9415262937545776}\n",
            "\n",
            "2024-05-30 00:02:54 :: encode posts per user in batch ...\n",
            "2024-05-30 00:02:54 :: First two user ids in current batch: [315516639] and [3294630133]\n",
            "called:  (451, 768)\n",
            "called:  (464, 768)\n",
            "called:  (377, 768)\n",
            "called:  (706, 768)\n",
            "called:  (230, 768)\n",
            "called:  (1772, 768)\n",
            "called:  (237, 768)\n",
            "called:  (573, 768)\n",
            "called:  (1270, 768)\n",
            "called:  (216, 768)\n",
            "called:  (383, 768)\n",
            "called:  (286, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9908, recall: 0.8968, f1: 0.9415, accuracy: 0.9418, batch_loss: 0.1114, loss: 0.0866 ||:  45%|####5     | 9/20 [18:01<23:13, 126.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 00:05:02 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 00:05:02 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:05:02 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-30 00:05:02 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:05:02 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:05:02 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9908088445663452, 'recall': 0.8968386054039001, 'f1': 0.9414847493171692}\n",
            "\n",
            "2024-05-30 00:05:02 :: encode posts per user in batch ...\n",
            "2024-05-30 00:05:02 :: First two user ids in current batch: [158519221] and [411158003]\n",
            "called:  (1065, 768)\n",
            "called:  (622, 768)\n",
            "called:  (225, 768)\n",
            "called:  (786, 768)\n",
            "called:  (812, 768)\n",
            "called:  (325, 768)\n",
            "called:  (376, 768)\n",
            "called:  (213, 768)\n",
            "called:  (263, 768)\n",
            "called:  (784, 768)\n",
            "called:  (236, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9917, recall: 0.8986, f1: 0.9429, accuracy: 0.9437, batch_loss: 0.1023, loss: 0.0882 ||:  50%|#####     | 10/20 [19:43<19:48, 118.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 00:06:43 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 00:06:43 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:06:43 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-30 00:06:43 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:06:43 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:06:43 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9916527271270752, 'recall': 0.8986384272575378, 'f1': 0.9428570866584778}\n",
            "\n",
            "2024-05-30 00:06:43 :: encode posts per user in batch ...\n",
            "2024-05-30 00:06:43 :: First two user ids in current batch: [2712962393] and [23794435]\n",
            "called:  (569, 768)\n",
            "called:  (477, 768)\n",
            "called:  (1230, 768)\n",
            "called:  (553, 768)\n",
            "called:  (1096, 768)\n",
            "called:  (1638, 768)\n",
            "called:  (2317, 768)\n",
            "called:  (2116, 768)\n",
            "called:  (539, 768)\n",
            "called:  (356, 768)\n",
            "called:  (1560, 768)\n",
            "called:  (2298, 768)\n",
            "called:  (320, 768)\n",
            "called:  (412, 768)\n",
            "called:  (826, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9922, recall: 0.8973, f1: 0.9424, accuracy: 0.9446, batch_loss: 0.0907, loss: 0.0884 ||:  55%|#####5    | 11/20 [23:46<23:31, 156.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 00:10:46 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 00:10:46 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:10:46 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-30 00:10:46 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:10:46 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:10:46 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9922239780426025, 'recall': 0.897327721118927, 'f1': 0.9423930048942566}\n",
            "\n",
            "2024-05-30 00:10:46 :: encode posts per user in batch ...\n",
            "2024-05-30 00:10:46 :: First two user ids in current batch: [388888812] and [14423451]\n",
            "called:  (288, 768)\n",
            "called:  (520, 768)\n",
            "called:  (900, 768)\n",
            "called:  (2037, 768)\n",
            "called:  (299, 768)\n",
            "called:  (269, 768)\n",
            "called:  (313, 768)\n",
            "called:  (430, 768)\n",
            "called:  (229, 768)\n",
            "called:  (483, 768)\n",
            "called:  (297, 768)\n",
            "called:  (338, 768)\n",
            "called:  (233, 768)\n",
            "called:  (2068, 768)\n",
            "called:  (385, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9915, recall: 0.9017, f1: 0.9444, accuracy: 0.9466, batch_loss: 0.0836, loss: 0.0880 ||:  60%|######    | 12/20 [26:20<20:47, 155.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 00:13:20 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 00:13:20 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:13:20 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-30 00:13:20 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:13:20 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:13:20 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.991465151309967, 'recall': 0.9016817808151245, 'f1': 0.9444444179534912}\n",
            "\n",
            "2024-05-30 00:13:20 :: encode posts per user in batch ...\n",
            "2024-05-30 00:13:20 :: First two user ids in current batch: [1165111988] and [4832873160]\n",
            "called:  (503, 768)\n",
            "called:  (950, 768)\n",
            "called:  (2042, 768)\n",
            "called:  (1103, 768)\n",
            "called:  (216, 768)\n",
            "called:  (232, 768)\n",
            "called:  (515, 768)\n",
            "called:  (235, 768)\n",
            "called:  (610, 768)\n",
            "called:  (257, 768)\n",
            "called:  (1362, 768)\n",
            "called:  (651, 768)\n",
            "called:  (1983, 768)\n",
            "called:  (347, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9922, recall: 0.9030, f1: 0.9455, accuracy: 0.9471, batch_loss: 0.0726, loss: 0.0868 ||:  65%|######5   | 13/20 [29:23<19:10, 164.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 00:16:24 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 00:16:24 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:16:24 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-30 00:16:24 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:16:24 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:16:24 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9921976327896118, 'recall': 0.9029585719108582, 'f1': 0.9454770684242249}\n",
            "\n",
            "2024-05-30 00:16:24 :: encode posts per user in batch ...\n",
            "2024-05-30 00:16:24 :: First two user ids in current batch: [3054136006] and [172856944]\n",
            "called:  (947, 768)\n",
            "called:  (514, 768)\n",
            "called:  (279, 768)\n",
            "called:  (1230, 768)\n",
            "called:  (641, 768)\n",
            "called:  (453, 768)\n",
            "called:  (263, 768)\n",
            "called:  (551, 768)\n",
            "called:  (282, 768)\n",
            "called:  (1025, 768)\n",
            "called:  (1059, 768)\n",
            "called:  (458, 768)\n",
            "called:  (294, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9916, recall: 0.9057, f1: 0.9467, accuracy: 0.9481, batch_loss: 0.0613, loss: 0.0850 ||:  70%|#######   | 14/20 [31:39<15:33, 155.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 00:18:39 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 00:18:39 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:18:39 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-30 00:18:39 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:18:39 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:18:39 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9915966391563416, 'recall': 0.905701756477356, 'f1': 0.9467049241065979}\n",
            "\n",
            "2024-05-30 00:18:39 :: encode posts per user in batch ...\n",
            "2024-05-30 00:18:39 :: First two user ids in current batch: [289694289] and [172109901]\n",
            "called:  (226, 768)\n",
            "called:  (1909, 768)\n",
            "called:  (294, 768)\n",
            "called:  (413, 768)\n",
            "called:  (1181, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9922, recall: 0.9059, f1: 0.9471, accuracy: 0.9484, batch_loss: 0.0666, loss: 0.0838 ||:  75%|#######5  | 15/20 [32:59<11:05, 133.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 00:20:00 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 00:20:00 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:20:00 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-30 00:20:00 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:20:00 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:20:00 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9921612739562988, 'recall': 0.9059304594993591, 'f1': 0.9470870494842529}\n",
            "\n",
            "2024-05-30 00:20:00 :: encode posts per user in batch ...\n",
            "2024-05-30 00:20:00 :: First two user ids in current batch: [2717428366] and [841981478]\n",
            "called:  (328, 768)\n",
            "called:  (854, 768)\n",
            "called:  (420, 768)\n",
            "called:  (618, 768)\n",
            "called:  (279, 768)\n",
            "called:  (413, 768)\n",
            "called:  (493, 768)\n",
            "called:  (529, 768)\n",
            "called:  (644, 768)\n",
            "called:  (850, 768)\n",
            "called:  (627, 768)\n",
            "called:  (456, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9926, recall: 0.9047, f1: 0.9466, accuracy: 0.9482, batch_loss: 0.0860, loss: 0.0839 ||:  80%|########  | 16/20 [35:00<08:37, 129.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 00:22:00 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 00:22:00 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:22:00 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-30 00:22:00 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:22:00 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:22:00 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9926082491874695, 'recall': 0.9047160744667053, 'f1': 0.9466263651847839}\n",
            "\n",
            "2024-05-30 00:22:01 :: encode posts per user in batch ...\n",
            "2024-05-30 00:22:01 :: First two user ids in current batch: [129689777] and [2796425153]\n",
            "called:  (2189, 768)\n",
            "called:  (222, 768)\n",
            "called:  (389, 768)\n",
            "called:  (407, 768)\n",
            "called:  (326, 768)\n",
            "called:  (329, 768)\n",
            "called:  (556, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9931, recall: 0.9053, f1: 0.9472, accuracy: 0.9485, batch_loss: 0.0564, loss: 0.0823 ||:  85%|########5 | 17/20 [36:22<05:45, 115.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 00:23:22 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 00:23:22 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:23:22 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-30 00:23:22 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:23:22 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:23:22 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9930761456489563, 'recall': 0.9053201079368591, 'f1': 0.9471697807312012}\n",
            "\n",
            "2024-05-30 00:23:23 :: encode posts per user in batch ...\n",
            "2024-05-30 00:23:23 :: First two user ids in current batch: [627001568] and [3174911426]\n",
            "called:  (1594, 768)\n",
            "called:  (616, 768)\n",
            "called:  (371, 768)\n",
            "called:  (249, 768)\n",
            "called:  (831, 768)\n",
            "called:  (283, 768)\n",
            "called:  (397, 768)\n",
            "called:  (959, 768)\n",
            "called:  (439, 768)\n",
            "called:  (464, 768)\n",
            "called:  (241, 768)\n",
            "called:  (804, 768)\n",
            "called:  (426, 768)\n",
            "called:  (332, 768)\n",
            "called:  (223, 768)\n",
            "called:  (1012, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9926, recall: 0.9051, f1: 0.9468, accuracy: 0.9479, batch_loss: 0.0999, loss: 0.0833 ||:  90%|######### | 18/20 [39:04<04:18, 129.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 00:26:04 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 00:26:04 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:26:04 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-30 00:26:04 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:26:04 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:26:04 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9925650358200073, 'recall': 0.9050847291946411, 'f1': 0.9468085169792175}\n",
            "\n",
            "2024-05-30 00:26:04 :: encode posts per user in batch ...\n",
            "2024-05-30 00:26:04 :: First two user ids in current batch: [2931206170] and [373617596]\n",
            "called:  (323, 768)\n",
            "called:  (800, 768)\n",
            "called:  (358, 768)\n",
            "called:  (326, 768)\n",
            "called:  (655, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9929, recall: 0.9036, f1: 0.9462, accuracy: 0.9474, batch_loss: 0.0945, loss: 0.0838 ||:  95%|#########5| 19/20 [40:00<01:47, 107.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 00:27:01 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 00:27:01 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:27:01 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-30 00:27:01 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:27:01 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:27:01 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9929391145706177, 'recall': 0.9036144614219666, 'f1': 0.9461733102798462}\n",
            "\n",
            "2024-05-30 00:27:01 :: encode posts per user in batch ...\n",
            "2024-05-30 00:27:01 :: First two user ids in current batch: [32064936] and [619131572]\n",
            "called:  (259, 768)\n",
            "called:  (206, 768)\n",
            "called:  (936, 768)\n",
            "called:  (208, 768)\n",
            "called:  (685, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "precision: 0.9932, recall: 0.9042, f1: 0.9466, accuracy: 0.9477, batch_loss: 0.0568, loss: 0.0825 ||: 100%|##########| 20/20 [40:48<00:00, 122.41s/it]\n",
            "  0%|          | 0/7 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 00:27:48 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 00:27:48 :: tensor size after padding: torch.Size([92, 200, 768])\n",
            "2024-05-30 00:27:48 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([92, 200, 768])]\n",
            "2024-05-30 00:27:48 :: post masking: content [torch.Size([92, 200])]\n",
            "new tenor size: torch.Size([92, 200, 768])\n",
            "2024-05-30 00:27:48 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([92, 200, 768])\n",
            "2024-05-30 00:27:48 :: post reprsentation shape : torch.Size([92, 768])\n",
            "{'precision': 0.9932146072387695, 'recall': 0.9042471051216125, 'f1': 0.946645200252533}\n",
            "\n",
            "{'precision': 0.9932146072387695, 'recall': 0.9042471051216125, 'f1': 0.946645200252533}\n",
            "\n",
            "2024-05-30 00:27:48 :: encode posts per user in batch ...\n",
            "2024-05-30 00:27:48 :: First two user ids in current batch: [67392818] and [115904805]\n",
            "called:  (303, 768)\n",
            "called:  (246, 768)\n",
            "called:  (241, 768)\n",
            "called:  (232, 768)\n",
            "called:  (226, 768)\n",
            "called:  (201, 768)\n",
            "called:  (352, 768)\n",
            "called:  (249, 768)\n",
            "called:  (366, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 1.0000, recall: 1.0000, f1: 1.0000, accuracy: 1.0000, batch_loss: 0.0021, loss: 0.0021 ||:  14%|#4        | 1/7 [00:50<05:02, 50.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 00:28:39 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 00:28:39 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:28:39 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-30 00:28:39 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:28:39 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:28:39 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
            "\n",
            "2024-05-30 00:28:39 :: encode posts per user in batch ...\n",
            "2024-05-30 00:28:39 :: First two user ids in current batch: [735257592130195456] and [101324552]\n",
            "called:  (223, 768)\n",
            "called:  (401, 768)\n",
            "called:  (292, 768)\n",
            "called:  (302, 768)\n",
            "called:  (232, 768)\n",
            "called:  (772, 768)\n",
            "called:  (874, 768)\n",
            "called:  (351, 768)\n",
            "called:  (522, 768)\n",
            "called:  (215, 768)\n",
            "called:  (1194, 768)\n",
            "called:  (507, 768)\n",
            "called:  (251, 768)\n",
            "called:  (216, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 1.0000, recall: 0.9783, f1: 0.9890, accuracy: 0.9883, batch_loss: 0.0673, loss: 0.0347 ||:  29%|##8       | 2/7 [02:42<07:12, 86.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 00:30:31 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 00:30:31 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:30:31 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-30 00:30:31 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:30:31 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:30:31 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 1.0, 'recall': 0.97826087474823, 'f1': 0.9890109896659851}\n",
            "\n",
            "2024-05-30 00:30:31 :: encode posts per user in batch ...\n",
            "2024-05-30 00:30:31 :: First two user ids in current batch: [1153459789] and [438454672]\n",
            "called:  (214, 768)\n",
            "called:  (212, 768)\n",
            "called:  (289, 768)\n",
            "called:  (207, 768)\n",
            "called:  (1008, 768)\n",
            "called:  (932, 768)\n",
            "called:  (523, 768)\n",
            "called:  (751, 768)\n",
            "called:  (666, 768)\n",
            "called:  (1604, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9949, recall: 0.9848, f1: 0.9898, accuracy: 0.9896, batch_loss: 0.0129, loss: 0.0274 ||:  43%|####2     | 3/7 [04:29<06:23, 95.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 00:32:17 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 00:32:17 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:32:17 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-30 00:32:17 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:32:17 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:32:17 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9948979616165161, 'recall': 0.9848484992980957, 'f1': 0.989847719669342}\n",
            "\n",
            "2024-05-30 00:32:18 :: encode posts per user in batch ...\n",
            "2024-05-30 00:32:18 :: First two user ids in current batch: [132696556] and [399605744]\n",
            "called:  (218, 768)\n",
            "called:  (440, 768)\n",
            "called:  (336, 768)\n",
            "called:  (449, 768)\n",
            "called:  (285, 768)\n",
            "called:  (283, 768)\n",
            "called:  (324, 768)\n",
            "called:  (431, 768)\n",
            "called:  (985, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9962, recall: 0.9848, f1: 0.9905, accuracy: 0.9902, batch_loss: 0.0193, loss: 0.0254 ||:  57%|#####7    | 4/7 [05:44<04:22, 87.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 00:33:32 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 00:33:32 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:33:32 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-30 00:33:32 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:33:32 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:33:32 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9961685538291931, 'recall': 0.9848484992980957, 'f1': 0.990476131439209}\n",
            "\n",
            "2024-05-30 00:33:32 :: encode posts per user in batch ...\n",
            "2024-05-30 00:33:32 :: First two user ids in current batch: [331380408] and [2711255306]\n",
            "called:  (1078, 768)\n",
            "called:  (297, 768)\n",
            "called:  (1477, 768)\n",
            "called:  (310, 768)\n",
            "called:  (329, 768)\n",
            "called:  (348, 768)\n",
            "called:  (947, 768)\n",
            "called:  (236, 768)\n",
            "called:  (265, 768)\n",
            "called:  (1311, 768)\n",
            "called:  (219, 768)\n",
            "called:  (421, 768)\n",
            "called:  (309, 768)\n",
            "called:  (1923, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9970, recall: 0.9880, f1: 0.9925, accuracy: 0.9922, batch_loss: 0.0070, loss: 0.0217 ||:  71%|#######1  | 5/7 [08:09<03:36, 108.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 00:35:58 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 00:35:58 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:35:58 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-30 00:35:58 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:35:58 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:35:58 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9969696998596191, 'recall': 0.9879879951477051, 'f1': 0.9924585223197937}\n",
            "\n",
            "2024-05-30 00:35:58 :: encode posts per user in batch ...\n",
            "2024-05-30 00:35:58 :: First two user ids in current batch: [746496955300249601] and [242547030]\n",
            "called:  (226, 768)\n",
            "called:  (371, 768)\n",
            "called:  (2229, 768)\n",
            "called:  (1122, 768)\n",
            "called:  (989, 768)\n",
            "called:  (608, 768)\n",
            "called:  (222, 768)\n",
            "called:  (318, 768)\n",
            "called:  (1276, 768)\n",
            "called:  (242, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9949, recall: 0.9875, f1: 0.9912, accuracy: 0.9909, batch_loss: 0.0599, loss: 0.0281 ||:  86%|########5 | 6/7 [10:10<01:52, 112.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 00:37:59 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 00:37:59 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:37:59 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-30 00:37:59 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:37:59 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:37:59 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9949495196342468, 'recall': 0.9874686598777771, 'f1': 0.9911949634552002}\n",
            "\n",
            "2024-05-30 00:37:59 :: encode posts per user in batch ...\n",
            "2024-05-30 00:37:59 :: First two user ids in current batch: [1382368694] and [244939232]\n",
            "called:  (2606, 768)\n",
            "called:  (269, 768)\n",
            "called:  (207, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "precision: 0.9953, recall: 0.9884, f1: 0.9919, accuracy: 0.9917, batch_loss: 0.0021, loss: 0.0244 ||: 100%|##########| 7/7 [11:02<00:00, 94.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 00:38:51 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 00:38:51 :: tensor size after padding: torch.Size([74, 200, 768])\n",
            "2024-05-30 00:38:51 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([74, 200, 768])]\n",
            "2024-05-30 00:38:51 :: post masking: content [torch.Size([74, 200])]\n",
            "new tenor size: torch.Size([74, 200, 768])\n",
            "2024-05-30 00:38:51 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([74, 200, 768])\n",
            "2024-05-30 00:38:51 :: post reprsentation shape : torch.Size([74, 768])\n",
            "{'precision': 0.9953380227088928, 'recall': 0.9884259104728699, 'f1': 0.9918699264526367}\n",
            "\n",
            "{'precision': 0.9953380227088928, 'recall': 0.9884259104728699, 'f1': 0.9918699264526367}\n",
            "\n",
            "Metrics at the end of epoch: 7 {'best_epoch': 7, 'peak_worker_0_memory_MB': 2071.5859375, 'peak_gpu_0_memory_MB': 1573.1474609375, 'training_duration': '6:56:53.353757', 'epoch': 7, 'training_precision': 0.9932146072387695, 'training_recall': 0.9042471051216125, 'training_f1': 0.946645200252533, 'training_accuracy': 0.9477020602218701, 'training_loss': 0.08249233327805996, 'training_worker_0_memory_MB': 2071.5859375, 'training_gpu_0_memory_MB': 1573.1474609375, 'validation_precision': 0.9953380227088928, 'validation_recall': 0.9884259104728699, 'validation_f1': 0.9918699264526367, 'validation_accuracy': 0.9916864608076009, 'validation_loss': 0.02436796698852309, 'best_validation_precision': 0.9953380227088928, 'best_validation_recall': 0.9884259104728699, 'best_validation_f1': 0.9918699264526367, 'best_validation_accuracy': 0.9916864608076009, 'best_validation_loss': 0.02436796698852309}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/cuda/memory.py:330: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
            "  warnings.warn(\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 00:38:52 :: encode posts per user in batch ...\n",
            "2024-05-30 00:38:52 :: First two user ids in current batch: [811424076799639552] and [1968531222]\n",
            "called:  (241, 768)\n",
            "called:  (320, 768)\n",
            "called:  (1270, 768)\n",
            "called:  (216, 768)\n",
            "called:  (213, 768)\n",
            "called:  (573, 768)\n",
            "called:  (830, 768)\n",
            "called:  (1230, 768)\n",
            "called:  (383, 768)\n",
            "called:  (323, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 1.0000, recall: 0.8857, f1: 0.9394, accuracy: 0.9375, batch_loss: 0.0726, loss: 0.0726 ||:   5%|5         | 1/20 [01:50<34:57, 110.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 00:40:42 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 00:40:42 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:40:42 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-30 00:40:42 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:40:42 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:40:42 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 1.0, 'recall': 0.8857142925262451, 'f1': 0.939393937587738}\n",
            "\n",
            "2024-05-30 00:40:42 :: encode posts per user in batch ...\n",
            "2024-05-30 00:40:42 :: First two user ids in current batch: [716803361991819264] and [129046320]\n",
            "called:  (499, 768)\n",
            "called:  (2062, 768)\n",
            "called:  (468, 768)\n",
            "called:  (936, 768)\n",
            "called:  (458, 768)\n",
            "called:  (1025, 768)\n",
            "called:  (279, 768)\n",
            "called:  (360, 768)\n",
            "called:  (236, 768)\n",
            "called:  (441, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 1.0000, recall: 0.8832, f1: 0.9380, accuracy: 0.9375, batch_loss: 0.1647, loss: 0.1187 ||:  10%|#         | 2/20 [03:47<34:19, 114.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 00:42:39 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 00:42:39 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:42:39 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-30 00:42:39 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:42:39 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:42:39 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 1.0, 'recall': 0.8832116723060608, 'f1': 0.9379845261573792}\n",
            "\n",
            "2024-05-30 00:42:39 :: encode posts per user in batch ...\n",
            "2024-05-30 00:42:39 :: First two user ids in current batch: [417340902] and [1421480214]\n",
            "called:  (352, 768)\n",
            "called:  (282, 768)\n",
            "called:  (1772, 768)\n",
            "called:  (276, 768)\n",
            "called:  (600, 768)\n",
            "called:  (226, 768)\n",
            "called:  (515, 768)\n",
            "called:  (685, 768)\n",
            "called:  (437, 768)\n",
            "called:  (389, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 1.0000, recall: 0.9034, f1: 0.9492, accuracy: 0.9479, batch_loss: 0.0554, loss: 0.0976 ||:  15%|#5        | 3/20 [05:27<30:31, 107.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 00:44:19 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 00:44:19 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:44:19 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-30 00:44:19 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:44:19 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:44:19 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 1.0, 'recall': 0.9033816456794739, 'f1': 0.9492385983467102}\n",
            "\n",
            "2024-05-30 00:44:19 :: encode posts per user in batch ...\n",
            "2024-05-30 00:44:19 :: First two user ids in current batch: [1302230832] and [189790300]\n",
            "called:  (389, 768)\n",
            "called:  (201, 768)\n",
            "called:  (456, 768)\n",
            "called:  (634, 768)\n",
            "called:  (430, 768)\n",
            "called:  (283, 768)\n",
            "called:  (206, 768)\n",
            "called:  (517, 768)\n",
            "called:  (254, 768)\n",
            "called:  (464, 768)\n",
            "called:  (598, 768)\n",
            "called:  (299, 768)\n",
            "called:  (482, 768)\n",
            "called:  (231, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 1.0000, recall: 0.9074, f1: 0.9515, accuracy: 0.9512, batch_loss: 0.0811, loss: 0.0934 ||:  20%|##        | 4/20 [07:18<29:02, 108.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 00:46:10 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 00:46:10 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:46:10 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-30 00:46:10 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:46:10 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:46:10 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 1.0, 'recall': 0.9074074029922485, 'f1': 0.9514563083648682}\n",
            "\n",
            "2024-05-30 00:46:10 :: encode posts per user in batch ...\n",
            "2024-05-30 00:46:10 :: First two user ids in current batch: [33979523] and [2874152273]\n",
            "called:  (335, 768)\n",
            "called:  (539, 768)\n",
            "called:  (420, 768)\n",
            "called:  (706, 768)\n",
            "called:  (914, 768)\n",
            "called:  (1362, 768)\n",
            "called:  (541, 768)\n",
            "called:  (616, 768)\n",
            "called:  (1065, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9966, recall: 0.8985, f1: 0.9450, accuracy: 0.9469, batch_loss: 0.0880, loss: 0.0923 ||:  25%|##5       | 5/20 [09:07<27:16, 109.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 00:47:59 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 00:47:59 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:47:59 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-30 00:47:59 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:47:59 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:47:59 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9965870380401611, 'recall': 0.8984615206718445, 'f1': 0.9449837803840637}\n",
            "\n",
            "2024-05-30 00:47:59 :: encode posts per user in batch ...\n",
            "2024-05-30 00:47:59 :: First two user ids in current batch: [4355916570] and [3993245832]\n",
            "called:  (413, 768)\n",
            "called:  (520, 768)\n",
            "called:  (716, 768)\n",
            "called:  (2189, 768)\n",
            "called:  (244, 768)\n",
            "called:  (451, 768)\n",
            "called:  (1543, 768)\n",
            "called:  (618, 768)\n",
            "called:  (498, 768)\n",
            "called:  (2068, 768)\n",
            "called:  (1594, 768)\n",
            "called:  (1237, 768)\n",
            "called:  (900, 768)\n",
            "called:  (477, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9972, recall: 0.9121, f1: 0.9528, accuracy: 0.9544, batch_loss: 0.0668, loss: 0.0881 ||:  30%|###       | 6/20 [12:39<33:37, 144.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 00:51:31 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 00:51:31 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:51:31 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-30 00:51:31 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:51:31 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:51:31 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9971751570701599, 'recall': 0.9121447205543518, 'f1': 0.9527665376663208}\n",
            "\n",
            "2024-05-30 00:51:31 :: encode posts per user in batch ...\n",
            "2024-05-30 00:51:31 :: First two user ids in current batch: [4659874881] and [2786442471]\n",
            "called:  (388, 768)\n",
            "called:  (304, 768)\n",
            "called:  (2668, 768)\n",
            "called:  (1059, 768)\n",
            "called:  (493, 768)\n",
            "called:  (786, 768)\n",
            "called:  (812, 768)\n",
            "called:  (338, 768)\n",
            "called:  (232, 768)\n",
            "called:  (569, 768)\n",
            "called:  (784, 768)\n",
            "called:  (556, 768)\n",
            "called:  (627, 768)\n",
            "called:  (262, 768)\n",
            "called:  (1463, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9952, recall: 0.9163, f1: 0.9541, accuracy: 0.9554, batch_loss: 0.0665, loss: 0.0850 ||:  35%|###5      | 7/20 [15:47<34:18, 158.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 00:54:39 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 00:54:39 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:54:39 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-30 00:54:39 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:54:39 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:54:39 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9952152967453003, 'recall': 0.91629958152771, 'f1': 0.9541284441947937}\n",
            "\n",
            "2024-05-30 00:54:39 :: encode posts per user in batch ...\n",
            "2024-05-30 00:54:39 :: First two user ids in current batch: [1716581] and [106682211]\n",
            "called:  (323, 768)\n",
            "called:  (225, 768)\n",
            "called:  (207, 768)\n",
            "called:  (2116, 768)\n",
            "called:  (831, 768)\n",
            "called:  (313, 768)\n",
            "called:  (503, 768)\n",
            "called:  (377, 768)\n",
            "called:  (320, 768)\n",
            "called:  (524, 768)\n",
            "called:  (1181, 768)\n",
            "called:  (644, 768)\n",
            "called:  (527, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9959, recall: 0.9213, f1: 0.9571, accuracy: 0.9580, batch_loss: 0.0582, loss: 0.0817 ||:  40%|####      | 8/20 [18:08<30:36, 153.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 00:57:01 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 00:57:01 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:57:01 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-30 00:57:01 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:57:01 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:57:01 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9958506226539612, 'recall': 0.9213051795959473, 'f1': 0.957128643989563}\n",
            "\n",
            "2024-05-30 00:57:01 :: encode posts per user in batch ...\n",
            "2024-05-30 00:57:01 :: First two user ids in current batch: [15173851] and [16985345]\n",
            "called:  (514, 768)\n",
            "called:  (230, 768)\n",
            "called:  (2042, 768)\n",
            "called:  (840, 768)\n",
            "called:  (390, 768)\n",
            "called:  (284, 768)\n",
            "called:  (535, 768)\n",
            "called:  (323, 768)\n",
            "called:  (622, 768)\n",
            "called:  (296, 768)\n",
            "called:  (861, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9963, recall: 0.9185, f1: 0.9558, accuracy: 0.9566, batch_loss: 0.0595, loss: 0.0792 ||:  45%|####5     | 9/20 [20:17<26:37, 145.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 00:59:09 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 00:59:09 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:59:09 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-30 00:59:09 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:59:09 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-30 00:59:09 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9963167309761047, 'recall': 0.9185059666633606, 'f1': 0.9558303952217102}\n",
            "\n",
            "2024-05-30 00:59:09 :: encode posts per user in batch ...\n",
            "2024-05-30 00:59:09 :: First two user ids in current batch: [4578453673] and [2556109368]\n",
            "called:  (1909, 768)\n",
            "called:  (651, 768)\n",
            "called:  (826, 768)\n",
            "called:  (358, 768)\n",
            "called:  (655, 768)\n",
            "called:  (397, 768)\n",
            "called:  (263, 768)\n",
            "called:  (257, 768)\n",
            "called:  (483, 768)\n",
            "called:  (2534, 768)\n",
            "called:  (610, 768)\n",
            "called:  (269, 768)\n",
            "called:  (1567, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9967, recall: 0.9215, f1: 0.9576, accuracy: 0.9578, batch_loss: 0.0676, loss: 0.0780 ||:  50%|#####     | 10/20 [23:15<25:53, 155.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 01:02:07 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 01:02:07 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:02:07 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-30 01:02:07 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:02:07 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:02:07 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9967319965362549, 'recall': 0.921450138092041, 'f1': 0.9576138257980347}\n",
            "\n",
            "2024-05-30 01:02:07 :: encode posts per user in batch ...\n",
            "2024-05-30 01:02:07 :: First two user ids in current batch: [112386734] and [1165111988]\n",
            "called:  (373, 768)\n",
            "called:  (332, 768)\n",
            "called:  (410, 768)\n",
            "called:  (453, 768)\n",
            "called:  (255, 768)\n",
            "called:  (959, 768)\n",
            "called:  (223, 768)\n",
            "called:  (1096, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9970, recall: 0.9236, f1: 0.9589, accuracy: 0.9595, batch_loss: 0.0573, loss: 0.0761 ||:  55%|#####5    | 11/20 [24:31<19:41, 131.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 01:03:23 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 01:03:23 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:03:23 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-30 01:03:23 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:03:23 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:03:23 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9970015287399292, 'recall': 0.9236111044883728, 'f1': 0.9589041471481323}\n",
            "\n",
            "2024-05-30 01:03:23 :: encode posts per user in batch ...\n",
            "2024-05-30 01:03:23 :: First two user ids in current batch: [382076973] and [609945242]\n",
            "called:  (854, 768)\n",
            "called:  (207, 768)\n",
            "called:  (326, 768)\n",
            "called:  (326, 768)\n",
            "called:  (233, 768)\n",
            "called:  (1638, 768)\n",
            "called:  (263, 768)\n",
            "called:  (795, 768)\n",
            "called:  (822, 768)\n",
            "called:  (266, 768)\n",
            "called:  (228, 768)\n",
            "called:  (2298, 768)\n",
            "called:  (641, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9972, recall: 0.9196, f1: 0.9569, accuracy: 0.9577, batch_loss: 0.0639, loss: 0.0751 ||:  60%|######    | 12/20 [27:02<18:17, 137.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 01:05:54 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 01:05:54 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:05:54 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-30 01:05:54 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:05:54 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:05:54 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9972337484359741, 'recall': 0.9196428656578064, 'f1': 0.9568679332733154}\n",
            "\n",
            "2024-05-30 01:05:54 :: encode posts per user in batch ...\n",
            "2024-05-30 01:05:54 :: First two user ids in current batch: [21888269] and [756681929395765248]\n",
            "called:  (950, 768)\n",
            "called:  (947, 768)\n",
            "called:  (376, 768)\n",
            "called:  (371, 768)\n",
            "called:  (249, 768)\n",
            "called:  (420, 768)\n",
            "called:  (2317, 768)\n",
            "called:  (383, 768)\n",
            "called:  (288, 768)\n",
            "called:  (444, 768)\n",
            "called:  (551, 768)\n",
            "called:  (297, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9962, recall: 0.9210, f1: 0.9571, accuracy: 0.9579, batch_loss: 0.0638, loss: 0.0743 ||:  65%|######5   | 13/20 [29:14<15:50, 135.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 01:08:07 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 01:08:07 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:08:07 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-30 01:08:07 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:08:07 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:08:07 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9961734414100647, 'recall': 0.9209905862808228, 'f1': 0.9571077823638916}\n",
            "\n",
            "2024-05-30 01:08:07 :: encode posts per user in batch ...\n",
            "2024-05-30 01:08:07 :: First two user ids in current batch: [1546606406] and [25001029]\n",
            "called:  (1601, 768)\n",
            "called:  (336, 768)\n",
            "called:  (259, 768)\n",
            "called:  (231, 768)\n",
            "called:  (511, 768)\n",
            "called:  (835, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9964, recall: 0.9179, f1: 0.9556, accuracy: 0.9565, batch_loss: 0.0838, loss: 0.0749 ||:  70%|#######   | 14/20 [30:31<11:47, 117.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 01:09:23 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 01:09:23 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:09:23 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-30 01:09:23 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:09:23 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:09:23 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9964370727539062, 'recall': 0.9179431200027466, 'f1': 0.9555808901786804}\n",
            "\n",
            "2024-05-30 01:09:23 :: encode posts per user in batch ...\n",
            "2024-05-30 01:09:23 :: First two user ids in current batch: [934759062] and [1458242976]\n",
            "called:  (458, 768)\n",
            "called:  (237, 768)\n",
            "called:  (464, 768)\n",
            "called:  (280, 768)\n",
            "called:  (288, 768)\n",
            "called:  (465, 768)\n",
            "called:  (1983, 768)\n",
            "called:  (937, 768)\n",
            "called:  (254, 768)\n",
            "called:  (279, 768)\n",
            "called:  (1284, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9967, recall: 0.9156, f1: 0.9544, accuracy: 0.9552, batch_loss: 0.0714, loss: 0.0747 ||:  75%|#######5  | 15/20 [32:35<09:58, 119.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 01:11:27 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 01:11:27 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:11:27 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-30 01:11:27 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:11:27 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:11:27 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9966777563095093, 'recall': 0.9155645966529846, 'f1': 0.9544008374214172}\n",
            "\n",
            "2024-05-30 01:11:27 :: encode posts per user in batch ...\n",
            "2024-05-30 01:11:27 :: First two user ids in current batch: [576915249] and [1554866528]\n",
            "called:  (216, 768)\n",
            "called:  (2037, 768)\n",
            "called:  (426, 768)\n",
            "called:  (376, 768)\n",
            "called:  (220, 768)\n",
            "called:  (529, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9958, recall: 0.9147, f1: 0.9535, accuracy: 0.9546, batch_loss: 0.1268, loss: 0.0780 ||:  80%|########  | 16/20 [33:49<07:04, 106.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 01:12:42 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 01:12:42 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:12:42 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-30 01:12:42 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:12:42 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:12:42 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9958246350288391, 'recall': 0.9146692156791687, 'f1': 0.9535232782363892}\n",
            "\n",
            "2024-05-30 01:12:42 :: encode posts per user in batch ...\n",
            "2024-05-30 01:12:42 :: First two user ids in current batch: [67615051] and [93774143]\n",
            "called:  (412, 768)\n",
            "called:  (692, 768)\n",
            "called:  (356, 768)\n",
            "called:  (329, 768)\n",
            "called:  (286, 768)\n",
            "called:  (800, 768)\n",
            "called:  (523, 768)\n",
            "called:  (942, 768)\n",
            "called:  (555, 768)\n",
            "called:  (1230, 768)\n",
            "called:  (229, 768)\n",
            "called:  (804, 768)\n",
            "called:  (673, 768)\n",
            "called:  (632, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9951, recall: 0.9161, f1: 0.9540, accuracy: 0.9550, batch_loss: 0.0739, loss: 0.0777 ||:  85%|########5 | 17/20 [36:13<05:52, 117.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 01:15:05 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 01:15:05 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:15:05 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-30 01:15:05 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:15:05 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:15:05 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9951028227806091, 'recall': 0.9161406755447388, 'f1': 0.953990638256073}\n",
            "\n",
            "2024-05-30 01:15:05 :: encode posts per user in batch ...\n",
            "2024-05-30 01:15:05 :: First two user ids in current batch: [22666497] and [122044263]\n",
            "called:  (290, 768)\n",
            "called:  (1012, 768)\n",
            "called:  (553, 768)\n",
            "called:  (267, 768)\n",
            "called:  (326, 768)\n",
            "called:  (1103, 768)\n",
            "called:  (1560, 768)\n",
            "called:  (235, 768)\n",
            "called:  (493, 768)\n",
            "called:  (942, 768)\n",
            "called:  (464, 768)\n",
            "called:  (407, 768)\n",
            "called:  (259, 768)\n",
            "called:  (1572, 768)\n",
            "called:  (222, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9954, recall: 0.9178, f1: 0.9550, accuracy: 0.9562, batch_loss: 0.1477, loss: 0.0816 ||:  90%|######### | 18/20 [38:52<04:20, 130.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 01:17:45 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 01:17:45 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:17:45 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-30 01:17:45 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:17:45 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:17:45 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9953574538230896, 'recall': 0.9178082346916199, 'f1': 0.9550111293792725}\n",
            "\n",
            "2024-05-30 01:17:45 :: encode posts per user in batch ...\n",
            "2024-05-30 01:17:45 :: First two user ids in current batch: [97945564] and [3226052148]\n",
            "called:  (337, 768)\n",
            "called:  (283, 768)\n",
            "called:  (222, 768)\n",
            "called:  (850, 768)\n",
            "called:  (262, 768)\n",
            "called:  (347, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9956, recall: 0.9162, f1: 0.9543, accuracy: 0.9552, batch_loss: 0.0911, loss: 0.0821 ||:  95%|#########5| 19/20 [39:49<01:47, 107.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 01:18:41 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 01:18:41 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:18:41 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-30 01:18:41 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:18:41 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:18:41 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9956217408180237, 'recall': 0.9161966443061829, 'f1': 0.9542593955993652}\n",
            "\n",
            "2024-05-30 01:18:41 :: encode posts per user in batch ...\n",
            "2024-05-30 01:18:41 :: First two user ids in current batch: [755385124427010048] and [857030982]\n",
            "called:  (439, 768)\n",
            "called:  (413, 768)\n",
            "called:  (325, 768)\n",
            "called:  (385, 768)\n",
            "called:  (328, 768)\n",
            "called:  (208, 768)\n",
            "called:  (294, 768)\n",
            "called:  (294, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "precision: 0.9958, recall: 0.9151, f1: 0.9537, accuracy: 0.9544, batch_loss: 0.0734, loss: 0.0817 ||: 100%|##########| 20/20 [40:45<00:00, 122.29s/it]\n",
            "  0%|          | 0/7 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 01:19:38 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 01:19:38 :: tensor size after padding: torch.Size([92, 200, 768])\n",
            "2024-05-30 01:19:38 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([92, 200, 768])]\n",
            "2024-05-30 01:19:38 :: post masking: content [torch.Size([92, 200])]\n",
            "new tenor size: torch.Size([92, 200, 768])\n",
            "2024-05-30 01:19:38 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([92, 200, 768])\n",
            "2024-05-30 01:19:38 :: post reprsentation shape : torch.Size([92, 768])\n",
            "{'precision': 0.9957982897758484, 'recall': 0.915057897567749, 'f1': 0.9537222981452942}\n",
            "\n",
            "{'precision': 0.9957982897758484, 'recall': 0.915057897567749, 'f1': 0.9537222981452942}\n",
            "\n",
            "2024-05-30 01:19:38 :: encode posts per user in batch ...\n",
            "2024-05-30 01:19:38 :: First two user ids in current batch: [3091530881] and [2316539723]\n",
            "called:  (751, 768)\n",
            "called:  (449, 768)\n",
            "called:  (932, 768)\n",
            "called:  (303, 768)\n",
            "called:  (421, 768)\n",
            "called:  (215, 768)\n",
            "called:  (522, 768)\n",
            "called:  (608, 768)\n",
            "called:  (431, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 1.0000, recall: 0.9683, f1: 0.9839, accuracy: 0.9844, batch_loss: 0.0653, loss: 0.0653 ||:  14%|#4        | 1/7 [01:19<07:58, 79.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 01:20:57 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 01:20:57 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:20:57 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-30 01:20:57 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:20:57 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:20:57 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 1.0, 'recall': 0.9682539701461792, 'f1': 0.9838709831237793}\n",
            "\n",
            "2024-05-30 01:20:57 :: encode posts per user in batch ...\n",
            "2024-05-30 01:20:57 :: First two user ids in current batch: [2946776229] and [174220830]\n",
            "called:  (1276, 768)\n",
            "called:  (232, 768)\n",
            "called:  (1923, 768)\n",
            "called:  (219, 768)\n",
            "called:  (222, 768)\n",
            "called:  (772, 768)\n",
            "called:  (2606, 768)\n",
            "called:  (351, 768)\n",
            "called:  (283, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9844, recall: 0.9767, f1: 0.9805, accuracy: 0.9805, batch_loss: 0.0649, loss: 0.0651 ||:  29%|##8       | 2/7 [03:25<08:55, 107.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 01:23:04 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 01:23:04 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:23:04 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-30 01:23:04 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:23:04 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:23:04 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.984375, 'recall': 0.9767441749572754, 'f1': 0.9805447459220886}\n",
            "\n",
            "2024-05-30 01:23:04 :: encode posts per user in batch ...\n",
            "2024-05-30 01:23:04 :: First two user ids in current batch: [2647458960] and [391631136]\n",
            "called:  (1477, 768)\n",
            "called:  (1194, 768)\n",
            "called:  (242, 768)\n",
            "called:  (302, 768)\n",
            "called:  (1122, 768)\n",
            "called:  (1008, 768)\n",
            "called:  (352, 768)\n",
            "called:  (232, 768)\n",
            "called:  (1078, 768)\n",
            "called:  (666, 768)\n",
            "called:  (310, 768)\n",
            "called:  (201, 768)\n",
            "called:  (285, 768)\n",
            "called:  (218, 768)\n",
            "called:  (309, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9897, recall: 0.9797, f1: 0.9847, accuracy: 0.9844, batch_loss: 0.0290, loss: 0.0531 ||:  43%|####2     | 3/7 [05:59<08:33, 128.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 01:25:38 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 01:25:38 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:25:38 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-30 01:25:38 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:25:38 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:25:38 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9897435903549194, 'recall': 0.9796954393386841, 'f1': 0.9846938848495483}\n",
            "\n",
            "2024-05-30 01:25:38 :: encode posts per user in batch ...\n",
            "2024-05-30 01:25:38 :: First two user ids in current batch: [3202172187] and [858138444]\n",
            "called:  (336, 768)\n",
            "called:  (348, 768)\n",
            "called:  (246, 768)\n",
            "called:  (236, 768)\n",
            "called:  (2229, 768)\n",
            "called:  (216, 768)\n",
            "called:  (297, 768)\n",
            "called:  (329, 768)\n",
            "called:  (947, 768)\n",
            "called:  (874, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9922, recall: 0.9846, f1: 0.9884, accuracy: 0.9883, batch_loss: 0.0012, loss: 0.0401 ||:  57%|#####7    | 4/7 [07:35<05:47, 115.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 01:27:14 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 01:27:14 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:27:14 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-30 01:27:14 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:27:14 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:27:14 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9922178983688354, 'recall': 0.9845559597015381, 'f1': 0.9883720278739929}\n",
            "\n",
            "2024-05-30 01:27:14 :: encode posts per user in batch ...\n",
            "2024-05-30 01:27:14 :: First two user ids in current batch: [249447233] and [1907082865]\n",
            "called:  (523, 768)\n",
            "called:  (440, 768)\n",
            "called:  (241, 768)\n",
            "called:  (318, 768)\n",
            "called:  (289, 768)\n",
            "called:  (265, 768)\n",
            "called:  (507, 768)\n",
            "called:  (989, 768)\n",
            "called:  (1311, 768)\n",
            "called:  (1604, 768)\n",
            "called:  (226, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9940, recall: 0.9881, f1: 0.9910, accuracy: 0.9906, batch_loss: 0.0060, loss: 0.0333 ||:  71%|#######1  | 5/7 [09:24<03:45, 113.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 01:29:02 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 01:29:02 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:29:02 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-30 01:29:02 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:29:02 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:29:02 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9940119981765747, 'recall': 0.988095223903656, 'f1': 0.991044819355011}\n",
            "\n",
            "2024-05-30 01:29:02 :: encode posts per user in batch ...\n",
            "2024-05-30 01:29:02 :: First two user ids in current batch: [2614000926] and [766713329351995396]\n",
            "called:  (226, 768)\n",
            "called:  (292, 768)\n",
            "called:  (324, 768)\n",
            "called:  (214, 768)\n",
            "called:  (366, 768)\n",
            "called:  (223, 768)\n",
            "called:  (401, 768)\n",
            "called:  (207, 768)\n",
            "called:  (269, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9949, recall: 0.9898, f1: 0.9923, accuracy: 0.9922, batch_loss: 0.0020, loss: 0.0281 ||:  86%|########5 | 6/7 [10:21<01:34, 94.08s/it] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 01:29:59 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 01:29:59 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:29:59 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-30 01:29:59 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:29:59 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:29:59 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9948586225509644, 'recall': 0.9897698163986206, 'f1': 0.9923076629638672}\n",
            "\n",
            "2024-05-30 01:29:59 :: encode posts per user in batch ...\n",
            "2024-05-30 01:29:59 :: First two user ids in current batch: [242547030] and [2364340860]\n",
            "called:  (251, 768)\n",
            "called:  (371, 768)\n",
            "called:  (207, 768)\n",
            "called:  (212, 768)\n",
            "called:  (249, 768)\n",
            "called:  (985, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "precision: 0.9953, recall: 0.9884, f1: 0.9919, accuracy: 0.9917, batch_loss: 0.0207, loss: 0.0270 ||: 100%|##########| 7/7 [11:01<00:00, 94.52s/it]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/cuda/memory.py:330: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
            "  warnings.warn(\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 01:30:39 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 01:30:39 :: tensor size after padding: torch.Size([74, 200, 768])\n",
            "2024-05-30 01:30:39 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([74, 200, 768])]\n",
            "2024-05-30 01:30:39 :: post masking: content [torch.Size([74, 200])]\n",
            "new tenor size: torch.Size([74, 200, 768])\n",
            "2024-05-30 01:30:39 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([74, 200, 768])\n",
            "2024-05-30 01:30:39 :: post reprsentation shape : torch.Size([74, 768])\n",
            "{'precision': 0.9953380227088928, 'recall': 0.9884259104728699, 'f1': 0.9918699264526367}\n",
            "\n",
            "{'precision': 0.9953380227088928, 'recall': 0.9884259104728699, 'f1': 0.9918699264526367}\n",
            "\n",
            "Metrics at the end of epoch: 8 {'best_epoch': 7, 'peak_worker_0_memory_MB': 2074.94921875, 'peak_gpu_0_memory_MB': 1573.1474609375, 'training_duration': '7:48:42.132442', 'epoch': 8, 'training_precision': 0.9957982897758484, 'training_recall': 0.915057897567749, 'training_f1': 0.9537222981452942, 'training_accuracy': 0.9544374009508716, 'training_loss': 0.08167169727385044, 'training_worker_0_memory_MB': 2074.94921875, 'training_gpu_0_memory_MB': 1573.1474609375, 'validation_precision': 0.9953380227088928, 'validation_recall': 0.9884259104728699, 'validation_f1': 0.9918699264526367, 'validation_accuracy': 0.9916864608076009, 'validation_loss': 0.02700597925909928, 'best_validation_precision': 0.9953380227088928, 'best_validation_recall': 0.9884259104728699, 'best_validation_f1': 0.9918699264526367, 'best_validation_accuracy': 0.9916864608076009, 'best_validation_loss': 0.02436796698852309}\n",
            "2024-05-30 01:30:39 :: encode posts per user in batch ...\n",
            "2024-05-30 01:30:39 :: First two user ids in current batch: [324294391] and [3080544138]\n",
            "called:  (356, 768)\n",
            "called:  (326, 768)\n",
            "called:  (279, 768)\n",
            "called:  (2534, 768)\n",
            "called:  (826, 768)\n",
            "called:  (2068, 768)\n",
            "called:  (420, 768)\n",
            "called:  (1237, 768)\n",
            "called:  (655, 768)\n",
            "called:  (376, 768)\n",
            "called:  (296, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 1.0000, recall: 0.8906, f1: 0.9421, accuracy: 0.9453, batch_loss: 0.0780, loss: 0.0780 ||:   5%|5         | 1/20 [02:46<52:41, 166.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 01:33:26 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 01:33:26 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:33:26 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-30 01:33:26 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:33:26 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:33:26 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 1.0, 'recall': 0.890625, 'f1': 0.942148745059967}\n",
            "\n",
            "2024-05-30 01:33:26 :: encode posts per user in batch ...\n",
            "2024-05-30 01:33:26 :: First two user ids in current batch: [16205293] and [368152564]\n",
            "called:  (529, 768)\n",
            "called:  (373, 768)\n",
            "called:  (299, 768)\n",
            "called:  (323, 768)\n",
            "called:  (786, 768)\n",
            "called:  (1463, 768)\n",
            "called:  (336, 768)\n",
            "called:  (468, 768)\n",
            "called:  (499, 768)\n",
            "called:  (514, 768)\n",
            "called:  (493, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 1.0000, recall: 0.9200, f1: 0.9583, accuracy: 0.9609, batch_loss: 0.0410, loss: 0.0595 ||:  10%|#         | 2/20 [04:34<39:35, 131.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 01:35:13 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 01:35:13 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:35:13 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-30 01:35:13 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:35:13 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:35:13 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 1.0, 'recall': 0.9200000166893005, 'f1': 0.9583333134651184}\n",
            "\n",
            "2024-05-30 01:35:14 :: encode posts per user in batch ...\n",
            "2024-05-30 01:35:14 :: First two user ids in current batch: [269382184] and [242505415]\n",
            "called:  (288, 768)\n",
            "called:  (430, 768)\n",
            "called:  (329, 768)\n",
            "called:  (286, 768)\n",
            "called:  (255, 768)\n",
            "called:  (225, 768)\n",
            "called:  (523, 768)\n",
            "called:  (352, 768)\n",
            "called:  (254, 768)\n",
            "called:  (1230, 768)\n",
            "called:  (266, 768)\n",
            "called:  (229, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 1.0000, recall: 0.9040, f1: 0.9496, accuracy: 0.9505, batch_loss: 0.0825, loss: 0.0672 ||:  15%|#5        | 3/20 [06:05<32:08, 113.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 01:36:45 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 01:36:45 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:36:45 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-30 01:36:45 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:36:45 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:36:45 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 1.0, 'recall': 0.9040403962135315, 'f1': 0.9496021270751953}\n",
            "\n",
            "2024-05-30 01:36:45 :: encode posts per user in batch ...\n",
            "2024-05-30 01:36:45 :: First two user ids in current batch: [3337613123] and [247152544]\n",
            "called:  (259, 768)\n",
            "called:  (232, 768)\n",
            "called:  (328, 768)\n",
            "called:  (716, 768)\n",
            "called:  (456, 768)\n",
            "called:  (1560, 768)\n",
            "called:  (228, 768)\n",
            "called:  (493, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 1.0000, recall: 0.9015, f1: 0.9482, accuracy: 0.9492, batch_loss: 0.0729, loss: 0.0686 ||:  20%|##        | 4/20 [07:30<27:13, 102.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 01:38:10 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 01:38:10 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:38:10 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-30 01:38:10 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:38:10 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:38:10 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 1.0, 'recall': 0.9015151262283325, 'f1': 0.9482071399688721}\n",
            "\n",
            "2024-05-30 01:38:10 :: encode posts per user in batch ...\n",
            "2024-05-30 01:38:10 :: First two user ids in current batch: [274752125] and [15766949]\n",
            "called:  (244, 768)\n",
            "called:  (527, 768)\n",
            "called:  (230, 768)\n",
            "called:  (861, 768)\n",
            "called:  (269, 768)\n",
            "called:  (279, 768)\n",
            "called:  (641, 768)\n",
            "called:  (1181, 768)\n",
            "called:  (206, 768)\n",
            "called:  (535, 768)\n",
            "called:  (323, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9967, recall: 0.9012, f1: 0.9465, accuracy: 0.9469, batch_loss: 0.0924, loss: 0.0734 ||:  25%|##5       | 5/20 [09:10<25:18, 101.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 01:39:49 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 01:39:49 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:39:49 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-30 01:39:49 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:39:49 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:39:49 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.996688723564148, 'recall': 0.901197612285614, 'f1': 0.946540892124176}\n",
            "\n",
            "2024-05-30 01:39:49 :: encode posts per user in batch ...\n",
            "2024-05-30 01:39:49 :: First two user ids in current batch: [3014241258] and [2766967863]\n",
            "called:  (692, 768)\n",
            "called:  (280, 768)\n",
            "called:  (795, 768)\n",
            "called:  (2317, 768)\n",
            "called:  (412, 768)\n",
            "called:  (1096, 768)\n",
            "called:  (376, 768)\n",
            "called:  (233, 768)\n",
            "called:  (385, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9944, recall: 0.9049, f1: 0.9475, accuracy: 0.9492, batch_loss: 0.1169, loss: 0.0806 ||:  30%|###       | 6/20 [11:10<25:06, 107.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 01:41:49 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 01:41:49 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:41:49 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-30 01:41:49 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:41:49 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:41:49 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.994350254535675, 'recall': 0.9048843383789062, 'f1': 0.9475101232528687}\n",
            "\n",
            "2024-05-30 01:41:49 :: encode posts per user in batch ...\n",
            "2024-05-30 01:41:49 :: First two user ids in current batch: [773557883833348096] and [111273431]\n",
            "called:  (263, 768)\n",
            "called:  (320, 768)\n",
            "called:  (477, 768)\n",
            "called:  (283, 768)\n",
            "called:  (850, 768)\n",
            "called:  (840, 768)\n",
            "called:  (437, 768)\n",
            "called:  (498, 768)\n",
            "called:  (377, 768)\n",
            "called:  (1270, 768)\n",
            "called:  (482, 768)\n",
            "called:  (2189, 768)\n",
            "called:  (263, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9951, recall: 0.9031, f1: 0.9469, accuracy: 0.9487, batch_loss: 0.1019, loss: 0.0837 ||:  35%|###5      | 7/20 [13:35<26:00, 120.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 01:44:15 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 01:44:15 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:44:15 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-30 01:44:15 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:44:15 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:44:15 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9951456189155579, 'recall': 0.9030836820602417, 'f1': 0.9468821883201599}\n",
            "\n",
            "2024-05-30 01:44:15 :: encode posts per user in batch ...\n",
            "2024-05-30 01:44:15 :: First two user ids in current batch: [1015044480] and [3177705637]\n",
            "called:  (1543, 768)\n",
            "called:  (458, 768)\n",
            "called:  (347, 768)\n",
            "called:  (673, 768)\n",
            "called:  (332, 768)\n",
            "called:  (254, 768)\n",
            "called:  (237, 768)\n",
            "called:  (784, 768)\n",
            "called:  (216, 768)\n",
            "called:  (444, 768)\n",
            "called:  (2062, 768)\n",
            "called:  (207, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9958, recall: 0.9082, f1: 0.9500, accuracy: 0.9512, batch_loss: 0.0498, loss: 0.0794 ||:  40%|####      | 8/20 [15:42<24:26, 122.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 01:46:22 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 01:46:22 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:46:22 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-30 01:46:22 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:46:22 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:46:22 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9958071112632751, 'recall': 0.9082217812538147, 'f1': 0.949999988079071}\n",
            "\n",
            "2024-05-30 01:46:22 :: encode posts per user in batch ...\n",
            "2024-05-30 01:46:22 :: First two user ids in current batch: [1334942948] and [1715627744]\n",
            "called:  (950, 768)\n",
            "called:  (276, 768)\n",
            "called:  (914, 768)\n",
            "called:  (936, 768)\n",
            "called:  (464, 768)\n",
            "called:  (830, 768)\n",
            "called:  (622, 768)\n",
            "called:  (804, 768)\n",
            "called:  (294, 768)\n",
            "called:  (1572, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9963, recall: 0.9082, f1: 0.9502, accuracy: 0.9514, batch_loss: 0.0965, loss: 0.0813 ||:  45%|####5     | 9/20 [17:55<23:02, 125.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 01:48:35 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 01:48:35 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:48:35 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-30 01:48:35 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:48:35 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:48:35 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.996268630027771, 'recall': 0.9081632494926453, 'f1': 0.9501779079437256}\n",
            "\n",
            "2024-05-30 01:48:35 :: encode posts per user in batch ...\n",
            "2024-05-30 01:48:35 :: First two user ids in current batch: [121635249] and [3281514829]\n",
            "called:  (441, 768)\n",
            "called:  (1025, 768)\n",
            "called:  (453, 768)\n",
            "called:  (262, 768)\n",
            "called:  (236, 768)\n",
            "called:  (335, 768)\n",
            "called:  (223, 768)\n",
            "called:  (573, 768)\n",
            "called:  (297, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9967, recall: 0.9024, f1: 0.9472, accuracy: 0.9477, batch_loss: 0.1060, loss: 0.0838 ||:  50%|#####     | 10/20 [19:15<18:35, 111.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 01:49:55 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 01:49:55 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:49:55 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-30 01:49:55 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:49:55 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:49:55 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9966832399368286, 'recall': 0.902402400970459, 'f1': 0.9472025036811829}\n",
            "\n",
            "2024-05-30 01:49:55 :: encode posts per user in batch ...\n",
            "2024-05-30 01:49:55 :: First two user ids in current batch: [259504215] and [2292997566]\n",
            "called:  (541, 768)\n",
            "called:  (284, 768)\n",
            "called:  (551, 768)\n",
            "called:  (947, 768)\n",
            "called:  (262, 768)\n",
            "called:  (1909, 768)\n",
            "called:  (338, 768)\n",
            "called:  (2668, 768)\n",
            "called:  (503, 768)\n",
            "called:  (2116, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9970, recall: 0.9063, f1: 0.9495, accuracy: 0.9503, batch_loss: 0.0410, loss: 0.0799 ||:  55%|#####5    | 11/20 [22:06<19:28, 129.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 01:52:46 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 01:52:46 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:52:46 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-30 01:52:46 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:52:46 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:52:46 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9969696998596191, 'recall': 0.9063360691070557, 'f1': 0.9494949579238892}\n",
            "\n",
            "2024-05-30 01:52:46 :: encode posts per user in batch ...\n",
            "2024-05-30 01:52:46 :: First two user ids in current batch: [356133748] and [304648182]\n",
            "called:  (2037, 768)\n",
            "called:  (1594, 768)\n",
            "called:  (220, 768)\n",
            "called:  (235, 768)\n",
            "called:  (201, 768)\n",
            "called:  (959, 768)\n",
            "called:  (1362, 768)\n",
            "called:  (520, 768)\n",
            "called:  (283, 768)\n",
            "called:  (320, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9945, recall: 0.9045, f1: 0.9474, accuracy: 0.9479, batch_loss: 0.1069, loss: 0.0822 ||:  60%|######    | 12/20 [24:22<17:32, 131.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 01:55:02 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 01:55:02 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:55:02 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-30 01:55:02 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:55:02 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:55:02 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9944751262664795, 'recall': 0.9045225977897644, 'f1': 0.9473683834075928}\n",
            "\n",
            "2024-05-30 01:55:02 :: encode posts per user in batch ...\n",
            "2024-05-30 01:55:02 :: First two user ids in current batch: [136722716] and [705213304784945152]\n",
            "called:  (511, 768)\n",
            "called:  (553, 768)\n",
            "called:  (1983, 768)\n",
            "called:  (1012, 768)\n",
            "called:  (600, 768)\n",
            "called:  (313, 768)\n",
            "called:  (464, 768)\n",
            "called:  (413, 768)\n",
            "called:  (213, 768)\n",
            "called:  (835, 768)\n",
            "called:  (942, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9937, recall: 0.9067, f1: 0.9482, accuracy: 0.9483, batch_loss: 0.0966, loss: 0.0833 ||:  65%|######5   | 13/20 [26:34<15:21, 131.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 01:57:14 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 01:57:14 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:57:14 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-30 01:57:14 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:57:14 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:57:14 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.993686854839325, 'recall': 0.906682014465332, 'f1': 0.9481927156448364}\n",
            "\n",
            "2024-05-30 01:57:14 :: encode posts per user in batch ...\n",
            "2024-05-30 01:57:14 :: First two user ids in current batch: [3681053654] and [702032066809110528]\n",
            "called:  (900, 768)\n",
            "called:  (706, 768)\n",
            "called:  (337, 768)\n",
            "called:  (290, 768)\n",
            "called:  (2042, 768)\n",
            "called:  (854, 768)\n",
            "called:  (569, 768)\n",
            "called:  (822, 768)\n",
            "called:  (413, 768)\n",
            "called:  (371, 768)\n",
            "called:  (216, 768)\n",
            "called:  (464, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9941, recall: 0.9064, f1: 0.9482, accuracy: 0.9487, batch_loss: 0.0730, loss: 0.0825 ||:  70%|#######   | 14/20 [28:52<13:21, 133.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 01:59:32 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 01:59:32 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:59:32 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-30 01:59:32 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:59:32 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-30 01:59:32 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9940968155860901, 'recall': 0.9063509106636047, 'f1': 0.9481981992721558}\n",
            "\n",
            "2024-05-30 01:59:32 :: encode posts per user in batch ...\n",
            "2024-05-30 01:59:32 :: First two user ids in current batch: [233021323] and [4847700568]\n",
            "called:  (420, 768)\n",
            "called:  (294, 768)\n",
            "called:  (1059, 768)\n",
            "called:  (388, 768)\n",
            "called:  (208, 768)\n",
            "called:  (524, 768)\n",
            "called:  (1601, 768)\n",
            "called:  (226, 768)\n",
            "called:  (937, 768)\n",
            "called:  (326, 768)\n",
            "called:  (358, 768)\n",
            "called:  (407, 768)\n",
            "called:  (685, 768)\n",
            "called:  (942, 768)\n",
            "called:  (515, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9934, recall: 0.9061, f1: 0.9477, accuracy: 0.9484, batch_loss: 0.0960, loss: 0.0834 ||:  75%|#######5  | 15/20 [31:25<11:37, 139.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 02:02:05 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 02:02:05 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-30 02:02:05 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-30 02:02:05 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-30 02:02:05 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-30 02:02:05 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9933554530143738, 'recall': 0.9060605764389038, 'f1': 0.9477020502090454}\n",
            "\n",
            "2024-05-30 02:02:05 :: encode posts per user in batch ...\n",
            "2024-05-30 02:02:05 :: First two user ids in current batch: [3115328297] and [1286880470]\n",
            "called:  (249, 768)\n",
            "called:  (288, 768)\n",
            "called:  (389, 768)\n",
            "called:  (1284, 768)\n",
            "called:  (539, 768)\n",
            "called:  (1772, 768)\n",
            "called:  (1638, 768)\n",
            "called:  (231, 768)\n",
            "called:  (651, 768)\n",
            "called:  (632, 768)\n",
            "called:  (2298, 768)\n",
            "called:  (831, 768)\n",
            "called:  (390, 768)\n",
            "called:  (644, 768)\n",
            "called:  (517, 768)\n",
            "called:  (231, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9938, recall: 0.9056, f1: 0.9476, accuracy: 0.9482, batch_loss: 0.1009, loss: 0.0845 ||:  80%|########  | 16/20 [34:52<10:38, 159.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 02:05:31 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 02:05:31 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-30 02:05:31 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-30 02:05:31 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-30 02:05:31 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-30 02:05:31 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9937824010848999, 'recall': 0.9055712819099426, 'f1': 0.9476284384727478}\n",
            "\n",
            "2024-05-30 02:05:31 :: encode posts per user in batch ...\n",
            "2024-05-30 02:05:31 :: First two user ids in current batch: [3401400052] and [2864314343]\n",
            "called:  (304, 768)\n",
            "called:  (439, 768)\n",
            "called:  (257, 768)\n",
            "called:  (222, 768)\n",
            "called:  (556, 768)\n",
            "called:  (383, 768)\n",
            "called:  (634, 768)\n",
            "called:  (326, 768)\n",
            "called:  (360, 768)\n",
            "called:  (1065, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9941, recall: 0.9020, f1: 0.9458, accuracy: 0.9467, batch_loss: 0.0858, loss: 0.0846 ||:  85%|########5 | 17/20 [36:24<06:58, 139.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 02:07:04 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 02:07:04 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-30 02:07:04 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-30 02:07:04 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-30 02:07:04 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-30 02:07:04 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.994106113910675, 'recall': 0.9019607901573181, 'f1': 0.945794403553009}\n",
            "\n",
            "2024-05-30 02:07:04 :: encode posts per user in batch ...\n",
            "2024-05-30 02:07:04 :: First two user ids in current batch: [1909531093] and [2738372117]\n",
            "called:  (222, 768)\n",
            "called:  (241, 768)\n",
            "called:  (458, 768)\n",
            "called:  (616, 768)\n",
            "called:  (812, 768)\n",
            "called:  (1103, 768)\n",
            "called:  (627, 768)\n",
            "called:  (610, 768)\n",
            "called:  (397, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9944, recall: 0.9016, f1: 0.9457, accuracy: 0.9466, batch_loss: 0.0785, loss: 0.0843 ||:  90%|######### | 18/20 [38:02<04:13, 126.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 02:08:42 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 02:08:42 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-30 02:08:42 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-30 02:08:42 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-30 02:08:42 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-30 02:08:42 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.994434118270874, 'recall': 0.9015979766845703, 'f1': 0.9457432627677917}\n",
            "\n",
            "2024-05-30 02:08:42 :: encode posts per user in batch ...\n",
            "2024-05-30 02:08:42 :: First two user ids in current batch: [822599120] and [451720580]\n",
            "called:  (282, 768)\n",
            "called:  (483, 768)\n",
            "called:  (207, 768)\n",
            "called:  (1230, 768)\n",
            "called:  (267, 768)\n",
            "called:  (323, 768)\n",
            "called:  (389, 768)\n",
            "called:  (598, 768)\n",
            "called:  (325, 768)\n",
            "called:  (410, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9947, recall: 0.8993, f1: 0.9446, accuracy: 0.9457, batch_loss: 0.1735, loss: 0.0890 ||:  95%|#########5| 19/20 [39:31<01:55, 115.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 02:10:11 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 02:10:11 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-30 02:10:11 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-30 02:10:11 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-30 02:10:11 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-30 02:10:11 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9946949481964111, 'recall': 0.8992805480957031, 'f1': 0.944584310054779}\n",
            "\n",
            "2024-05-30 02:10:11 :: encode posts per user in batch ...\n",
            "2024-05-30 02:10:11 :: First two user ids in current batch: [740062711] and [2261842362]\n",
            "called:  (259, 768)\n",
            "called:  (426, 768)\n",
            "called:  (618, 768)\n",
            "called:  (555, 768)\n",
            "called:  (465, 768)\n",
            "called:  (800, 768)\n",
            "called:  (383, 768)\n",
            "called:  (451, 768)\n",
            "called:  (1567, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "precision: 0.9949, recall: 0.8996, f1: 0.9449, accuracy: 0.9461, batch_loss: 0.0698, loss: 0.0880 ||: 100%|##########| 20/20 [41:11<00:00, 123.58s/it]\n",
            "  0%|          | 0/7 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 02:11:51 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 02:11:51 :: tensor size after padding: torch.Size([92, 200, 768])\n",
            "2024-05-30 02:11:51 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([92, 200, 768])]\n",
            "2024-05-30 02:11:51 :: post masking: content [torch.Size([92, 200])]\n",
            "new tenor size: torch.Size([92, 200, 768])\n",
            "2024-05-30 02:11:51 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([92, 200, 768])\n",
            "2024-05-30 02:11:51 :: post reprsentation shape : torch.Size([92, 768])\n",
            "{'precision': 0.9948761463165283, 'recall': 0.8996139168739319, 'f1': 0.9448500275611877}\n",
            "\n",
            "{'precision': 0.9948761463165283, 'recall': 0.8996139168739319, 'f1': 0.9448500275611877}\n",
            "\n",
            "2024-05-30 02:11:51 :: encode posts per user in batch ...\n",
            "2024-05-30 02:11:51 :: First two user ids in current batch: [215419157] and [102584428]\n",
            "called:  (309, 768)\n",
            "called:  (242, 768)\n",
            "called:  (507, 768)\n",
            "called:  (292, 768)\n",
            "called:  (1604, 768)\n",
            "called:  (207, 768)\n",
            "called:  (207, 768)\n",
            "called:  (1078, 768)\n",
            "called:  (222, 768)\n",
            "called:  (285, 768)\n",
            "called:  (608, 768)\n",
            "called:  (401, 768)\n",
            "called:  (1008, 768)\n",
            "called:  (265, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 1.0000, recall: 0.9841, f1: 0.9920, accuracy: 0.9922, batch_loss: 0.0346, loss: 0.0346 ||:  14%|#4        | 1/7 [02:00<12:01, 120.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 02:13:51 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 02:13:51 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-30 02:13:51 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-30 02:13:51 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-30 02:13:51 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-30 02:13:51 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 1.0, 'recall': 0.9841269850730896, 'f1': 0.9919999837875366}\n",
            "\n",
            "2024-05-30 02:13:51 :: encode posts per user in batch ...\n",
            "2024-05-30 02:13:51 :: First two user ids in current batch: [1605453978] and [3373077143]\n",
            "called:  (1311, 768)\n",
            "called:  (289, 768)\n",
            "called:  (236, 768)\n",
            "called:  (212, 768)\n",
            "called:  (371, 768)\n",
            "called:  (216, 768)\n",
            "called:  (201, 768)\n",
            "called:  (348, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 1.0000, recall: 0.9835, f1: 0.9917, accuracy: 0.9922, batch_loss: 0.0300, loss: 0.0323 ||:  29%|##8       | 2/7 [03:05<07:20, 88.03s/it] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 02:14:57 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 02:14:57 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-30 02:14:57 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-30 02:14:57 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-30 02:14:57 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-30 02:14:57 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 1.0, 'recall': 0.9834710955619812, 'f1': 0.9916666746139526}\n",
            "\n",
            "2024-05-30 02:14:57 :: encode posts per user in batch ...\n",
            "2024-05-30 02:14:57 :: First two user ids in current batch: [812988260771205121] and [711945679]\n",
            "called:  (2606, 768)\n",
            "called:  (989, 768)\n",
            "called:  (1194, 768)\n",
            "called:  (1122, 768)\n",
            "called:  (522, 768)\n",
            "called:  (232, 768)\n",
            "called:  (2229, 768)\n",
            "called:  (1923, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 1.0000, recall: 0.9892, f1: 0.9946, accuracy: 0.9948, batch_loss: 0.0066, loss: 0.0237 ||:  43%|####2     | 3/7 [05:48<08:08, 122.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 02:17:39 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 02:17:39 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-30 02:17:39 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-30 02:17:39 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-30 02:17:39 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-30 02:17:39 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 1.0, 'recall': 0.9891892075538635, 'f1': 0.9945652484893799}\n",
            "\n",
            "2024-05-30 02:17:39 :: encode posts per user in batch ...\n",
            "2024-05-30 02:17:39 :: First two user ids in current batch: [614357920] and [202496777]\n",
            "called:  (324, 768)\n",
            "called:  (666, 768)\n",
            "called:  (352, 768)\n",
            "called:  (226, 768)\n",
            "called:  (751, 768)\n",
            "called:  (303, 768)\n",
            "called:  (246, 768)\n",
            "called:  (232, 768)\n",
            "called:  (241, 768)\n",
            "called:  (297, 768)\n",
            "called:  (351, 768)\n",
            "called:  (772, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 1.0000, recall: 0.9880, f1: 0.9939, accuracy: 0.9941, batch_loss: 0.0250, loss: 0.0241 ||:  57%|#####7    | 4/7 [07:20<05:30, 110.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 02:19:12 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 02:19:12 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-30 02:19:12 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-30 02:19:12 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-30 02:19:12 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-30 02:19:12 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 1.0, 'recall': 0.9879518151283264, 'f1': 0.9939393997192383}\n",
            "\n",
            "2024-05-30 02:19:12 :: encode posts per user in batch ...\n",
            "2024-05-30 02:19:12 :: First two user ids in current batch: [398986909] and [19627181]\n",
            "called:  (214, 768)\n",
            "called:  (269, 768)\n",
            "called:  (985, 768)\n",
            "called:  (421, 768)\n",
            "called:  (226, 768)\n",
            "called:  (249, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 1.0000, recall: 0.9876, f1: 0.9938, accuracy: 0.9938, batch_loss: 0.0412, loss: 0.0275 ||:  71%|#######1  | 5/7 [08:07<02:54, 87.45s/it] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 02:19:58 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 02:19:58 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-30 02:19:58 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-30 02:19:58 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-30 02:19:58 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-30 02:19:58 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 1.0, 'recall': 0.9876161217689514, 'f1': 0.9937695264816284}\n",
            "\n",
            "2024-05-30 02:19:59 :: encode posts per user in batch ...\n",
            "2024-05-30 02:19:59 :: First two user ids in current batch: [1482105181] and [2411177527]\n",
            "called:  (1276, 768)\n",
            "called:  (440, 768)\n",
            "called:  (366, 768)\n",
            "called:  (218, 768)\n",
            "called:  (874, 768)\n",
            "called:  (336, 768)\n",
            "called:  (283, 768)\n",
            "called:  (523, 768)\n",
            "called:  (329, 768)\n",
            "called:  (932, 768)\n",
            "called:  (219, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9949, recall: 0.9898, f1: 0.9923, accuracy: 0.9922, batch_loss: 0.0559, loss: 0.0322 ||:  86%|########5 | 6/7 [09:51<01:32, 92.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 02:21:42 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 02:21:42 :: tensor size after padding: torch.Size([128, 200, 768])\n",
            "2024-05-30 02:21:42 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([128, 200, 768])]\n",
            "2024-05-30 02:21:42 :: post masking: content [torch.Size([128, 200])]\n",
            "new tenor size: torch.Size([128, 200, 768])\n",
            "2024-05-30 02:21:42 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([128, 200, 768])\n",
            "2024-05-30 02:21:42 :: post reprsentation shape : torch.Size([128, 768])\n",
            "{'precision': 0.9948849081993103, 'recall': 0.9898219108581543, 'f1': 0.9923468828201294}\n",
            "\n",
            "2024-05-30 02:21:42 :: encode posts per user in batch ...\n",
            "2024-05-30 02:21:42 :: First two user ids in current batch: [254614253] and [766518900188078081]\n",
            "called:  (310, 768)\n",
            "called:  (215, 768)\n",
            "called:  (251, 768)\n",
            "called:  (1477, 768)\n",
            "called:  (318, 768)\n",
            "called:  (431, 768)\n",
            "called:  (449, 768)\n",
            "called:  (223, 768)\n",
            "called:  (947, 768)\n",
            "called:  (302, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "precision: 0.9953, recall: 0.9907, f1: 0.9930, accuracy: 0.9929, batch_loss: 0.0031, loss: 0.0281 ||: 100%|##########| 7/7 [11:10<00:00, 95.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 02:23:02 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 02:23:02 :: tensor size after padding: torch.Size([74, 200, 768])\n",
            "2024-05-30 02:23:02 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([74, 200, 768])]\n",
            "2024-05-30 02:23:02 :: post masking: content [torch.Size([74, 200])]\n",
            "new tenor size: torch.Size([74, 200, 768])\n",
            "2024-05-30 02:23:02 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([74, 200, 768])\n",
            "2024-05-30 02:23:02 :: post reprsentation shape : torch.Size([74, 768])\n",
            "{'precision': 0.9953488111495972, 'recall': 0.9907407164573669, 'f1': 0.9930394887924194}\n",
            "\n",
            "{'precision': 0.9953488111495972, 'recall': 0.9907407164573669, 'f1': 0.9930394887924194}\n",
            "\n",
            "Metrics at the end of epoch: 9 {'best_epoch': 7, 'peak_worker_0_memory_MB': 2074.94921875, 'peak_gpu_0_memory_MB': 1573.1474609375, 'training_duration': '8:41:04.602847', 'epoch': 9, 'training_precision': 0.9948761463165283, 'training_recall': 0.8996139168739319, 'training_f1': 0.9448500275611877, 'training_accuracy': 0.9461172741679873, 'training_loss': 0.08800178002566099, 'training_worker_0_memory_MB': 2074.94921875, 'training_gpu_0_memory_MB': 1573.1474609375, 'validation_precision': 0.9953488111495972, 'validation_recall': 0.9907407164573669, 'validation_f1': 0.9930394887924194, 'validation_accuracy': 0.9928741092636579, 'validation_loss': 0.028062050829508474, 'best_validation_precision': 0.9953380227088928, 'best_validation_recall': 0.9884259104728699, 'best_validation_f1': 0.9918699264526367, 'best_validation_accuracy': 0.9916864608076009, 'best_validation_loss': 0.02436796698852309}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 02:23:02 :: done.\n",
            "Training Losses: [0.519289817661047, 0.16092434488236904, 0.12038053460419178, 0.10551146045327187, 0.11054278463125229, 0.09588195458054542, 0.07651024255901576, 0.08249233327805996, 0.08167169727385044, 0.08800178002566099]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 02:23:03 :: archive model and vocabulary ... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "building vocab: 100%|##########| 842/842 [00:00<00:00, 704629.68it/s]\n",
            "loading instances: 842it [00:00, 78839.24it/s]\n",
            "0it [00:00, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 02:23:04 :: done. model file and vocab file are archived in [/content/../../output/training_test202405300223]\n",
            "2024-05-30 02:23:04 :: evaluating  .... \n",
            "2024-05-30 02:23:04 :: DepressionDataReader ...\n",
            "test.csv\n",
            "test.csv\n",
            "PRINTING BATCH.....\n",
            "{'user_id': ['135489644', '832275878', '711992177765834753', '2572245337', '335071157', '2210406066', '3248467598', '2567339966', '1723052366', '606639254', '2585636739', '2205649782', '1045293601', '3010723291', '121468956', '44593603', '2689547981', '216229469', '180600314', '339946116', '940627640', '900193381', '351134683', '321199767', '2990909615', '20806196', '22757462', '2311350786', '559661220', '1784534575', '759999604276334592', '20728954'], 'label': tensor([0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1,\n",
            "        0, 1, 1, 1, 0, 1, 0, 1])}\n",
            "2024-05-30 02:23:04 :: encode posts per user in batch ...\n",
            "2024-05-30 02:23:04 :: First two user ids in current batch: [135489644] and [832275878]\n",
            "called:  (1047, 768)\n",
            "called:  (411, 768)\n",
            "called:  (617, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 1.0000, recall: 1.0000, f1: 1.0000, accuracy: 1.0000, loss: 0.0035 ||: : 1it [00:32, 32.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 02:23:37 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 02:23:37 :: tensor size after padding: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:23:37 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([32, 200, 768])]\n",
            "2024-05-30 02:23:37 :: post masking: content [torch.Size([32, 200])]\n",
            "new tenor size: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:23:37 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:23:37 :: post reprsentation shape : torch.Size([32, 768])\n",
            "{'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
            "\n",
            "PRINTING BATCH.....\n",
            "{'user_id': ['3214169961', '74091079', '38565215', '509222972', '1543464326', '3091556565', '880851151', '425162617', '2196264227', '123413321', '391757760', '4846541546', '2393649578', '700708515162169344', '2505372074', '1513669094', '738032858992803840', '946573555', '1666494990', '58298436', '325137737', '300963163', '454231140', '113740246', '39204895', '176712354', '4869597951', '2309031460', '2620645073', '14218429', '1220277662', '4726763873'], 'label': tensor([1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
            "        1, 1, 0, 1, 1, 0, 1, 0])}\n",
            "2024-05-30 02:23:37 :: encode posts per user in batch ...\n",
            "2024-05-30 02:23:37 :: First two user ids in current batch: [3214169961] and [74091079]\n",
            "called:  (387, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 1.0000, recall: 1.0000, f1: 1.0000, accuracy: 1.0000, loss: 0.0018 ||: : 2it [00:39, 17.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 02:23:44 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 02:23:44 :: tensor size after padding: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:23:44 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([32, 200, 768])]\n",
            "2024-05-30 02:23:44 :: post masking: content [torch.Size([32, 200])]\n",
            "new tenor size: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:23:44 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:23:44 :: post reprsentation shape : torch.Size([32, 768])\n",
            "{'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
            "\n",
            "PRINTING BATCH.....\n",
            "{'user_id': ['1326107413', '2285806435', '799253635175587840', '2238830439', '702875058', '759748213595312128', '772747309', '3131227588', '1100893603', '1259665160', '2372142631', '3112326141', '412702391', '201760496', '144360450', '160827816', '1519595377', '30403097', '21616979', '3382699715', '58297636', '2907121522', '333951048', '474163451', '1488530904', '26114386', '550496468', '155982293', '736745796750577664', '24045908', '791522959810781184', '1111682804'], 'label': tensor([1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0,\n",
            "        1, 1, 1, 1, 0, 1, 0, 1])}\n",
            "2024-05-30 02:23:44 :: encode posts per user in batch ...\n",
            "2024-05-30 02:23:44 :: First two user ids in current batch: [1326107413] and [2285806435]\n",
            "called:  (625, 768)\n",
            "called:  (657, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 1.0000, recall: 1.0000, f1: 1.0000, accuracy: 1.0000, loss: 0.0038 ||: : 3it [01:01, 19.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 02:24:06 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 02:24:06 :: tensor size after padding: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:24:06 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([32, 200, 768])]\n",
            "2024-05-30 02:24:06 :: post masking: content [torch.Size([32, 200])]\n",
            "new tenor size: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:24:06 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:24:06 :: post reprsentation shape : torch.Size([32, 768])\n",
            "{'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
            "\n",
            "PRINTING BATCH.....\n",
            "{'user_id': ['3224961990', '28337813', '791625572950511616', '2261110143', '134041540', '2764091643', '548265223', '184142474', '103956963', '3298537542', '886882400', '74177248', '3016719256', '715211815', '2610683418', '1235555588', '23033786', '856798200', '2743891948', '2792502776', '563910015', '807624209652273152', '1564176703', '716106795974922241', '763387438525997056', '17588515', '731636346', '21361078', '20012387', '392383901', '2966661748', '1614094921'], 'label': tensor([1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0,\n",
            "        0, 1, 1, 1, 1, 0, 0, 1])}\n",
            "2024-05-30 02:24:06 :: encode posts per user in batch ...\n",
            "2024-05-30 02:24:06 :: First two user ids in current batch: [3224961990] and [28337813]\n",
            "called:  (1060, 768)\n",
            "called:  (378, 768)\n",
            "called:  (447, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 1.0000, recall: 1.0000, f1: 1.0000, accuracy: 1.0000, loss: 0.0031 ||: : 4it [01:32, 23.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 02:24:36 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 02:24:36 :: tensor size after padding: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:24:36 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([32, 200, 768])]\n",
            "2024-05-30 02:24:36 :: post masking: content [torch.Size([32, 200])]\n",
            "new tenor size: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:24:36 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:24:36 :: post reprsentation shape : torch.Size([32, 768])\n",
            "{'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
            "\n",
            "PRINTING BATCH.....\n",
            "{'user_id': ['1506187387', '100329578', '29478233', '14465878', '108758183', '2594417592', '408494777', '3006885983', '737227964', '55635974', '1544507695', '2283021097', '2626655253', '753990962402111488', '2547919868', '47544907', '2681415696', '2605265379', '801552757', '20190678', '1191647448', '239650951', '63905946', '748961334755258368', '22154248', '583404801', '800139766268194816', '1075948759', '2353651812', '2402793963', '245819759', '3343088487'], 'label': tensor([1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n",
            "        1, 0, 0, 1, 1, 1, 1, 1])}\n",
            "2024-05-30 02:24:36 :: encode posts per user in batch ...\n",
            "2024-05-30 02:24:36 :: First two user ids in current batch: [1506187387] and [100329578]\n",
            "called:  (1165, 768)\n",
            "called:  (209, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 1.0000, recall: 1.0000, f1: 1.0000, accuracy: 1.0000, loss: 0.0031 ||: : 5it [01:56, 24.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 02:25:01 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 02:25:01 :: tensor size after padding: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:25:01 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([32, 200, 768])]\n",
            "2024-05-30 02:25:01 :: post masking: content [torch.Size([32, 200])]\n",
            "new tenor size: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:25:01 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:25:01 :: post reprsentation shape : torch.Size([32, 768])\n",
            "{'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
            "\n",
            "PRINTING BATCH.....\n",
            "{'user_id': ['2985170567', '754087075339579392', '549020625', '273502057', '337458108', '71223348', '809492450775601152', '477972863', '1200392156', '354647964', '203214161', '805847091633262592', '200504800', '220344199', '601864211', '390432065', '818815998258089985', '294437559', '142208324', '2955482271', '552418698', '241425263', '2700487889', '272001325', '156772237', '801826419584225280', '41550430', '485732083', '739915733707034624', '796258199623995392', '356760177', '804879116390531072'], 'label': tensor([1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1,\n",
            "        0, 0, 1, 0, 0, 0, 0, 0])}\n",
            "2024-05-30 02:25:01 :: encode posts per user in batch ...\n",
            "2024-05-30 02:25:01 :: First two user ids in current batch: [2985170567] and [754087075339579392]\n",
            "called:  (223, 768)\n",
            "called:  (400, 768)\n",
            "called:  (477, 768)\n",
            "called:  (455, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 1.0000, recall: 0.9904, f1: 0.9952, accuracy: 0.9948, loss: 0.0492 ||: : 6it [02:23, 25.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 02:25:28 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 02:25:28 :: tensor size after padding: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:25:28 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([32, 200, 768])]\n",
            "2024-05-30 02:25:28 :: post masking: content [torch.Size([32, 200])]\n",
            "new tenor size: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:25:28 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:25:28 :: post reprsentation shape : torch.Size([32, 768])\n",
            "{'precision': 1.0, 'recall': 0.9903846383094788, 'f1': 0.9951691031455994}\n",
            "\n",
            "[8]\n",
            "Misclassified: ['1200392156']\n",
            "PRINTING BATCH.....\n",
            "{'user_id': ['918742332', '17991647', '4781302514', '24426056', '265080468', '1143551', '1071543110', '4092129317', '158212147', '423551349', '2592315696', '39191362', '719105116712742912', '151825149', '3433228701', '719842819834277888', '1924430738', '15928975', '309800571', '109036793', '1635007963', '602226329', '3232405261', '43854061', '1038095460', '404237953', '972054860', '818330161133142016', '2330482621', '23172786', '2520471177', '1884559891'], 'label': tensor([1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1,\n",
            "        0, 0, 1, 0, 1, 0, 1, 1])}\n",
            "2024-05-30 02:25:28 :: encode posts per user in batch ...\n",
            "2024-05-30 02:25:28 :: First two user ids in current batch: [918742332] and [17991647]\n",
            "called:  (574, 768)\n",
            "called:  (796, 768)\n",
            "called:  (332, 768)\n",
            "called:  (1123, 768)\n",
            "called:  (250, 768)\n",
            "called:  (287, 768)\n",
            "called:  (550, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 1.0000, recall: 0.9916, f1: 0.9958, accuracy: 0.9955, loss: 0.0426 ||: : 7it [03:24, 36.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 02:26:28 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 02:26:28 :: tensor size after padding: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:26:28 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([32, 200, 768])]\n",
            "2024-05-30 02:26:28 :: post masking: content [torch.Size([32, 200])]\n",
            "new tenor size: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:26:28 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:26:28 :: post reprsentation shape : torch.Size([32, 768])\n",
            "{'precision': 1.0, 'recall': 0.9915966391563416, 'f1': 0.9957805871963501}\n",
            "\n",
            "PRINTING BATCH.....\n",
            "{'user_id': ['241947826', '446585979', '1613397283', '742247601127358464', '878978684', '2811509374', '2646522164', '1949904595', '31082995', '16738904', '2425085448', '221982028', '2852091260', '40151293', '420614611', '20388645', '2657688577', '218438613', '126850554', '3751886105', '28122482', '781990124183838720', '407420253', '4645978055', '709729372207316992', '279322567', '757111959372214274', '176218085', '214435856', '3219872251', '2518046547', '354082151'], 'label': tensor([0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0,\n",
            "        0, 1, 0, 0, 1, 0, 1, 0])}\n",
            "2024-05-30 02:26:28 :: encode posts per user in batch ...\n",
            "2024-05-30 02:26:28 :: First two user ids in current batch: [241947826] and [446585979]\n",
            "called:  (411, 768)\n",
            "called:  (234, 768)\n",
            "called:  (662, 768)\n",
            "called:  (313, 768)\n",
            "called:  (234, 768)\n",
            "called:  (258, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 1.0000, recall: 0.9928, f1: 0.9964, accuracy: 0.9961, loss: 0.0374 ||: : 8it [04:06, 38.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 02:27:10 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 02:27:10 :: tensor size after padding: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:27:10 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([32, 200, 768])]\n",
            "2024-05-30 02:27:10 :: post masking: content [torch.Size([32, 200])]\n",
            "new tenor size: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:27:10 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:27:10 :: post reprsentation shape : torch.Size([32, 768])\n",
            "{'precision': 1.0, 'recall': 0.9927536249160767, 'f1': 0.996363639831543}\n",
            "\n",
            "PRINTING BATCH.....\n",
            "{'user_id': ['1252920726', '2348249317', '1679227562', '2951343582', '383204251', '2731960979', '41958469', '363353483', '2874576417', '858586387', '28889521', '364095622', '343506495', '3213526828', '852948648', '1377825259', '1029310188', '416708443', '1673872422', '357284935', '2440719877', '1015648590', '350865849', '277430409', '4297408152', '614832612', '1285711058', '214298797', '1907826211', '2565591398', '3473629813', '421964806'], 'label': tensor([0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
            "        0, 0, 0, 1, 0, 0, 1, 1])}\n",
            "2024-05-30 02:27:10 :: encode posts per user in batch ...\n",
            "2024-05-30 02:27:10 :: First two user ids in current batch: [1252920726] and [2348249317]\n",
            "called:  (217, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 1.0000, recall: 0.9934, f1: 0.9967, accuracy: 0.9965, loss: 0.0332 ||: : 9it [04:11, 27.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 02:27:15 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 02:27:15 :: tensor size after padding: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:27:15 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([32, 200, 768])]\n",
            "2024-05-30 02:27:15 :: post masking: content [torch.Size([32, 200])]\n",
            "new tenor size: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:27:15 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:27:15 :: post reprsentation shape : torch.Size([32, 768])\n",
            "{'precision': 1.0, 'recall': 0.9933775067329407, 'f1': 0.9966777563095093}\n",
            "\n",
            "PRINTING BATCH.....\n",
            "{'user_id': ['3550732332', '436195626', '219381081', '706848471', '896245921', '120163618', '3163071174', '15836690', '2203700234', '2515730320', '826373646', '2618981980', '724648306379395073', '1464852277', '338481255', '357679590', '2470707042', '2592655262', '230067281', '625314459', '271163315', '2419414645', '1965159528', '107186693', '3513423265', '1321006592', '84846583', '85766241', '2859205926', '2275343617', '1642388713', '173497217'], 'label': tensor([0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1,\n",
            "        1, 1, 1, 1, 1, 0, 0, 1])}\n",
            "2024-05-30 02:27:15 :: encode posts per user in batch ...\n",
            "2024-05-30 02:27:15 :: First two user ids in current batch: [3550732332] and [436195626]\n",
            "called:  (745, 768)\n",
            "called:  (465, 768)\n",
            "called:  (1256, 768)\n",
            "called:  (855, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 1.0000, recall: 0.9942, f1: 0.9971, accuracy: 0.9969, loss: 0.0303 ||: : 10it [05:01, 34.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 02:28:05 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 02:28:05 :: tensor size after padding: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:28:05 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([32, 200, 768])]\n",
            "2024-05-30 02:28:05 :: post masking: content [torch.Size([32, 200])]\n",
            "new tenor size: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:28:05 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:28:05 :: post reprsentation shape : torch.Size([32, 768])\n",
            "{'precision': 1.0, 'recall': 0.9941860437393188, 'f1': 0.9970845580101013}\n",
            "\n",
            "PRINTING BATCH.....\n",
            "{'user_id': ['818600778', '2909430422', '983758176', '2206843508', '46808996', '95915769', '28359865', '245857111', '585981766', '1497398432', '272662679', '2588023398', '1616404141', '774379867', '204953789', '2559333325', '1964212802', '762522504', '236851154', '1025920645', '4490534239', '533389464', '3437449245', '2432464050', '1258401020', '2680974648', '67822852', '3297186746', '238039116', '712867990304387073', '225951967', '3665838258'], 'label': tensor([1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
            "        1, 0, 0, 0, 0, 0, 0, 0])}\n",
            "2024-05-30 02:28:05 :: encode posts per user in batch ...\n",
            "2024-05-30 02:28:05 :: First two user ids in current batch: [818600778] and [2909430422]\n",
            "called:  (287, 768)\n",
            "called:  (405, 768)\n",
            "called:  (223, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 1.0000, recall: 0.9892, f1: 0.9946, accuracy: 0.9943, loss: 0.0317 ||: : 11it [05:20, 30.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 02:28:25 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 02:28:25 :: tensor size after padding: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:28:25 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([32, 200, 768])]\n",
            "2024-05-30 02:28:25 :: post masking: content [torch.Size([32, 200])]\n",
            "new tenor size: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:28:25 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:28:25 :: post reprsentation shape : torch.Size([32, 768])\n",
            "{'precision': 1.0, 'recall': 0.9891892075538635, 'f1': 0.9945652484893799}\n",
            "\n",
            "[24]\n",
            "Misclassified: ['1258401020']\n",
            "PRINTING BATCH.....\n",
            "{'user_id': ['1698105630', '2424102426', '1474321034', '960564350', '350943800', '430735682', '175193266', '3388919592', '2173256966', '1561584698', '67065873', '236888232', '3177758516', '2418483577', '105264115', '2231448409', '4902494247', '1601814768', '1257535368', '335584858', '851515356', '3087689846', '388043362', '3273077468', '818547213248958466', '3883737315', '523934232', '3024435496', '176994984', '309811175', '22633030', '1353344935'], 'label': tensor([1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1,\n",
            "        0, 1, 0, 1, 0, 0, 1, 0])}\n",
            "2024-05-30 02:28:25 :: encode posts per user in batch ...\n",
            "2024-05-30 02:28:25 :: First two user ids in current batch: [1698105630] and [2424102426]\n",
            "called:  (401, 768)\n",
            "called:  (1209, 768)\n",
            "called:  (406, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 1.0000, recall: 0.9853, f1: 0.9926, accuracy: 0.9922, loss: 0.0526 ||: : 12it [05:53, 30.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 02:28:57 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 02:28:57 :: tensor size after padding: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:28:57 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([32, 200, 768])]\n",
            "2024-05-30 02:28:57 :: post masking: content [torch.Size([32, 200])]\n",
            "new tenor size: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:28:57 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:28:57 :: post reprsentation shape : torch.Size([32, 768])\n",
            "{'precision': 1.0, 'recall': 0.9852941036224365, 'f1': 0.9925925731658936}\n",
            "\n",
            "[18]\n",
            "Misclassified: ['1257535368']\n",
            "PRINTING BATCH.....\n",
            "{'user_id': ['3068076770', '2989066724', '559279863', '2464078411', '15206901', '336235355', '2477669659', '1424057688', '1978342920', '1296744302', '111106012', '620463363', '41791241', '627569577', '384628919', '409682525', '19255830', '2780481957', '329116859', '878779472', '127030509', '554309415', '219350642', '3031678371', '2994745433', '4033684694', '726292296866484225', '1221577147', '2397303030', '8394312', '714738324', '455204994'], 'label': tensor([1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n",
            "        1, 0, 0, 1, 0, 1, 0, 1])}\n",
            "2024-05-30 02:28:57 :: encode posts per user in batch ...\n",
            "2024-05-30 02:28:57 :: First two user ids in current batch: [3068076770] and [2989066724]\n",
            "called:  (379, 768)\n",
            "called:  (287, 768)\n",
            "called:  (380, 768)\n",
            "called:  (343, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 1.0000, recall: 0.9865, f1: 0.9932, accuracy: 0.9928, loss: 0.0489 ||: : 13it [06:20, 29.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 02:29:25 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 02:29:25 :: tensor size after padding: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:29:25 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([32, 200, 768])]\n",
            "2024-05-30 02:29:25 :: post masking: content [torch.Size([32, 200])]\n",
            "new tenor size: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:29:25 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:29:25 :: post reprsentation shape : torch.Size([32, 768])\n",
            "{'precision': 1.0, 'recall': 0.9864864945411682, 'f1': 0.9931973218917847}\n",
            "\n",
            "PRINTING BATCH.....\n",
            "{'user_id': ['2570353677', '430212021', '494427807', '2205600084', '806575166759305220', '286338907', '3187047836', '858118561', '894592406', '763287796975013888', '330190537', '292498017', '113462625', '2903946398', '165563781', '289485444', '346877404', '37228047', '1348619448', '2468007066', '3307076397', '1264929151', '2683897469', '583296364', '715114883847688192', '466891832', '323600805', '71830029', '745068600155766785', '795849339314860032', '2250468772', '566870792'], 'label': tensor([0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0,\n",
            "        0, 1, 1, 0, 0, 0, 0, 1])}\n",
            "2024-05-30 02:29:25 :: encode posts per user in batch ...\n",
            "2024-05-30 02:29:25 :: First two user ids in current batch: [2570353677] and [430212021]\n",
            "called:  (449, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9957, recall: 0.9832, f1: 0.9894, accuracy: 0.9888, loss: 0.0515 ||: : 14it [06:30, 23.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 02:29:34 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 02:29:35 :: tensor size after padding: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:29:35 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([32, 200, 768])]\n",
            "2024-05-30 02:29:35 :: post masking: content [torch.Size([32, 200])]\n",
            "new tenor size: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:29:35 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:29:35 :: post reprsentation shape : torch.Size([32, 768])\n",
            "{'precision': 0.9957447052001953, 'recall': 0.9831932783126831, 'f1': 0.9894291758537292}\n",
            "\n",
            "[16 31]\n",
            "Misclassified: ['346877404', '566870792']\n",
            "PRINTING BATCH.....\n",
            "{'user_id': ['522704485', '1924231016', '2880009689', '262444535', '35835330', '361696440', '100379503', '56517553', '90160322', '1410936632', '2204584801', '32335150', '73939844', '1152256718', '2949780208', '52587154', '2701640070', '258706088', '434369401', '795562855659696128', '724451072', '27266714', '1431084794', '2776097096', '797495232816353280', '2943367130', '710221160223367168', '608748587', '982445436', '74949284', '4825420934', '171368979'], 'label': tensor([0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0,\n",
            "        0, 1, 0, 1, 1, 1, 0, 0])}\n",
            "2024-05-30 02:29:35 :: encode posts per user in batch ...\n",
            "2024-05-30 02:29:35 :: First two user ids in current batch: [522704485] and [1924231016]\n",
            "called:  (1931, 768)\n",
            "called:  (686, 768)\n",
            "called:  (247, 768)\n",
            "called:  (441, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9960, recall: 0.9841, f1: 0.9900, accuracy: 0.9896, loss: 0.0482 ||: : 15it [07:21, 31.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 02:30:25 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 02:30:25 :: tensor size after padding: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:30:25 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([32, 200, 768])]\n",
            "2024-05-30 02:30:25 :: post masking: content [torch.Size([32, 200])]\n",
            "new tenor size: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:30:25 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:30:25 :: post reprsentation shape : torch.Size([32, 768])\n",
            "{'precision': 0.9959839582443237, 'recall': 0.9841269850730896, 'f1': 0.9900199770927429}\n",
            "\n",
            "PRINTING BATCH.....\n",
            "{'user_id': ['330694961', '72397721', '2911253850', '766492164', '813509383443324928', '562022092', '773881837567574016', '724683291710750720', '17778215', '1554750566', '235062074', '25210608', '53480059', '734490870557335553', '2953108204', '3266197364', '2828686140', '2299077498', '1263042128', '42170767', '768541206', '2891577529', '174930501', '116879261', '1308063908', '20783929', '3131630224', '777444610809270272', '16824090', '130615364', '1090703214', '16889988'], 'label': tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0,\n",
            "        1, 1, 1, 0, 1, 1, 1, 1])}\n",
            "2024-05-30 02:30:25 :: encode posts per user in batch ...\n",
            "2024-05-30 02:30:25 :: First two user ids in current batch: [330694961] and [72397721]\n",
            "called:  (316, 768)\n",
            "called:  (231, 768)\n",
            "called:  (232, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9925, recall: 0.9851, f1: 0.9888, accuracy: 0.9883, loss: 0.0575 ||: : 16it [07:38, 27.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 02:30:43 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 02:30:43 :: tensor size after padding: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:30:43 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([32, 200, 768])]\n",
            "2024-05-30 02:30:43 :: post masking: content [torch.Size([32, 200])]\n",
            "new tenor size: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:30:43 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:30:43 :: post reprsentation shape : torch.Size([32, 768])\n",
            "{'precision': 0.9924812316894531, 'recall': 0.9850746393203735, 'f1': 0.9887641072273254}\n",
            "\n",
            "[20]\n",
            "Misclassified: ['768541206']\n",
            "PRINTING BATCH.....\n",
            "{'user_id': ['2550770106', '2780536832', '3839630199', '2387755969', '2955725076', '290007940', '3075915906', '289674969', '2174893676', '751627013446701056', '74869237', '3675117253', '2733510843', '3489973693', '50742387', '2792588894', '1632052196', '106888704', '2478045410', '288516978', '528237810', '38832219', '309287261', '2795859943', '2251993736', '3170783378', '229778675', '717929442459320320', '2193976020', '3936987923', '213188050', '319848001'], 'label': tensor([1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0,\n",
            "        0, 0, 0, 0, 0, 0, 1, 1])}\n",
            "2024-05-30 02:30:43 :: encode posts per user in batch ...\n",
            "2024-05-30 02:30:43 :: First two user ids in current batch: [2550770106] and [2780536832]\n",
            "called:  (2161, 768)\n",
            "called:  (340, 768)\n",
            "called:  (670, 768)\n",
            "called:  (220, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9928, recall: 0.9857, f1: 0.9892, accuracy: 0.9890, loss: 0.0542 ||: : 17it [08:32, 35.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 02:31:36 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 02:31:36 :: tensor size after padding: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:31:36 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([32, 200, 768])]\n",
            "2024-05-30 02:31:36 :: post masking: content [torch.Size([32, 200])]\n",
            "new tenor size: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:31:36 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:31:36 :: post reprsentation shape : torch.Size([32, 768])\n",
            "{'precision': 0.9927797913551331, 'recall': 0.9856630563735962, 'f1': 0.9892086386680603}\n",
            "\n",
            "PRINTING BATCH.....\n",
            "{'user_id': ['2263551014', '1395742416', '22956144', '260383789', '383088547', '988896109', '79151660', '4850525943', '890086446', '2356642926', '1164553514', '18109114', '606804677', '2697156349', '1642895108', '1325372719', '800144609703661568', '374517864', '2310168283', '259456473', '3003013589', '2343780440', '186025593', '77149325', '3431634372', '237085303', '50187291', '844973203', '1206228912', '3304801889', '925444885', '342836694'], 'label': tensor([1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1,\n",
            "        0, 0, 0, 0, 1, 1, 0, 1])}\n",
            "2024-05-30 02:31:36 :: encode posts per user in batch ...\n",
            "2024-05-30 02:31:36 :: First two user ids in current batch: [2263551014] and [1395742416]\n",
            "called:  (219, 768)\n",
            "called:  (1335, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9932, recall: 0.9864, f1: 0.9898, accuracy: 0.9896, loss: 0.0513 ||: : 18it [09:01, 33.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 02:32:05 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 02:32:05 :: tensor size after padding: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:32:05 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([32, 200, 768])]\n",
            "2024-05-30 02:32:05 :: post masking: content [torch.Size([32, 200])]\n",
            "new tenor size: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:32:05 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:32:05 :: post reprsentation shape : torch.Size([32, 768])\n",
            "{'precision': 0.9931507110595703, 'recall': 0.9863945841789246, 'f1': 0.9897610545158386}\n",
            "\n",
            "PRINTING BATCH.....\n",
            "{'user_id': ['1404453853', '189182634', '58826629', '2496060638', '3293333825', '3261067974', '39621699', '2463553073', '1475774791', '16644866', '94610482', '754591070', '2620902314', '2577747152', '2716146803', '2186807718', '500407390', '2919740217', '172189012', '1365610058', '3252234517', '804768361959735299', '11733482', '2201229530', '2794575981', '3214326412', '1704052507', '3309007203', '819445547748601858', '2682251407', '486097249', '382605888'], 'label': tensor([0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1,\n",
            "        1, 1, 1, 1, 0, 1, 0, 1])}\n",
            "2024-05-30 02:32:05 :: encode posts per user in batch ...\n",
            "2024-05-30 02:32:05 :: First two user ids in current batch: [1404453853] and [189182634]\n",
            "called:  (643, 768)\n",
            "called:  (236, 768)\n",
            "called:  (215, 768)\n",
            "called:  (533, 768)\n",
            "called:  (459, 768)\n",
            "called:  (1165, 768)\n",
            "called:  (206, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9935, recall: 0.9872, f1: 0.9904, accuracy: 0.9901, loss: 0.0493 ||: : 19it [09:56, 40.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 02:33:01 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 02:33:01 :: tensor size after padding: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:33:01 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([32, 200, 768])]\n",
            "2024-05-30 02:33:01 :: post masking: content [torch.Size([32, 200])]\n",
            "new tenor size: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:33:01 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:33:01 :: post reprsentation shape : torch.Size([32, 768])\n",
            "{'precision': 0.9935483932495117, 'recall': 0.9871794581413269, 'f1': 0.9903537034988403}\n",
            "\n",
            "PRINTING BATCH.....\n",
            "{'user_id': ['733807362176221185', '2778758881', '1394480425', '359004324', '14213981', '409630525', '742898899', '2265235430', '271239847', '246426922', '30090088', '1684625450', '1077787441', '331347673', '545253402', '852265598', '2501692766', '3182641520', '283501843', '2795889116', '1850260346', '786547405583896577', '2675050550', '509509243', '276911876', '387436546', '4319255233', '1414093086', '2467655728', '232046158', '428990245', '2958122503'], 'label': tensor([0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1,\n",
            "        1, 1, 0, 1, 0, 1, 0, 1])}\n",
            "2024-05-30 02:33:01 :: encode posts per user in batch ...\n",
            "2024-05-30 02:33:01 :: First two user ids in current batch: [733807362176221185] and [2778758881]\n",
            "called:  (339, 768)\n",
            "called:  (326, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9939, recall: 0.9878, f1: 0.9909, accuracy: 0.9906, loss: 0.0469 ||: : 20it [10:11, 32.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 02:33:16 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 02:33:16 :: tensor size after padding: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:33:16 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([32, 200, 768])]\n",
            "2024-05-30 02:33:16 :: post masking: content [torch.Size([32, 200])]\n",
            "new tenor size: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:33:16 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:33:16 :: post reprsentation shape : torch.Size([32, 768])\n",
            "{'precision': 0.9938837885856628, 'recall': 0.9878419637680054, 'f1': 0.9908537268638611}\n",
            "\n",
            "PRINTING BATCH.....\n",
            "{'user_id': ['2320227232', '279885063', '365848193', '249496407', '41141597', '294462275', '3091389007', '276713709', '271089475', '524990794', '3033519901', '1195705436', '269786387', '2843274460', '3177666918', '166401747', '944195358', '794560833032491008', '4535494887', '801021697340088325', '1401051756', '883259971', '18302641', '330638375', '760573447', '1310331727', '42483843', '607704515', '3013165740', '30610478', '1533665540', '2666097020'], 'label': tensor([0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0,\n",
            "        1, 0, 1, 1, 0, 0, 0, 1])}\n",
            "2024-05-30 02:33:16 :: encode posts per user in batch ...\n",
            "2024-05-30 02:33:16 :: First two user ids in current batch: [2320227232] and [279885063]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9942, recall: 0.9884, f1: 0.9913, accuracy: 0.9911, loss: 0.0448 ||: : 21it [10:15, 23.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 02:33:20 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 02:33:20 :: tensor size after padding: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:33:20 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([32, 200, 768])]\n",
            "2024-05-30 02:33:20 :: post masking: content [torch.Size([32, 200])]\n",
            "new tenor size: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:33:20 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:33:20 :: post reprsentation shape : torch.Size([32, 768])\n",
            "{'precision': 0.9941860437393188, 'recall': 0.9884393215179443, 'f1': 0.9913043975830078}\n",
            "\n",
            "PRINTING BATCH.....\n",
            "{'user_id': ['1326277782', '4220144173', '2187004009', '729631754726703104', '306117045', '292088285', '2970080866', '2453500499', '553141265', '1266763519', '784890429275721728', '65428564', '597020530', '496656065', '491518747', '2225969900', '87238977', '1481228695', '2268327331', '1336424340', '70994156', '1593193470', '607494477', '328356499', '2155166083', '816751502643568640', '3927175643', '362908506', '716034034221105161', '1165308708', '1483519507', '2477320338'], 'label': tensor([0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0,\n",
            "        0, 0, 0, 1, 0, 0, 0, 0])}\n",
            "2024-05-30 02:33:20 :: encode posts per user in batch ...\n",
            "2024-05-30 02:33:20 :: First two user ids in current batch: [1326277782] and [4220144173]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9944, recall: 0.9888, f1: 0.9916, accuracy: 0.9915, loss: 0.0429 ||: : 22it [10:19, 17.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 02:33:23 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 02:33:23 :: tensor size after padding: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:33:23 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([32, 200, 768])]\n",
            "2024-05-30 02:33:23 :: post masking: content [torch.Size([32, 200])]\n",
            "new tenor size: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:33:23 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:33:23 :: post reprsentation shape : torch.Size([32, 768])\n",
            "{'precision': 0.9943661689758301, 'recall': 0.9887955188751221, 'f1': 0.9915730357170105}\n",
            "\n",
            "PRINTING BATCH.....\n",
            "{'user_id': ['20310610', '186667137', '1492113409', '123198713', '239874758', '812520833885360128', '72260072', '2239142310', '2468263692', '4166502252', '1201511060', '498922994', '828193093', '301849804', '419930070', '590454670', '981269616', '2171246268', '616697007', '720733488', '367853663', '276400165', '2238789760', '2496081360', '1270938476', '7818902', '484548546', '809164013166731264', '163210599', '1070377050', '2339181019', '471697015'], 'label': tensor([1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n",
            "        1, 1, 0, 0, 1, 0, 0, 0])}\n",
            "2024-05-30 02:33:23 :: encode posts per user in batch ...\n",
            "2024-05-30 02:33:23 :: First two user ids in current batch: [20310610] and [186667137]\n",
            "called:  (315, 768)\n",
            "called:  (345, 768)\n",
            "called:  (212, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9946, recall: 0.9892, f1: 0.9919, accuracy: 0.9918, loss: 0.0411 ||: : 23it [10:36, 17.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 02:33:40 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 02:33:40 :: tensor size after padding: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:33:40 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([32, 200, 768])]\n",
            "2024-05-30 02:33:40 :: post masking: content [torch.Size([32, 200])]\n",
            "new tenor size: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:33:40 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:33:40 :: post reprsentation shape : torch.Size([32, 768])\n",
            "{'precision': 0.9945945739746094, 'recall': 0.9892473220825195, 'f1': 0.9919137358665466}\n",
            "\n",
            "PRINTING BATCH.....\n",
            "{'user_id': ['149249078', '49630734', '1129433366', '367906382', '1696251404', '133889960', '527804333', '2338968578', '40583679', '3540415093', '448292065', '634612808', '716114630', '52534149', '251261305', '543505284', '2851392822', '416548302', '546034844', '4643117782', '1483003130', '439733664', '107543218', '478424181', '1454052205', '1965639428', '3596682315', '1426496107', '344180927', '468616914', '395457568', '2942166386'], 'label': tensor([1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0,\n",
            "        0, 1, 0, 1, 1, 1, 1, 0])}\n",
            "2024-05-30 02:33:40 :: encode posts per user in batch ...\n",
            "2024-05-30 02:33:40 :: First two user ids in current batch: [149249078] and [49630734]\n",
            "called:  (288, 768)\n",
            "called:  (438, 768)\n",
            "called:  (250, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9948, recall: 0.9897, f1: 0.9923, accuracy: 0.9922, loss: 0.0398 ||: : 24it [10:56, 18.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 02:34:01 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 02:34:01 :: tensor size after padding: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:34:01 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([32, 200, 768])]\n",
            "2024-05-30 02:34:01 :: post masking: content [torch.Size([32, 200])]\n",
            "new tenor size: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:34:01 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:34:01 :: post reprsentation shape : torch.Size([32, 768])\n",
            "{'precision': 0.9948320388793945, 'recall': 0.9897172451019287, 'f1': 0.9922680854797363}\n",
            "\n",
            "PRINTING BATCH.....\n",
            "{'user_id': ['38884124', '1123162682', '255023313', '59121241', '15501305', '860459916', '33165799', '200172782', '764409588183687168', '381851647', '69511036', '902786155', '3400037493', '345502588', '4645192822', '754748916688498688', '398264458', '2816689907', '132543609', '1332656455', '2208125289', '54903945', '1716408985', '78029799', '394610276', '1568881466', '589270759', '1942358431', '4681763282', '18942749', '250976575', '3114283501'], 'label': tensor([0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1,\n",
            "        0, 1, 0, 1, 1, 1, 0, 0])}\n",
            "2024-05-30 02:34:01 :: encode posts per user in batch ...\n",
            "2024-05-30 02:34:01 :: First two user ids in current batch: [38884124] and [1123162682]\n",
            "called:  (454, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9951, recall: 0.9902, f1: 0.9926, accuracy: 0.9925, loss: 0.0387 ||: : 25it [11:08, 16.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 02:34:12 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 02:34:12 :: tensor size after padding: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:34:12 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([32, 200, 768])]\n",
            "2024-05-30 02:34:12 :: post masking: content [torch.Size([32, 200])]\n",
            "new tenor size: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:34:12 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:34:12 :: post reprsentation shape : torch.Size([32, 768])\n",
            "{'precision': 0.9950617551803589, 'recall': 0.9901719689369202, 'f1': 0.9926108121871948}\n",
            "\n",
            "PRINTING BATCH.....\n",
            "{'user_id': ['397317188', '2199921271', '354694798', '3134911251', '3106421874', '430254098', '1366273202', '1726951441', '1657007726', '1618094582', '700999275', '355531595', '2787517213', '715137886065180672', '216493614', '2847312748', '3037438274', '2674907557', '3070121118', '2989058306', '695004125629513728', '2888695487', '67752929', '412412198', '733475696970858497', '2787067758', '261487164', '702685269959442432', '31230042', '1609178257', '99167707', '330691650'], 'label': tensor([0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1,\n",
            "        0, 0, 0, 0, 1, 0, 0, 1])}\n",
            "2024-05-30 02:34:12 :: encode posts per user in batch ...\n",
            "2024-05-30 02:34:12 :: First two user ids in current batch: [397317188] and [2199921271]\n",
            "called:  (306, 768)\n",
            "called:  (507, 768)\n",
            "called:  (636, 768)\n",
            "called:  (876, 768)\n",
            "called:  (2013, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprecision: 0.9953, recall: 0.9883, f1: 0.9918, accuracy: 0.9916, loss: 0.0442 ||: : 26it [12:13, 30.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 02:35:17 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 02:35:17 :: tensor size after padding: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:35:17 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([32, 200, 768])]\n",
            "2024-05-30 02:35:17 :: post masking: content [torch.Size([32, 200])]\n",
            "new tenor size: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:35:17 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([32, 200, 768])\n",
            "2024-05-30 02:35:17 :: post reprsentation shape : torch.Size([32, 768])\n",
            "{'precision': 0.9952718615531921, 'recall': 0.9882628917694092, 'f1': 0.991754949092865}\n",
            "\n",
            "[6]\n",
            "Misclassified: ['1366273202']\n",
            "PRINTING BATCH.....\n",
            "{'user_id': ['3269731676', '16472629', '725316724141117440', '608347066', '977259259', '751390290733174784', '2741763729', '1085972869', '187245058', '19484358'], 'label': tensor([0, 1, 0, 1, 1, 0, 1, 1, 0, 1])}\n",
            "2024-05-30 02:35:17 :: encode posts per user in batch ...\n",
            "2024-05-30 02:35:17 :: First two user ids in current batch: [3269731676] and [16472629]\n",
            "called:  (467, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "precision: 0.9953, recall: 0.9884, f1: 0.9919, accuracy: 0.9917, loss: 0.0425 ||: : 27it [12:20, 27.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-30 02:35:25 :: done post & metaphor encoding! Padding and normalise sequence tensors for current batch now...\n",
            "2024-05-30 02:35:25 :: tensor size after padding: torch.Size([10, 200, 768])\n",
            "2024-05-30 02:35:25 :: Done. propagation tensors after batch normalisation: post content shape [torch.Size([10, 200, 768])]\n",
            "2024-05-30 02:35:25 :: post masking: content [torch.Size([10, 200])]\n",
            "new tenor size: torch.Size([10, 200, 768])\n",
            "2024-05-30 02:35:25 :: encode social context with LSTM\n",
            "query shape: torch.Size([128, 1, 768])\n",
            "key shape: torch.Size([10, 200, 768])\n",
            "2024-05-30 02:35:25 :: post reprsentation shape : torch.Size([10, 768])\n",
            "{'precision': 0.9953380227088928, 'recall': 0.9884259104728699, 'f1': 0.9918699264526367}\n",
            "\n",
            "{'precision': 0.9953380227088928, 'recall': 0.9884259104728699, 'f1': 0.9918699264526367}\n",
            "\n",
            "Misclassified Instances: ['1200392156', '1258401020', '1257535368', '346877404', '566870792', '768541206', '1366273202']\n",
            "Confusion Matrix:\n",
            "[[408   2]\n",
            " [  5 427]]\n",
            "2024-05-30 02:35:25 :: Finished evaluating.\n",
            "2024-05-30 02:35:25 :: Metrics:\n",
            "precision: 0.9953380227088928\n",
            "recall: 0.9884259104728699\n",
            "f1: 0.9918699264526367\n",
            "accuracy: 0.9916864608076009\n",
            "loss: 0.04254099717918844\n",
            "misclassified_instances: ['1200392156', '1258401020', '1257535368', '346877404', '566870792', '768541206', '1366273202']\n",
            "completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "from depression_classifier_778_clustering import model_training\n",
        "from data_loader import load_abs_path\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    # import optparse\n",
        "\n",
        "    # parser = optparse.OptionParser()\n",
        "\n",
        "    # parser.add_option('-t', '--trainset',\n",
        "    #                   dest=\"trainset\",\n",
        "    #                   help=\"train set path\", default=None)\n",
        "\n",
        "    # parser.add_option('-d', '--heldout',\n",
        "    #                   dest=\"heldout\",\n",
        "    #                   help=\"heldout dataset csv file\", default=None)\n",
        "\n",
        "    # parser.add_option('-e', '--evaluationset',\n",
        "    #                   dest=\"evalset\",\n",
        "    #                   help=\"evaluation/test dataset csv file\", default=None)\n",
        "\n",
        "    # parser.add_option('--post_dir',\n",
        "    #                   dest=\"postdir\",\n",
        "    #                   help=\"directory where posts are saved\", default=None)\n",
        "\n",
        "    # parser.add_option('-p', '--model_file_prefix',\n",
        "    #                   dest=\"model_file_prefix\",\n",
        "    #                   help=\"model file prefix for model weight output file\", default=None)\n",
        "\n",
        "    # parser.add_option('-g', '--n_gpu',\n",
        "    #                   dest=\"n_gpu\",\n",
        "    #                   help=\"gpu device(s) to use (-1: no gpu, 0: 1 gpu). only support int value for device no.\",\n",
        "    #                   default=-1)\n",
        "\n",
        "\n",
        "    # parser.add_option('--epochs', dest=\"num_epochs\", help=\"set num_epochs for training\", default=2)\n",
        "\n",
        "\n",
        "    # parser.add_option(\"--max_post_size\", dest=\"max_post_size_option\", help=\"maximum post size (default 200)\",\n",
        "    #                   default=200)\n",
        "\n",
        "\n",
        "    # options, args = parser.parse_args()\n",
        "\n",
        "    train_set_path = 'train.csv'\n",
        "    heldout_set_path = 'dev.csv'\n",
        "    evaluation_data_path = 'test.csv'\n",
        "    post_data_dir = 'mdl_HAN'\n",
        "    model_file_prefix = 'training_test'\n",
        "    no_gpu = 0\n",
        "\n",
        "    num_epochs = 10\n",
        "    max_post_size_option = 200\n",
        "\n",
        "    print(\"================= model settings ========================\")\n",
        "    print(\"trainset file path: \", train_set_path)\n",
        "    print(\"heldout file path: \", heldout_set_path)\n",
        "    print(\"evaluation set path: \", evaluation_data_path)\n",
        "    print(\"post data dir: \", post_data_dir)\n",
        "    print(\"model file prefix: \", model_file_prefix)\n",
        "    print(\"gpu device: \", no_gpu)\n",
        "\n",
        "    print(\"num_epochs: \", num_epochs)\n",
        "    print(\"max_post_size_option: \", max_post_size_option)\n",
        "    print(\"============================================================\")\n",
        "\n",
        "    if no_gpu != -1:\n",
        "        # check GPU device usage and help to set suitable GPU device\n",
        "        print(\"================================ check current GPU usage =============================\")\n",
        "        import subprocess\n",
        "\n",
        "        gpu_usage_result = subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE)\n",
        "        print(gpu_usage_result.stdout.decode('utf-8'))\n",
        "        print(\"======================================================================================\")\n",
        "\n",
        "    # see https://pytorch.org/docs/stable/notes/cuda.html\n",
        "    # os.environ['CUDA_VISIBLE_DEVICES'] = str(no_gpu)\n",
        "\n",
        "    if not os.path.isfile(train_set_path):\n",
        "        raise FileNotFoundError(\"training dataset csv file [%s] not found!\", train_set_path)\n",
        "\n",
        "    if not os.path.isfile(heldout_set_path):\n",
        "        raise FileNotFoundError(\"heldout dataset csv file [%s] not found!\", heldout_set_path)\n",
        "\n",
        "    if not os.path.isfile(evaluation_data_path):\n",
        "        raise FileNotFoundError(\"test set csv file [%s] not found!\", evaluation_data_path)\n",
        "\n",
        "\n",
        "    print(\"training HAN on development dataset [%s] and [%s] with gpu [%s]\" %\n",
        "          (train_set_path, heldout_set_path, no_gpu))\n",
        "\n",
        "    import depression_classifier_778_clustering\n",
        "    import data_loader\n",
        "    from depression_classifier_778_clustering import config_gpu_use\n",
        "\n",
        "    config_gpu_use(no_gpu)\n",
        "\n",
        "\n",
        "    data_loader.post_data_dir = post_data_dir\n",
        "\n",
        "    print(\"post data directory is set to [%s]\" % data_loader.post_data_dir)\n",
        "\n",
        "\n",
        "    train_batch_size = 128\n",
        "\n",
        "\n",
        "    print(\"model training in batches [size: %s]\" % train_batch_size)\n",
        "    model_training(train_set_path, heldout_set_path, evaluation_data_path, no_gpu, train_batch_size,\n",
        "                   model_file_prefix,\n",
        "                   num_epochs=num_epochs,\n",
        "                   max_post_size_option=max_post_size_option)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9145228381e84439ba69400afddf7f08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_732c39e18f00415cbfd6fa9ec7ba5e6c",
              "IPY_MODEL_1d4852f01adb47d89c80dde7cbef242a",
              "IPY_MODEL_c1650893cc094d67b300b2b6c96c0622"
            ],
            "layout": "IPY_MODEL_b9f3655a0a2a408a84a15ee67f0f5703"
          }
        },
        "732c39e18f00415cbfd6fa9ec7ba5e6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc55967e05934297ba74488c1704ab6b",
            "placeholder": "​",
            "style": "IPY_MODEL_b82f01b4885f4cac8eab2c7cce2df1ca",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "1d4852f01adb47d89c80dde7cbef242a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aac59ab24c2f4f1b8a0daab4c81bb6ae",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_018f8f95c2404f39a644a88e68fe2b4a",
            "value": 48
          }
        },
        "c1650893cc094d67b300b2b6c96c0622": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c20276d83554a73865bd7a2155ddf12",
            "placeholder": "​",
            "style": "IPY_MODEL_b2ac30d5abc145e893c1c1f54033e4e7",
            "value": " 48.0/48.0 [00:00&lt;00:00, 3.73kB/s]"
          }
        },
        "b9f3655a0a2a408a84a15ee67f0f5703": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc55967e05934297ba74488c1704ab6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b82f01b4885f4cac8eab2c7cce2df1ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aac59ab24c2f4f1b8a0daab4c81bb6ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "018f8f95c2404f39a644a88e68fe2b4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6c20276d83554a73865bd7a2155ddf12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2ac30d5abc145e893c1c1f54033e4e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b99b97319aca426d9ac73e35732d0815": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6540cb0576bd430b9f193997be093800",
              "IPY_MODEL_cbb403780c714069a34484114a36f49c",
              "IPY_MODEL_877ff06916c447f3ad3ecaadc88d6efc"
            ],
            "layout": "IPY_MODEL_10c0db1ab1e3446eb8e31ea0e3000584"
          }
        },
        "6540cb0576bd430b9f193997be093800": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81822ecffe884dd8952c618f801dafdc",
            "placeholder": "​",
            "style": "IPY_MODEL_ba02f1693d5b46e992d538194cb5794c",
            "value": "config.json: 100%"
          }
        },
        "cbb403780c714069a34484114a36f49c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f25e8bc4cd4148b39f185369f3514272",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1f92e1ced55f4029a759ba24eef086aa",
            "value": 570
          }
        },
        "877ff06916c447f3ad3ecaadc88d6efc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe2d9fe6c4bc4cf4a3269fb6afa18d92",
            "placeholder": "​",
            "style": "IPY_MODEL_3eb9bce2caa2434ba1f3522f96ab6132",
            "value": " 570/570 [00:00&lt;00:00, 43.2kB/s]"
          }
        },
        "10c0db1ab1e3446eb8e31ea0e3000584": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81822ecffe884dd8952c618f801dafdc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba02f1693d5b46e992d538194cb5794c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f25e8bc4cd4148b39f185369f3514272": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f92e1ced55f4029a759ba24eef086aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fe2d9fe6c4bc4cf4a3269fb6afa18d92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3eb9bce2caa2434ba1f3522f96ab6132": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c38e040510d941afadd9b987194af2a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d998fd45599a4b01a4cbf3b541930e5f",
              "IPY_MODEL_830613a567f3450c9d15078c31bb25b0",
              "IPY_MODEL_d0b7fcf3a9a8481683e4f4e014599575"
            ],
            "layout": "IPY_MODEL_03d24806d6c340c6816fc38b27d722fc"
          }
        },
        "d998fd45599a4b01a4cbf3b541930e5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c5fa59228fd42a696deff6790e2e41b",
            "placeholder": "​",
            "style": "IPY_MODEL_26056809ae1a4b51b1b7127758b03276",
            "value": "vocab.txt: 100%"
          }
        },
        "830613a567f3450c9d15078c31bb25b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26b9219106494f338379f71b02ead85b",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3ca1fde70c7f4b4782e516022c94cf0f",
            "value": 231508
          }
        },
        "d0b7fcf3a9a8481683e4f4e014599575": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf865b83fdf04f81a8830e249afae2b9",
            "placeholder": "​",
            "style": "IPY_MODEL_bddfbb10472a4707a3632def13a33ea5",
            "value": " 232k/232k [00:00&lt;00:00, 11.6MB/s]"
          }
        },
        "03d24806d6c340c6816fc38b27d722fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c5fa59228fd42a696deff6790e2e41b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26056809ae1a4b51b1b7127758b03276": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "26b9219106494f338379f71b02ead85b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ca1fde70c7f4b4782e516022c94cf0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cf865b83fdf04f81a8830e249afae2b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bddfbb10472a4707a3632def13a33ea5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c06e4753558a4a249ea78759da57009d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c2e1b32293ec4c94887e8053e358ff28",
              "IPY_MODEL_3a3e4f98b82a42f6b579d6e5810b5bde",
              "IPY_MODEL_4933c17d1fff4ebf976ac42c51ac40cd"
            ],
            "layout": "IPY_MODEL_85741bf0fadf43b2a77a91ebb9bb1031"
          }
        },
        "c2e1b32293ec4c94887e8053e358ff28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0eda42ccbd8410390ec297966a2207e",
            "placeholder": "​",
            "style": "IPY_MODEL_2470d5f999484947b8302fc62577c08d",
            "value": "tokenizer.json: 100%"
          }
        },
        "3a3e4f98b82a42f6b579d6e5810b5bde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2be3dffe33a14c43907096c8bde47902",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c807cab2a75e4883b58eda40c2a86e54",
            "value": 466062
          }
        },
        "4933c17d1fff4ebf976ac42c51ac40cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d03fac667a44bc19937c7821807917d",
            "placeholder": "​",
            "style": "IPY_MODEL_ab4c899022c640d485f3b54e4580c296",
            "value": " 466k/466k [00:00&lt;00:00, 19.5MB/s]"
          }
        },
        "85741bf0fadf43b2a77a91ebb9bb1031": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0eda42ccbd8410390ec297966a2207e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2470d5f999484947b8302fc62577c08d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2be3dffe33a14c43907096c8bde47902": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c807cab2a75e4883b58eda40c2a86e54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1d03fac667a44bc19937c7821807917d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab4c899022c640d485f3b54e4580c296": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b20119ec26b4ea28272e9418da45985": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_537f30537edb4ce58418099110d45b04",
              "IPY_MODEL_06525c39ddc4482ea4fd6197fa61cc46",
              "IPY_MODEL_185faced2fc344cfbf5560ac260a04c9"
            ],
            "layout": "IPY_MODEL_ba1b85c0c6b54b5a930030b6e19fe9d0"
          }
        },
        "537f30537edb4ce58418099110d45b04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a6c2596ab8146bdb1153dcaf6db722f",
            "placeholder": "​",
            "style": "IPY_MODEL_bfdf9294b5384a25905bdc1b7953265d",
            "value": "model.safetensors: 100%"
          }
        },
        "06525c39ddc4482ea4fd6197fa61cc46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_afb6ca4d87554aaf844749c50537ccca",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0bd0af5aae6a483989081059e6b8e708",
            "value": 440449768
          }
        },
        "185faced2fc344cfbf5560ac260a04c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0959676f5e8f498aa7d31d61505cfffc",
            "placeholder": "​",
            "style": "IPY_MODEL_643286f983154a52b45a28f7381660a6",
            "value": " 440M/440M [00:01&lt;00:00, 468MB/s]"
          }
        },
        "ba1b85c0c6b54b5a930030b6e19fe9d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a6c2596ab8146bdb1153dcaf6db722f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfdf9294b5384a25905bdc1b7953265d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "afb6ca4d87554aaf844749c50537ccca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bd0af5aae6a483989081059e6b8e708": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0959676f5e8f498aa7d31d61505cfffc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "643286f983154a52b45a28f7381660a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}